{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat, create_glacfeat\n",
    "\n",
    "calc_emergence =False\n",
    "debris_only=False\n",
    "\n",
    "min_dhdt_perc = 75\n",
    "\n",
    "debug=False\n",
    "extra_layers=True\n",
    "\n",
    "csv_ending = '_mb_bins.csv'\n",
    "# outdir_csv = debris_prms.mb_binned_fp\n",
    "outdir_csv = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/debris_global/' + \n",
    "              '../output/mb_bins_all/csv/')\n",
    "outdir_csv = outdir_csv + debris_prms.roi + '/'\n",
    "if not os.path.exists(outdir_csv):\n",
    "    os.makedirs(outdir_csv)\n",
    "    \n",
    "# dhdt_vel_fns_fp = debris_prms.dhdt_vel_fns_fp\n",
    "dhdt_vel_fns_fp = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/debris_global/' + \n",
    "                   '../output/dhdt_vel_fns_all/')\n",
    "if not os.path.exists(dhdt_vel_fns_fp):\n",
    "    os.makedirs(dhdt_vel_fns_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All glaciers within region(s) 5 are included in this model run.\n",
      "This study is focusing on 20261 glaciers in region [5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlacNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RGI60-05.00001</td>\n",
       "      <td>-53.2909</td>\n",
       "      <td>66.0765</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168</td>\n",
       "      <td>689</td>\n",
       "      <td>995</td>\n",
       "      <td>868</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000814</td>\n",
       "      <td>1</td>\n",
       "      <td>05.00001</td>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RGI60-05.00002</td>\n",
       "      <td>-52.0705</td>\n",
       "      <td>65.3617</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>602</td>\n",
       "      <td>704</td>\n",
       "      <td>643</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000823</td>\n",
       "      <td>2</td>\n",
       "      <td>05.00002</td>\n",
       "      <td>5.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RGI60-05.00003</td>\n",
       "      <td>-52.0017</td>\n",
       "      <td>65.5791</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>646</td>\n",
       "      <td>697</td>\n",
       "      <td>683</td>\n",
       "      <td>10.1</td>\n",
       "      <td>28</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000823</td>\n",
       "      <td>3</td>\n",
       "      <td>05.00003</td>\n",
       "      <td>5.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RGI60-05.00004</td>\n",
       "      <td>-51.7992</td>\n",
       "      <td>65.1590</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188</td>\n",
       "      <td>635</td>\n",
       "      <td>775</td>\n",
       "      <td>735</td>\n",
       "      <td>11.8</td>\n",
       "      <td>30</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000823</td>\n",
       "      <td>4</td>\n",
       "      <td>05.00004</td>\n",
       "      <td>5.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RGI60-05.00005</td>\n",
       "      <td>-51.7228</td>\n",
       "      <td>65.1786</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>711</td>\n",
       "      <td>769</td>\n",
       "      <td>747</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000823</td>\n",
       "      <td>5</td>\n",
       "      <td>05.00005</td>\n",
       "      <td>5.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20256</th>\n",
       "      <td>20256</td>\n",
       "      <td>RGI60-05.20275</td>\n",
       "      <td>-29.7831</td>\n",
       "      <td>70.2707</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1226</td>\n",
       "      <td>1560</td>\n",
       "      <td>1502</td>\n",
       "      <td>12.6</td>\n",
       "      <td>21</td>\n",
       "      <td>1093</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20010921</td>\n",
       "      <td>20275</td>\n",
       "      <td>05.20275</td>\n",
       "      <td>5.20275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20257</th>\n",
       "      <td>20257</td>\n",
       "      <td>RGI60-05.20277</td>\n",
       "      <td>-29.7908</td>\n",
       "      <td>70.2829</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>1238</td>\n",
       "      <td>1282</td>\n",
       "      <td>1256</td>\n",
       "      <td>7.7</td>\n",
       "      <td>70</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20010921</td>\n",
       "      <td>20277</td>\n",
       "      <td>05.20277</td>\n",
       "      <td>5.20277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20258</th>\n",
       "      <td>20258</td>\n",
       "      <td>RGI60-05.20278</td>\n",
       "      <td>-28.9625</td>\n",
       "      <td>69.9847</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.459</td>\n",
       "      <td>955</td>\n",
       "      <td>2066</td>\n",
       "      <td>1430</td>\n",
       "      <td>42.8</td>\n",
       "      <td>359</td>\n",
       "      <td>1697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20010712</td>\n",
       "      <td>20278</td>\n",
       "      <td>05.20278</td>\n",
       "      <td>5.20278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20259</th>\n",
       "      <td>20259</td>\n",
       "      <td>RGI60-05.20279</td>\n",
       "      <td>-25.5287</td>\n",
       "      <td>71.2796</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1373</td>\n",
       "      <td>1638</td>\n",
       "      <td>1534</td>\n",
       "      <td>39.1</td>\n",
       "      <td>142</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20010820</td>\n",
       "      <td>20279</td>\n",
       "      <td>05.20279</td>\n",
       "      <td>5.20279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20260</th>\n",
       "      <td>20260</td>\n",
       "      <td>RGI60-05.20280</td>\n",
       "      <td>-25.5799</td>\n",
       "      <td>71.2776</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11.590</td>\n",
       "      <td>56</td>\n",
       "      <td>2124</td>\n",
       "      <td>1705</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88</td>\n",
       "      <td>9684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20010820</td>\n",
       "      <td>20280</td>\n",
       "      <td>05.20280</td>\n",
       "      <td>5.20280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20261 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        O1Index           RGIId   CenLon   CenLat  O1Region  O2Region    Area  \\\n",
       "GlacNo                                                                          \n",
       "0             0  RGI60-05.00001 -53.2909  66.0765         5         1   0.168   \n",
       "1             1  RGI60-05.00002 -52.0705  65.3617         5         1   0.118   \n",
       "2             2  RGI60-05.00003 -52.0017  65.5791         5         1   0.059   \n",
       "3             3  RGI60-05.00004 -51.7992  65.1590         5         1   0.188   \n",
       "4             4  RGI60-05.00005 -51.7228  65.1786         5         1   0.086   \n",
       "...         ...             ...      ...      ...       ...       ...     ...   \n",
       "20256     20256  RGI60-05.20275 -29.7831  70.2707         5         1   1.008   \n",
       "20257     20257  RGI60-05.20277 -29.7908  70.2829         5         1   0.071   \n",
       "20258     20258  RGI60-05.20278 -28.9625  69.9847         5         1   1.459   \n",
       "20259     20259  RGI60-05.20279 -25.5287  71.2796         5         1   0.051   \n",
       "20260     20260  RGI60-05.20280 -25.5799  71.2776         5         1  11.590   \n",
       "\n",
       "        Zmin  Zmax  Zmed  Slope  Aspect  Lmax  Form  TermType  Surging  \\\n",
       "GlacNo                                                                   \n",
       "0        689   995   868   29.0      25   406     0         0        9   \n",
       "1        602   704   643   14.0      49   283     0         0        9   \n",
       "2        646   697   683   10.1      28   365     0         0        9   \n",
       "3        635   775   735   11.8      30   392     0         0        9   \n",
       "4        711   769   747   13.1       1   218     0         0        9   \n",
       "...      ...   ...   ...    ...     ...   ...   ...       ...      ...   \n",
       "20256   1226  1560  1502   12.6      21  1093     1         0        9   \n",
       "20257   1238  1282  1256    7.7      70   175     0         0        9   \n",
       "20258    955  2066  1430   42.8     359  1697     1         0        9   \n",
       "20259   1373  1638  1534   39.1     142   242     0         0        9   \n",
       "20260     56  2124  1705   20.0      88  9684     0         1        9   \n",
       "\n",
       "         RefDate  glacno rgino_str  RGIId_float  \n",
       "GlacNo                                           \n",
       "0       20000814       1  05.00001      5.00001  \n",
       "1       20000823       2  05.00002      5.00002  \n",
       "2       20000823       3  05.00003      5.00003  \n",
       "3       20000823       4  05.00004      5.00004  \n",
       "4       20000823       5  05.00005      5.00005  \n",
       "...          ...     ...       ...          ...  \n",
       "20256   20010921   20275  05.20275      5.20275  \n",
       "20257   20010921   20277  05.20277      5.20277  \n",
       "20258   20010712   20278  05.20278      5.20278  \n",
       "20259   20010820   20279  05.20279      5.20279  \n",
       "20260   20010820   20280  05.20280      5.20280  \n",
       "\n",
       "[20261 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if debris_only:\n",
    "    # Debris cover extent shapefile with statistics\n",
    "    dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "    dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "    # Subset by percent debris-covered or debris-covered area\n",
    "    dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                            (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                            & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "    dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "    dc_shp_subset['CenLon_360'] = dc_shp_subset['CenLon']\n",
    "    dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "        360 + dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "\n",
    "    rgiid_list = [x.split('-')[1] for x in dc_shp_subset['RGIId'].values]\n",
    "    main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgiid_list)\n",
    "\n",
    "else:\n",
    "    # All glaciers\n",
    "    main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgi_regionsO1=debris_prms.roi_rgidict[debris_prms.roi],\n",
    "                                                              rgi_regionsO2='all', rgi_glac_number='all')\n",
    "    \n",
    "    # Debris cover extent shapefile with statistics\n",
    "    dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "    dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "    dc_shp.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# dc_shp\n",
    "main_glac_rgi_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhdt_vel_fns_fn = debris_prms.dhdt_vel_fns_fn.replace('XXXX',debris_prms.roi)\n",
    "if os.path.exists(dhdt_vel_fns_fp + dhdt_vel_fns_fn):\n",
    "    dhdt_vel_fns_df = pd.read_csv(dhdt_vel_fns_fp + dhdt_vel_fns_fn)\n",
    "else:\n",
    "    dhdt_vel_fns_df = pd.DataFrame(np.zeros((main_glac_rgi_subset.shape[0], 3)),\n",
    "                                   columns=['RGIId', 'dhdt_fullfn', 'vel_fullfn'])\n",
    "    dhdt_vel_fns_df['RGIId'] = main_glac_rgi_subset['RGIId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(main_glac_rgi_subset.rgino_str == '11.03005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing: 0\n"
     ]
    }
   ],
   "source": [
    "# skip existing\n",
    "rgiid_existing = []\n",
    "for i in os.listdir(outdir_csv):\n",
    "    if i.endswith('.csv'):\n",
    "        rgiid_existing.append(i.split('_')[0])\n",
    "print('existing:', len(rgiid_existing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15066 RGI60-05.15072\n",
      "1 15067 RGI60-05.15073\n",
      "2 15068 RGI60-05.15074\n",
      "3 15069 RGI60-05.15075\n",
      "4 15070 RGI60-05.15076\n",
      "5 15071 RGI60-05.15077\n",
      "6 15072 RGI60-05.15078\n",
      "7 15073 RGI60-05.15079\n",
      "8 15074 RGI60-05.15080\n",
      "9 15075 RGI60-05.15081\n",
      "10 15076 RGI60-05.15082\n"
     ]
    }
   ],
   "source": [
    "# ===== PROCESS EACH GLACIER =====\n",
    "dc_rgiids = dc_shp.RGIId.tolist()\n",
    "for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values):\n",
    "# for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values[15066:]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[0]]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[120]]): # Miage\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[2307]]): # Ngozumpa\n",
    "\n",
    "    glac_str = main_glac_rgi_subset.loc[glac_idx,'rgino_str']\n",
    "    rgiid = main_glac_rgi_subset.loc[glac_idx,'RGIId']\n",
    "    region = glac_str.split('.')[0]\n",
    "\n",
    "    if int(region) < 10:\n",
    "        glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "    else:\n",
    "        glac_str_noleadzero = glac_str\n",
    "        \n",
    "    if glac_str_noleadzero not in rgiid_existing:\n",
    "\n",
    "        print(nglac, glac_idx, rgiid)\n",
    "\n",
    "        # Create glacier feature from ice thickness raster\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "        \n",
    "        if os.path.exists(thick_dir + thick_fn):\n",
    "        \n",
    "            gf = create_glacfeat(thick_dir, thick_fn)\n",
    "\n",
    "            if rgiid in dc_rgiids:\n",
    "                # Debris shape layer processing\n",
    "                dc_shp_proj_fn = (debris_prms.glac_shp_proj_fp + glac_str + '_dc_crs' + \n",
    "                                  str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp')\n",
    "                if os.path.exists(dc_shp_proj_fn) == False:\n",
    "                    dc_shp_init = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "                    dc_shp_single = dc_shp_init[dc_shp_init['RGIId'] == rgiid]\n",
    "                    dc_shp_single = dc_shp_single.reset_index()\n",
    "                    dc_shp_proj = dc_shp_single.to_crs({'init': 'epsg:' + str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "                    dc_shp_proj.to_file(dc_shp_proj_fn)\n",
    "                dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "                dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "            else:\n",
    "                dc_shp_lyr = None\n",
    "\n",
    "            # ==== CHECK IF TIF HAS DHDT DATA OVER THE GLACIER =====\n",
    "            mb_fullfns = []\n",
    "            find_mb = True\n",
    "            dhdt_fn_wglacier = None\n",
    "            for mb_fp in debris_prms.mb_fp_list_roi[debris_prms.roi]:\n",
    "                if find_mb:\n",
    "                    for i in os.listdir(mb_fp):\n",
    "                        if i.endswith('.tif'):\n",
    "                            mb_fullfns.append(mb_fp + i)\n",
    "                    tif_count = 0\n",
    "                    while find_mb and tif_count < len(mb_fullfns):\n",
    "                        dhdt_fn = mb_fullfns[tif_count]\n",
    "                        if debug:\n",
    "                            print(tif_count, dhdt_fn.split('/')[-1])\n",
    "\n",
    "                        # Add the filenames\n",
    "                        fn_dict = OrderedDict()\n",
    "                        # DEM\n",
    "                        z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                        z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "                        fn_dict['z1'] = z1_fp + z1_fn\n",
    "                        # Ice thickness\n",
    "                        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "                        fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "                        # dh/dt\n",
    "                        fn_dict['dhdt'] = dhdt_fn\n",
    "                        # ===== PROCESS THE DATA =====\n",
    "                        #Expand extent to include buffered region around glacier polygon\n",
    "                        warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "                        #Warp everything to common res/extent/proj\n",
    "                        z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "                        z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "                        ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                           t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                        ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                        gf.ds_dict = ds_dict\n",
    "\n",
    "                        if 'z1' in ds_dict:\n",
    "                            #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                            glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "                            glac_geom_mask_copy = glac_geom_mask.copy()\n",
    "                            gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "                            if rgiid in dc_rgiids:\n",
    "                                # Debris cover\n",
    "                                dc_shp_lyr_mask = geolib.lyr2mask(dc_shp_lyr, ds_dict['ice_thick'])\n",
    "                                gf.dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "                            if 'dhdt' in ds_dict:\n",
    "                                gf.dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                                gf.dhdt.mask = np.ma.mask_or(\n",
    "                                    glac_geom_mask, np.ma.getmask(np.ma.masked_array(gf.dhdt.data, \n",
    "                                                                                     np.isnan(gf.dhdt.data))))\n",
    "                                \n",
    "                                if rgiid in dc_rgiids:\n",
    "                                    gf.dc_dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=gf.dc_mask)\n",
    "                                    gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=gf.dc_mask)\n",
    "                                # Count dhdt pixels\n",
    "                                dhdt_pixels = len(gf.dhdt.nonzero()[0])                              \n",
    "                                \n",
    "                                if dhdt_pixels / gf.z1.count() * 100 > min_dhdt_perc:\n",
    "                                    dhdt_fn_wglacier = dhdt_fn\n",
    "                                    find_mb = False\n",
    "                                    if debug:\n",
    "                                        print('\\n# z1 pixels:', gf.z1.count())\n",
    "                                        print('# dhdt_pixels:', dhdt_pixels)\n",
    "                                        var_full2plot = gf.dhdt.copy()\n",
    "                                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                        plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', \n",
    "                                                   close_fig=False)\n",
    "                        # Loop over layers        \n",
    "                        tif_count += 1\n",
    "\n",
    "            # ==== CHECK IF VELOCITY DATA OVER THE GLACIER =====\n",
    "            vel_fullfns = []\n",
    "            find_vel = True\n",
    "            vx_fn_wglacier = None\n",
    "            if find_vel and dhdt_fn_wglacier is not None:\n",
    "                vx_fns = debris_prms.vx_dir_dict_list[debris_prms.roi]\n",
    "                tif_count = 0\n",
    "                while find_vel and tif_count < len(vx_fns):\n",
    "                    vx_fn = vx_fns[tif_count]\n",
    "\n",
    "                    if debug:\n",
    "                        print(tif_count, vx_fn.split('/')[-1])\n",
    "\n",
    "                    # Add the filenames\n",
    "                    # Velocity\n",
    "                    fn_dict['vx'] = vx_fn\n",
    "                    fn_dict['vy'] = vx_fn.replace('_vx', '_vy')\n",
    "                    # ===== PROCESS THE DATA =====\n",
    "                    ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                       t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                    ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                    gf.ds_dict = ds_dict\n",
    "                    if 'vx' in ds_dict and 'vy' in ds_dict:\n",
    "                        #Load surface velocity maps\n",
    "                        gf.vx = np.ma.array(iolib.ds_getma(ds_dict['vx']), mask=glac_geom_mask)\n",
    "                        gf.vy = np.ma.array(iolib.ds_getma(ds_dict['vy']), mask=glac_geom_mask)\n",
    "                        gf.vm = np.ma.sqrt(gf.vx**2 + gf.vy**2)\n",
    "                        # Count velocity pixels\n",
    "                        vel_pixels = len(gf.vm.nonzero()[0])\n",
    "                        if debug:\n",
    "                                print('\\n# z1 pixels:', gf.z1.count())\n",
    "                                print('# vel_pixels:', vel_pixels)\n",
    "                                var_full2plot = gf.vm.copy()\n",
    "                                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vm (m/yr)', \n",
    "                                           close_fig=False)\n",
    "                        if vel_pixels / gf.z1.count() * 100 > min_dhdt_perc:\n",
    "                            vx_fn_wglacier = vx_fn\n",
    "                            find_vel = False\n",
    "\n",
    "                    # Loop over layers        \n",
    "                    tif_count += 1\n",
    "\n",
    "\n",
    "            # ===== Add layers =====\n",
    "            if dhdt_fn_wglacier is not None and vx_fn_wglacier is not None:\n",
    "                gf.add_layers(dc_shp_lyr, gf_add_dhdt=True, dhdt_fn=dhdt_fn_wglacier, gf_add_vel=True, \n",
    "                              vx_fn=vx_fn_wglacier, gf_add_ts=False, gf_add_slope_aspect=True, gf_add_ts_info=False, \n",
    "                              calc_emergence=calc_emergence, debug_emergence=False)\n",
    "                # Save dhdt and vel filenames\n",
    "                dhdt_vel_fns_df.loc[glac_idx,:] = [rgiid, dhdt_fn_wglacier, vx_fn_wglacier]\n",
    "\n",
    "                # ===== PLOTS =====\n",
    "#                 plot_layers = True\n",
    "                plot_layers = False\n",
    "                if plot_layers:\n",
    "                    # DEM\n",
    "                    var_full2plot = gf.z1.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                    # Elevation change\n",
    "                    var_full2plot = gf.dhdt.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', close_fig=False)\n",
    "                    # Velocity\n",
    "                    var_full2plot = gf.vm.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vel (m/yr)', close_fig=False)\n",
    "                    # Emergence velocity\n",
    "                    if gf.emvel is not None:\n",
    "                        var_full2plot = gf.emvel.copy()\n",
    "                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                        plot_array(var_full2plot, clim, [glac_str + ' emvel'], 'inferno', 'emvel (m/yr)', close_fig=False)\n",
    "                    # Surface temperature\n",
    "                    if gf.ts is not None:\n",
    "                        var_full2plot = gf.ts.copy()\n",
    "                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                        plot_array(var_full2plot, clim, [glac_str + ' Ts'], 'inferno', 'ts (degC)', close_fig=False)\n",
    "\n",
    "                # Bin data\n",
    "                outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "                # Export binned data\n",
    "                if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "                else:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "                outbins_df.loc[:,:] = np.nan_to_num(outbins_df.loc[:,:],0)\n",
    "                outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "            \n",
    "            # Elevation bins for glaciers with only dhdt data\n",
    "            elif dhdt_fn_wglacier is not None and vx_fn_wglacier is None:\n",
    "                gf.add_layers(dc_shp_lyr, gf_add_dhdt=True, dhdt_fn=dhdt_fn_wglacier, gf_add_vel=False, \n",
    "                              gf_add_ts=False, gf_add_slope_aspect=True, gf_add_ts_info=False, \n",
    "                              calc_emergence=calc_emergence, debug_emergence=False)\n",
    "                # Save dhdt and vel filenames\n",
    "                dhdt_vel_fns_df.loc[glac_idx,:] = [rgiid, dhdt_fn_wglacier, 0]\n",
    "\n",
    "                # ===== PLOTS =====\n",
    "#                 plot_layers = True\n",
    "                plot_layers = False\n",
    "                if plot_layers:\n",
    "                    # DEM\n",
    "                    var_full2plot = gf.z1.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                    # Elevation change\n",
    "                    var_full2plot = gf.dhdt.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', close_fig=False)\n",
    "                # Bin data\n",
    "                outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "                # Export binned data\n",
    "                if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "                else:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "                outbins_df.loc[:,:] = np.nan_to_num(outbins_df.loc[:,:],0)\n",
    "                outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "            \n",
    "            # Elevation bins for glaciers without any data\n",
    "            else:\n",
    "                gf.dhdt, gf.dc_dhdt = None, None\n",
    "                gf.vx, gf.vy, gf.vm = None, None, None\n",
    "                gf.add_layers(dc_shp_lyr, gf_add_dhdt=False, gf_add_vel=False, gf_add_ts=False, \n",
    "                              gf_add_slope_aspect=True, gf_add_ts_info=False, \n",
    "                              calc_emergence=calc_emergence, debug_emergence=False,\n",
    "                             verbose=False)\n",
    "                # ===== PLOTS =====\n",
    "#                 plot_layers = True\n",
    "                plot_layers = False\n",
    "                if plot_layers:\n",
    "                    # DEM\n",
    "                    var_full2plot = gf.z1.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                    \n",
    "                # Bin data\n",
    "                outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "                # Export binned data\n",
    "                outdir_csv_nodhdt = outdir_csv + 'no_dhdt/'\n",
    "                csv_ending_nodhdt = '_bins.csv'\n",
    "                if not os.path.exists(outdir_csv_nodhdt):\n",
    "                    os.makedirs(outdir_csv_nodhdt)\n",
    "                if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv_nodhdt, gf.feat_fn[0:7] + csv_ending_nodhdt)\n",
    "                else:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv_nodhdt, gf.feat_fn[0:8] + csv_ending_nodhdt)\n",
    "                outbins_df.loc[:,:] = np.nan_to_num(outbins_df.loc[:,:],0)\n",
    "                outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "\n",
    "\n",
    "# Save updated filenames\n",
    "dhdt_vel_fns_df.to_csv(dhdt_vel_fns_fp + dhdt_vel_fns_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\nDONE!\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip existing\n",
    "rgiid_existing = []\n",
    "for i in os.listdir(outdir_csv):\n",
    "    if i.endswith('.csv'):\n",
    "        rgiid_existing.append(i.split('_')[0])\n",
    "main_glac_rgi_processed = debris_prms.selectglaciersrgitable(rgiid_existing)\n",
    "print('Processed ' + str(len(rgiid_existing)) + ' of ' + str(len(main_glac_rgi_subset)) + ' glaciers')\n",
    "area_total = main_glac_rgi_subset.Area.sum()\n",
    "area_processed = main_glac_rgi_processed.Area.sum()\n",
    "print('  Area: ' + str(np.round(area_processed,1)) + ' km2 (' + str(np.round(area_processed / area_total * 100,1)) + \n",
    "      '%) of ' +  str(np.round(area_total,1)) + ' km2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Isolate HMA regions\n",
    "# # outdir_csv_raw = outdir_csv.replace('HMA/', '')\n",
    "# if debris_prms.roi == 'HMA':\n",
    "#     for region in ['13','14','15']:\n",
    "#         outdir_csv = outdir_csv_raw + region + '/'\n",
    "#         rgiid_existing = []\n",
    "#         for i in os.listdir(outdir_csv):\n",
    "#             if i.endswith('.csv'):\n",
    "#                 rgiid_existing.append(i.split('_')[0])\n",
    "#         main_glac_rgi_processed = debris_prms.selectglaciersrgitable(rgiid_existing)\n",
    "#         main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgi_regionsO1=[int(region)],\n",
    "#                                                                   rgi_regionsO2='all', rgi_glac_number='all')\n",
    "#         area_total = main_glac_rgi_subset.Area.sum()\n",
    "#         area_processed = main_glac_rgi_processed.Area.sum()\n",
    "#         print('Processed ' + str(len(rgiid_existing)) + ' of ' + str(len(main_glac_rgi_subset)) + ' glaciers')\n",
    "#         print('  Area: ' + str(np.round(area_processed,1)) + ' km2 (' + str(np.round(area_processed / area_total * 100,1)) + \n",
    "#               '%) of ' +  str(np.round(area_total,1)) + ' km2\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SHEAN ESTIMATE OF FLUX DIVERGENCE QUICKLY ======\n",
    "#                 if gf.H is not None:\n",
    "#                     #Compute flux\n",
    "#                     gf.Q = gf.H * debris_prms.v_col_f * np.array([gf.vx, gf.vy])\n",
    "#                     #Note: np.gradient returns derivatives relative to axis number, so (y, x) in this case\n",
    "#                     #Want x-derivative of x component\n",
    "#                     gf.divQ = np.gradient(gf.Q[0])[1] + np.gradient(gf.Q[1])[0]\n",
    "# #                     gf.divQ = gf.H*(np.gradient(v_col_f*gf.vx)[1] + np.gradient(v_col_f*gf.vy)[0]) \\\n",
    "# #                             + v_col_f*gf.vx*(np.gradient(gf.H)[1]) + v_col_f*gf.vy*(np.gradient(gf.H)[0])\n",
    "#                     #Should smooth divQ, better handling of data gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OLD CHECK DEM FOR ERRORS AND REPLACE SCRIPT (no longer needed with OGGM processing) =====\n",
    "#         #Create buffer around glacier polygon\n",
    "#         glac_geom_buff = gf.glac_geom.Buffer(debris_prms.buff_dist)\n",
    "#         #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#         glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "        \n",
    "#             # ds masks\n",
    "#             ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#             dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "#             dems_mask = dem1.mask\n",
    "#             if verbose:\n",
    "#                 print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#             #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#             static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#             static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "        \n",
    "        \n",
    "#             # Check if DEM has huge errors or not - replace if necessary\n",
    "#             if input.roi in ['01']:\n",
    "\n",
    "#                 gf.z1_check = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "#                 if gf.z1_check.min() < 0:\n",
    "\n",
    "#                     # Add backup DEM for regions with known poor quality (ex. Alaska)\n",
    "#                     print('switching DEMs')\n",
    "#                     fn_dict['z1_backup'] = input.z1_backup_dict[input.roi]\n",
    "#                     # Warp everything to common res/extent/proj (a second time)\n",
    "#                     ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, \\\n",
    "#                             extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "#                             r='cubic')\n",
    "#                     ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "#                     if verbose:\n",
    "#                         print(ds_list)\n",
    "#                         print(fn_dict.keys())\n",
    "\n",
    "#                     # ds masks\n",
    "#                     ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#                     dem1 = np.ma.masked_less_equal(ds_list_masked[-1], 0)\n",
    "#                     dems_mask = dem1.mask\n",
    "#                     if verbose:\n",
    "#                         print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#                     #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#                     static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#                     static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "#                     #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#                     glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1_backup'])\n",
    "#                     gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=glac_geom_mask)\n",
    "#                     #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "#                     # Debris cover\n",
    "#                     dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "#                     gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=dc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_shp = gpd.read_file('/Users/davidrounce/Documents/Dave_Rounce/HiMAT/qgis_himat/rgi60_HMA.shp')\n",
    "hma_fp = '/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/output/mb_bins_all/csv/HMA/'\n",
    "rgiids = []\n",
    "for i in os.listdir(hma_fp):\n",
    "    if i.endswith('.csv'):\n",
    "        rgiids.append('RGI60-' + i.split('_')[0])\n",
    "rgiids = sorted(rgiids)\n",
    "\n",
    "rgiids_all = list(rgi_shp.RGIId.values)\n",
    "rgiids_missing = list(set(rgiids_all) - set(rgiids))\n",
    "\n",
    "rgiids_missing_idx = []\n",
    "for nglac, x in enumerate(rgi_shp.RGIId.values):\n",
    "    if x in rgiids_missing:\n",
    "        rgiids_missing_idx.append(nglac)\n",
    "        \n",
    "rgi_shp_missing = rgi_shp.loc[rgiids_missing_idx,:]\n",
    "# rgi_shp_missing\n",
    "\n",
    "output_fn = '/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/output/hma_missing.shp'\n",
    "rgi_shp_missing.to_file(output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
