{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)\n",
    "\n",
    "def nearest_nonzero_idx(a,x,y):\n",
    "    r,c = np.nonzero(a)\n",
    "    min_idx = ((r - x)**2 + (c - y)**2).argmin()\n",
    "    return r[min_idx], c[min_idx]\n",
    "\n",
    "\n",
    "def maskedarray_gt(data, value, set_value=None):\n",
    "    \"\"\" Greater than operation on masked array to avoid warning errors \"\"\"\n",
    "    if set_value is None:\n",
    "        set_value = value\n",
    "    data = np.nan_to_num(data,0)\n",
    "    data[data > value] = set_value\n",
    "    return data\n",
    "\n",
    "\n",
    "def maskedarray_lt(data, value, set_value=None):\n",
    "    \"\"\" Less than operation on masked array to avoid warning errors \"\"\"\n",
    "    if set_value is None:\n",
    "        set_value = value\n",
    "    data = np.nan_to_num(data,0)\n",
    "    data[data < value] = value\n",
    "    return data\n",
    "\n",
    "\n",
    "def emergence_pixels(gf, vel_x_raw, vel_y_raw, icethickness_raw, xres, yres, \n",
    "                     vel_min=0, max_velocity=600, vel_depth_avg_factor=0.8, option_border=1,\n",
    "                     positive_is_east=True, positive_is_north=True, constant_icethickness=False, debug=True):\n",
    "    \"\"\" Compute the emergence velocity using an ice flux approach\n",
    "    \"\"\"\n",
    "    # Glacier mask\n",
    "    glac_mask = np.zeros(vel_x_raw.shape) + 1\n",
    "    glac_mask[gf.z1.mask] = 0\n",
    "    \n",
    "    # Modify vel_y by multiplying velocity by -1 such that matrix operations agree with flow direction\n",
    "    #    Specifically, a negative y velocity means the pixel is flowing south.\n",
    "    #    However, if you were to subtract that value from the rows, it would head north in the matrix.\n",
    "    #    This is due to the fact that the number of rows start at 0 at the top.\n",
    "    #    Therefore, multipylying by -1 aligns the matrix operations with the flow direction\n",
    "    if positive_is_north:\n",
    "        vel_y = -1*vel_y_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_y = vel_y_raw * vel_depth_avg_factor\n",
    "    if positive_is_east:\n",
    "        vel_x = vel_x_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_x = -1*vel_x_raw * vel_depth_avg_factor\n",
    "    vel_total = (vel_y**2 + vel_x**2)**0.5\n",
    "    # Ice thickness\n",
    "    icethickness = icethickness_raw.copy()\n",
    "    if constant_icethickness:\n",
    "        icethickness[:,:] = 1\n",
    "        icethickness = icethickness * glac_mask\n",
    "#     print('mean ice thickness:', np.round(icethickness.mean(),0), 'm')\n",
    "    # Compute the initial volume\n",
    "    volume_initial = icethickness * (xres * yres)\n",
    "    pix_maxres = xres\n",
    "    if yres > pix_maxres:\n",
    "        pix_maxres = yres\n",
    "    # Quality control options:\n",
    "    # Apply a border based on the max specified velocity to prevent errors associated with pixels going out of bounds\n",
    "    if option_border == 1:\n",
    "        border = int(max_velocity / pix_maxres) + 1\n",
    "        for r in range(vel_x.shape[0]):\n",
    "            for c in range(vel_x.shape[1]):\n",
    "                if (r < border) | (r >= vel_x.shape[0] - border) | (c < border) | (c >= vel_x.shape[1] - border):\n",
    "                    vel_x[r,c] = 0\n",
    "                    vel_y[r,c] = 0\n",
    "    # Minimum/maximum velocity bounds\n",
    "    vel_x[vel_total < vel_min] = 0\n",
    "    vel_y[vel_total < vel_min] = 0\n",
    "    vel_x[vel_total > max_velocity] = 0\n",
    "    vel_y[vel_total > max_velocity] = 0\n",
    "#     # Remove clusters of high velocity on stagnant portions of glaciers due to feature tracking of ice cliffs and ponds\n",
    "#     if option_stagnantbands == 1:\n",
    "#         vel_x[bands <= stagnant_band] = 0\n",
    "#         vel_y[bands <= stagnant_band] = 0        \n",
    "    # Compute displacement in units of pixels\n",
    "    vel_x_pix = vel_x / xres\n",
    "    vel_y_pix = vel_y / yres\n",
    "    # Compute the displacement and fraction of pixels moved for all columns (x-axis)\n",
    "    # col_x1 is the number of columns to the closest pixel receiving ice [ex. 2.6 returns 2, -2.6 returns -2]\n",
    "    #    int() automatically rounds towards zero\n",
    "    col_x1 = vel_x_pix.astype(int)\n",
    "    # col_x2 is the number of columns to the further pixel receiving ice [ex. 2.6 returns 3, -2.6 returns -3]\n",
    "    #    np.sign() returns a value of 1 or -1, so it's adding 1 pixel away from zero\n",
    "    col_x2 = (vel_x_pix + np.sign(vel_x_pix)).astype(int)\n",
    "    # rem_x2 is the fraction of the pixel that remains in the further pixel (col_x2) [ex. 2.6 returns 0.6, -2.6 returns 0.6]\n",
    "    #    np.sign() returns a value of 1 or -1, so multiplying by that ensures you have a positive value\n",
    "    #    then when you take the remainder using \"% 1\", you obtain the desired fraction\n",
    "    rem_x2 = np.multiply(np.sign(vel_x_pix), vel_x_pix) % 1\n",
    "    # rem_x1 is the fraction of the pixel that remains in the closer pixel (col_x1) [ex. 2.6 returns 0.4, -2.6 returns 0.4]\n",
    "    rem_x1 = 1 - rem_x2\n",
    "    # Repeat the displacement and fraction computations for all rows (y-axis)\n",
    "    row_y1 = vel_y_pix.astype(int)\n",
    "    row_y2 = (vel_y_pix + np.sign(vel_y_pix)).astype(int)\n",
    "    rem_y2 = np.multiply(np.sign(vel_y_pix), vel_y_pix) % 1\n",
    "    rem_y1 = 1 - rem_y2\n",
    "          \n",
    "    # Compute the mass flux for each pixel\n",
    "    volume_final = np.zeros(volume_initial.shape)\n",
    "    for r in range(vel_x.shape[0]):\n",
    "        for c in range(vel_x.shape[1]):\n",
    "            volume_final[r+row_y1[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x1[r,c]] + rem_y1[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x1[r,c]] + rem_y2[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y1[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x2[r,c]] + rem_y1[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x2[r,c]] + rem_y2[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "         \n",
    "    # Redistribute off-glacier volume back onto the nearest pixel on the glacier\n",
    "    offglac_row, offglac_col = np.where((glac_mask == 0) & (volume_final > 0))\n",
    "    for nidx in range(0,len(offglac_row)):\n",
    "        nrow = offglac_row[nidx]\n",
    "        ncol = offglac_col[nidx]\n",
    "        ridx, cidx = nearest_nonzero_idx(glac_mask, nrow, ncol)\n",
    "        # Add off-glacier volume back onto nearest pixel on glacier\n",
    "        volume_final[ridx,cidx] += volume_final[nrow,ncol]\n",
    "        volume_final[nrow,ncol] = 0\n",
    "            \n",
    "    # Check that mass is conserved (threshold = 0.1 m x pixel_size**2)\n",
    "    if debug:\n",
    "        print('Mass is conserved?', np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() < 0.01)\n",
    "        print(np.round(np.absolute(volume_final.sum() - volume_initial.sum()),1), \n",
    "              np.round(np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() * 100,2), '%')\n",
    "        \n",
    "    if np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() > 0.01:\n",
    "        print('MASS NOT CONSERVED FOR EMERGENCE VELOCITY')\n",
    "    # Final ice thickness\n",
    "    icethickness_final = volume_final / (xres * yres)\n",
    "    # Emergence velocity\n",
    "    emergence_velocity = icethickness_final - icethickness\n",
    "    return emergence_velocity\n",
    "\n",
    "\n",
    "\n",
    "class GlacFeat:\n",
    "    def __init__(self, feat, glacname_fieldname, glacnum_fieldname):\n",
    "\n",
    "        self.glacname = feat.GetField(glacname_fieldname)\n",
    "        if self.glacname is None:\n",
    "            self.glacname = \"\"\n",
    "        else:\n",
    "            #RGI has some nonstandard characters\n",
    "            #self.glacname = self.glacname.decode('unicode_escape').encode('ascii','ignore')\n",
    "            #glacname = re.sub(r'[^\\x00-\\x7f]',r'', glacname)\n",
    "            self.glacname = re.sub(r'\\W+', '', self.glacname)\n",
    "            self.glacname = self.glacname.replace(\" \", \"\")\n",
    "            self.glacname = self.glacname.replace(\"_\", \"\")\n",
    "            self.glacname = self.glacname.replace(\"/\", \"\")\n",
    "\n",
    "        self.glacnum = feat.GetField(glacnum_fieldname)\n",
    "        fn = feat.GetDefnRef().GetName()\n",
    "        #RGIId (String) = RGI50-01.00004\n",
    "        self.glacnum = '%0.5f' % float(self.glacnum.split('-')[-1])\n",
    "\n",
    "        if self.glacname:\n",
    "            self.feat_fn = \"%s_%s\" % (self.glacnum, self.glacname)\n",
    "        else:\n",
    "            self.feat_fn = str(self.glacnum)\n",
    "\n",
    "        self.glac_geom_orig = geolib.geom_dup(feat.GetGeometryRef())\n",
    "        self.glac_geom = geolib.geom_dup(self.glac_geom_orig)\n",
    "        #Hack to deal with fact that this is not preserved in geom when loaded from pickle on disk\n",
    "        self.glac_geom_srs_wkt = self.glac_geom.GetSpatialReference().ExportToWkt()\n",
    "\n",
    "        #Attributes written by mb_calc\n",
    "        self.z1 = None\n",
    "        self.z1_hs = None\n",
    "        self.z1_stats = None\n",
    "        self.z1_ela = None\n",
    "        self.z2 = None\n",
    "        self.z2_hs = None\n",
    "        self.z2_stats = None\n",
    "        self.z2_ela = None\n",
    "        self.z2_aspect = None\n",
    "        self.z2_aspect_stats = None\n",
    "        self.z2_slope = None\n",
    "        self.z2_slope_stats = None\n",
    "        self.res = None\n",
    "        self.dhdt = None\n",
    "        self.mb = None\n",
    "        self.mb_mean = None\n",
    "        self.t1 = None\n",
    "        self.t2 = None\n",
    "        self.dt = None\n",
    "        self.t1_mean = None\n",
    "        self.t2_mean = None\n",
    "        self.dt_mean = None\n",
    "\n",
    "        self.H = None\n",
    "        self.H_mean = np.nan\n",
    "        self.vx = None\n",
    "        self.vy = None\n",
    "        self.vm = None\n",
    "        self.vm_mean = np.nan\n",
    "        self.divQ = None\n",
    "        self.emvel = None\n",
    "        self.debris_class = None\n",
    "        self.debris_thick = None\n",
    "        self.debris_thick_mean = np.nan\n",
    "        self.perc_clean = np.nan\n",
    "        self.perc_debris = np.nan\n",
    "        self.perc_pond = np.nan\n",
    "        self.dc_area = None\n",
    "\n",
    "    def geom_srs_update(self, srs=None):\n",
    "        if self.glac_geom.GetSpatialReference() is None:\n",
    "            if srs is None:\n",
    "                srs = osr.SpatialReference()\n",
    "                srs.ImportFromWkt(self.glac_geom_srs_wkt)\n",
    "            self.glac_geom.AssignSpatialReference(srs)\n",
    "\n",
    "    def geom_attributes(self, srs=None):\n",
    "        self.geom_srs_update()\n",
    "        if srs is not None:\n",
    "            #Should reproject here to equal area, before geom_attributes\n",
    "            #self.glac_geom.AssignSpatialReference(glac_shp_srs)\n",
    "            #self.glac_geom_local = geolib.geom2localortho(self.glac_geom)\n",
    "            geolib.geom_transform(self.glac_geom, srs)\n",
    "\n",
    "        self.glac_geom_extent = geolib.geom_extent(self.glac_geom)\n",
    "        self.glac_area = self.glac_geom.GetArea()\n",
    "        self.glac_area_km2 = self.glac_area / 1E6\n",
    "        self.cx, self.cy = self.glac_geom.Centroid().GetPoint_2D()\n",
    "        \n",
    "        \n",
    "#RGI uses 50 m bins\n",
    "def hist_plot(gf, bin_width=50.0, dz_clim=(-2.0, 2.0), exportcsv=True, csv_ending='', mb_df=None):\n",
    "    #print(\"Generating histograms\")\n",
    "    #Create bins for full range of input data and specified bin width\n",
    "\n",
    "    #NOTE: these counts/areas are for valid pixels only\n",
    "    #Not necessarily a true representation of actual glacier hypsometry\n",
    "    #Need a void-filled DEM for this\n",
    "    if mb_df is not None:\n",
    "        # Align bins with mass balance data\n",
    "        bin_center_min = mb_df.loc[0,'# bin_center_elev_m']\n",
    "        while bin_center_min > gf.z1.min() + bin_width/2:\n",
    "            bin_center_min -= mb_bin_size\n",
    "        bin_center_max = mb_df['# bin_center_elev_m'].values[-1]\n",
    "        while bin_center_max < gf.z1.max():\n",
    "            bin_center_max += mb_bin_size    \n",
    "        z_bin_centers = np.arange(bin_center_min, bin_center_max + mb_bin_size/2, mb_bin_size)\n",
    "        z_bin_edges = np.arange(bin_center_min - mb_bin_size / 2, bin_center_max + mb_bin_size, mb_bin_size)\n",
    "    else:\n",
    "        z_bin_edges, z_bin_centers = malib.get_bins(gf.z1, bin_width)\n",
    "        \n",
    "    #Need to compress here, otherwise histogram uses masked values!\n",
    "    z1_bin_counts, z1_bin_edges = np.histogram(gf.z1.compressed(), bins=z_bin_edges)\n",
    "    z1_bin_areas = z1_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "    #RGI standard is integer thousandths of glaciers total area\n",
    "    #Should check to make sure sum of bin areas equals total area\n",
    "    #z1_bin_areas_perc = 100. * z1_bin_areas / np.sum(z1_bin_areas)\n",
    "    z1_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "    #If we only have one elevation grid with dhdt\n",
    "    if gf.z2 is not None:\n",
    "        z2_bin_counts, z2_bin_edges = np.histogram(gf.z2.compressed(), bins=z_bin_edges)\n",
    "        z2_bin_areas = z2_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "        #z2_bin_areas_perc = 100. * z2_bin_areas / np.sum(z2_bin_areas)\n",
    "        z2_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "    else:\n",
    "        z2_bin_counts = z1_bin_counts\n",
    "        z2_bin_edges = z1_bin_edges\n",
    "        z2_bin_areas = z1_bin_areas\n",
    "        z2_bin_areas_perc = z1_bin_areas_perc\n",
    "        \n",
    "    if gf.dc_area is not None:\n",
    "#         z_bin_edges, z_bin_centers = malib.get_bins(gf.z1, bin_width)\n",
    "#         #Need to compress here, otherwise histogram uses masked values!\n",
    "#         z1_bin_counts, z1_bin_edges = np.histogram(gf.z1.compressed(), bins=z_bin_edges)\n",
    "#         z1_bin_areas = z1_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "#         #RGI standard is integer thousandths of glaciers total area\n",
    "#         #Should check to make sure sum of bin areas equals total area\n",
    "#         #z1_bin_areas_perc = 100. * z1_bin_areas / np.sum(z1_bin_areas)\n",
    "#         z1_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "        \n",
    "# #         dc_bin_edges, dc_bin_centers = malib.get_bins(gf.dc_area, bin_width)\n",
    "        dc_bin_counts, dc_bin_edges = np.histogram(gf.dc_area.compressed(), bins=z_bin_edges)\n",
    "        dc_bin_areas = dc_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "        #RGI standard is integer thousandths of glaciers total area\n",
    "        dc_bin_areas_perc = 100. * (dc_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "    #Create arrays to store output\n",
    "    slope_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "    slope_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    aspect_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "    aspect_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.dhdt is not None:\n",
    "        mb_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        np.ma.set_fill_value(mb_bin_med, np.nan)\n",
    "        mb_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "        mb_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "        mb_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_med = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_count = np.ma.masked_all_like(mb_bin_med)\n",
    "    if gf.vm is not None:\n",
    "        vm_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        vm_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.H is not None:\n",
    "        H_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "        H_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.emvel is not None:\n",
    "        emvel_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.debris_class is not None:\n",
    "#         perc_clean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         perc_debris = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         perc_pond = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_clean_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_debris_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_pond_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "\n",
    "#         gf.dhdt_clean = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 1).data))\n",
    "#         gf.dhdt_debris = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 2).data))\n",
    "#         gf.dhdt_pond = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 3).data))\n",
    "\n",
    "    if gf.debris_thick_ts is not None:\n",
    "        debris_thick_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.meltfactor_ts is not None:\n",
    "        meltfactor_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        meltfactor_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "\n",
    "    #Bin sample count must be greater than this value\n",
    "    min_bin_samp_count = 9\n",
    "\n",
    "    #Loop through each bin and extract stats\n",
    "    idx = np.digitize(gf.z1, z_bin_edges)\n",
    "    for bin_n in range(z_bin_centers.size):\n",
    "        if gf.dhdt is not None:\n",
    "            mb_bin_samp = gf.mb_map[(idx == bin_n+1)]\n",
    "            if mb_bin_samp.count() > min_bin_samp_count:\n",
    "                mb_bin_med[bin_n] = malib.fast_median(mb_bin_samp)\n",
    "                mb_bin_mad[bin_n] = malib.mad(mb_bin_samp)\n",
    "                mb_bin_mean[bin_n] = mb_bin_samp.mean()\n",
    "                mb_bin_std[bin_n] = mb_bin_samp.std()\n",
    "            dhdt_bin_samp = gf.dhdt[(idx == bin_n+1)]\n",
    "            if dhdt_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_bin_med[bin_n] = malib.fast_median(dhdt_bin_samp)\n",
    "                dhdt_bin_mad[bin_n] = malib.mad(dhdt_bin_samp)\n",
    "                dhdt_bin_mean[bin_n] = dhdt_bin_samp.mean()\n",
    "                dhdt_bin_std[bin_n] = dhdt_bin_samp.std()\n",
    "                dhdt_bin_count[bin_n] = dhdt_bin_samp.count()\n",
    "        if gf.debris_thick is not None:\n",
    "            debris_thick_bin_samp = gf.debris_thick[(idx == bin_n+1)]\n",
    "            if debris_thick_bin_samp.size > min_bin_samp_count:\n",
    "                debris_thick_med[bin_n] = malib.fast_median(debris_thick_bin_samp)\n",
    "                debris_thick_mad[bin_n] = malib.mad(debris_thick_bin_samp)\n",
    "        \n",
    "        if gf.debris_thick_ts is not None:\n",
    "            debris_thick_ts_bin_samp = gf.debris_thick_ts[(idx == bin_n+1)]\n",
    "            if debris_thick_ts_bin_samp.size > min_bin_samp_count:\n",
    "                debris_thick_ts_med[bin_n] = malib.fast_median(debris_thick_ts_bin_samp)\n",
    "                debris_thick_ts_mad[bin_n] = malib.mad(debris_thick_ts_bin_samp)\n",
    "        if gf.meltfactor_ts is not None:\n",
    "            meltfactor_ts_bin_samp = gf.meltfactor_ts[(idx == bin_n+1)]\n",
    "            if meltfactor_ts_bin_samp.size > min_bin_samp_count:\n",
    "                meltfactor_ts_med[bin_n] = malib.fast_median(meltfactor_ts_bin_samp)\n",
    "                meltfactor_ts_mad[bin_n] = malib.mad(meltfactor_ts_bin_samp)\n",
    "        \n",
    "        if gf.debris_class is not None:\n",
    "            debris_class_bin_samp = gf.debris_class[(idx == bin_n+1)]\n",
    "            dhdt_clean_bin_samp = gf.dhdt_clean[(idx == bin_n+1)]\n",
    "            dhdt_debris_bin_samp = gf.dhdt_debris[(idx == bin_n+1)]\n",
    "            dhdt_pond_bin_samp = gf.dhdt_pond[(idx == bin_n+1)]\n",
    "            if debris_class_bin_samp.count() > min_bin_samp_count:\n",
    "                perc_clean[bin_n] = 100. * (debris_class_bin_samp == 1).sum()/debris_class_bin_samp.count()\n",
    "                perc_debris[bin_n] = 100. * (debris_class_bin_samp == 2).sum()/debris_class_bin_samp.count()\n",
    "                perc_pond[bin_n] = 100. * (debris_class_bin_samp == 3).sum()/debris_class_bin_samp.count()\n",
    "            if dhdt_clean_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_clean_bin_med[bin_n] = malib.fast_median(dhdt_clean_bin_samp)\n",
    "            if dhdt_debris_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_debris_bin_med[bin_n] = malib.fast_median(dhdt_debris_bin_samp)\n",
    "            if dhdt_pond_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_pond_bin_med[bin_n] = malib.fast_median(dhdt_pond_bin_samp)\n",
    "        if gf.vm is not None:\n",
    "            vm_bin_samp = gf.vm[(idx == bin_n+1)]\n",
    "            if vm_bin_samp.size > min_bin_samp_count:\n",
    "                vm_bin_med[bin_n] = malib.fast_median(vm_bin_samp)\n",
    "                vm_bin_mad[bin_n] = malib.mad(vm_bin_samp)\n",
    "        if gf.H is not None:\n",
    "            H_bin_samp = gf.H[(idx == bin_n+1)]\n",
    "            if H_bin_samp.size > min_bin_samp_count:\n",
    "                H_bin_mean[bin_n] = H_bin_samp.mean()\n",
    "                H_bin_std[bin_n] = H_bin_samp.std()\n",
    "        if gf.emvel is not None:\n",
    "            emvel_bin_samp = gf.emvel[(idx == bin_n+1)]\n",
    "            if emvel_bin_samp.size > min_bin_samp_count:\n",
    "                emvel_bin_mean[bin_n] = emvel_bin_samp.mean()\n",
    "                emvel_bin_std[bin_n] = emvel_bin_samp.std()\n",
    "                emvel_bin_med[bin_n] = malib.fast_median(emvel_bin_samp)\n",
    "                emvel_bin_mad[bin_n] = malib.mad(emvel_bin_samp)\n",
    "        slope_bin_samp = gf.z1_slope[(idx == bin_n+1)]\n",
    "        if slope_bin_samp.size > min_bin_samp_count:\n",
    "            slope_bin_med[bin_n] = malib.fast_median(slope_bin_samp)\n",
    "            slope_bin_mad[bin_n] = malib.mad(slope_bin_samp)\n",
    "        aspect_bin_samp = gf.z1_aspect[(idx == bin_n+1)]\n",
    "        if aspect_bin_samp.size > min_bin_samp_count:\n",
    "            aspect_bin_med[bin_n] = malib.fast_median(aspect_bin_samp)\n",
    "            aspect_bin_mad[bin_n] = malib.mad(aspect_bin_samp)\n",
    "\n",
    "    if gf.dhdt is not None:\n",
    "        dhdt_bin_areas = dhdt_bin_count * gf.res[0] * gf.res[1] / 1E6\n",
    "        #dhdt_bin_areas_perc = 100. * dhdt_bin_areas / np.sum(dhdt_bin_areas)\n",
    "        dhdt_bin_areas_perc = 100. * (dhdt_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "    outbins_header = 'bin_center_elev_m, z1_bin_count_valid, z1_bin_area_valid_km2, z1_bin_area_perc, z2_bin_count_valid, z2_bin_area_valid_km2, z2_bin_area_perc, slope_bin_med, aspect_bin_med'\n",
    "    fmt = '%0.1f, %0.0f, %0.3f, %0.2f, %0.0f, %0.3f, %0.2f, %0.2f, %0.2f'\n",
    "    outbins = [z_bin_centers, z1_bin_counts, z1_bin_areas, z1_bin_areas_perc, z2_bin_counts, z2_bin_areas, z2_bin_areas_perc, slope_bin_med, aspect_bin_med]\n",
    "    if gf.dhdt is not None:\n",
    "        outbins_header += ', dhdt_bin_count, dhdt_bin_area_valid_km2, dhdt_bin_area_perc, dhdt_bin_med_ma, dhdt_bin_mad_ma, dhdt_bin_mean_ma, dhdt_bin_std_ma, mb_bin_med_mwea, mb_bin_mad_mwea, mb_bin_mean_mwea, mb_bin_std_mwea'\n",
    "        fmt += ', %0.0f, %0.3f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "        outbins.extend([dhdt_bin_count, dhdt_bin_areas, dhdt_bin_areas_perc, dhdt_bin_med, dhdt_bin_mad, dhdt_bin_mean, dhdt_bin_std, \\\n",
    "                        mb_bin_med, mb_bin_mad, mb_bin_mean, mb_bin_std])\n",
    "    if gf.dc_area is not None:\n",
    "        outbins_header += ', dc_bin_count_valid, dc_bin_area_valid_km2, dc_bin_area_perc'\n",
    "        fmt += ', %0.0f, %0.3f, %0.2f'\n",
    "        outbins.extend([dc_bin_counts, dc_bin_areas, dc_bin_areas_perc])\n",
    "#         outbins.extend([z1_bin_counts, z1_bin_areas, z1_bin_areas_perc])\n",
    "        \n",
    "        \n",
    "    if gf.debris_thick is not None:\n",
    "        outbins_header += ', debris_thick_med_m, debris_thick_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        debris_thick_med[debris_thick_med == -(np.inf)] = 0.00\n",
    "        debris_thick_mad[debris_thick_mad == -(np.inf)] = 0.00\n",
    "        outbins.extend([debris_thick_med, debris_thick_mad])\n",
    "    \n",
    "    if gf.debris_thick_ts is not None:\n",
    "        outbins_header += ',debris_thick_ts_med_m,debris_thick_ts_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        debris_thick_ts_med[debris_thick_ts_med == -(np.inf)] = 0.00\n",
    "        debris_thick_ts_mad[debris_thick_ts_mad == -(np.inf)] = 0.00\n",
    "        outbins.extend([debris_thick_ts_med, debris_thick_ts_mad])\n",
    "    if gf.meltfactor_ts is not None:\n",
    "        outbins_header += ',meltfactor_ts_med_m,meltfactor_ts_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        meltfactor_ts_med[meltfactor_ts_med == -(np.inf)] = 1\n",
    "        meltfactor_ts_med[meltfactor_ts_med > 1] = 1\n",
    "        meltfactor_ts_med[meltfactor_ts_med <= 0] = 1\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad == -(np.inf)] = 0\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad > 1] = 0\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad <= 0] = 0\n",
    "        outbins.extend([meltfactor_ts_med, meltfactor_ts_mad])\n",
    "    \n",
    "    if gf.debris_class is not None:\n",
    "        outbins_header += ', perc_debris, perc_pond, perc_clean, dhdt_debris_med, dhdt_pond_med, dhdt_clean_med'\n",
    "        fmt += ', %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "        outbins.extend([perc_debris, perc_pond, perc_clean, dhdt_debris_bin_med, dhdt_pond_bin_med, dhdt_clean_bin_med])\n",
    "    if gf.vm is not None:\n",
    "        outbins_header += ', vm_med, vm_mad'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        outbins.extend([vm_bin_med, vm_bin_mad])\n",
    "    if gf.H is not None:\n",
    "        outbins_header += ', H_mean, H_std'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        outbins.extend([H_bin_mean, H_bin_std])\n",
    "#         outbins_header += ', H_mean, H_std, emvel_mean, emvel_std'\n",
    "#         fmt += ', %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "#         outbins.extend([H_bin_mean, H_bin_std, emvel_bin_mean, emvel_bin_std])\n",
    "\n",
    "    if gf.emvel is not None:\n",
    "        outbins_header += ', emvel_mean, emvel_std, emvel_med, emvel_mad'\n",
    "        fmt += ', %0.3f, %0.3f, %0.3f, %0.3f'\n",
    "        outbins.extend([emvel_bin_mean, emvel_bin_std, emvel_bin_med, emvel_bin_mad])\n",
    "    \n",
    "    outbins = np.ma.array(outbins).T.astype('float32')\n",
    "    np.ma.set_fill_value(outbins, np.nan)\n",
    "    outbins = outbins.filled(np.nan)\n",
    "    \n",
    "    outbins_df = pd.DataFrame(outbins, columns=outbins_header.split(','))\n",
    "    outbins_df['debris_perc'] = outbins_df[' dc_bin_count_valid'] / outbins_df[' z1_bin_count_valid'] * 100\n",
    "    \n",
    "    if mb_df is not None:\n",
    "        # ADD MASS BALANCE DATA\n",
    "        mb_df = mb_df[np.isfinite(mb_df['# bin_center_elev_m'])]\n",
    "        mb_df.reset_index(inplace=True, drop=True)\n",
    "        # start index for merge\n",
    "        if mb_df.loc[0,'# bin_center_elev_m'] >= outbins_df.loc[0,'bin_center_elev_m']:\n",
    "            mb_df_idx1 = 0\n",
    "            outbins_idx1 = np.where(outbins_df['bin_center_elev_m'] == mb_df.loc[0,'# bin_center_elev_m'])[0][0]\n",
    "        else:\n",
    "            outbins_idx1 = 0\n",
    "            mb_df_idx1 = np.where(outbins_df.loc[0,'bin_center_elev_m'] == mb_df['# bin_center_elev_m'])[0][0]\n",
    "    #     print('idx1:', \n",
    "    #           '\\noutbins:', outbins_idx1, outbins_df.loc[outbins_idx1,'bin_center_elev_m'],\n",
    "    #           '\\ndfbins:', mb_df_idx1, mb_df.loc[mb_df_idx1,'# bin_center_elev_m'])\n",
    "        # end index for merge\n",
    "        if outbins_df.loc[outbins_df.shape[0]-1,'bin_center_elev_m'] >= mb_df.loc[mb_df.shape[0]-1,'# bin_center_elev_m']:\n",
    "            outbins_idx2 = np.where(outbins_df['bin_center_elev_m'] == mb_df.loc[mb_df.shape[0]-1,'# bin_center_elev_m'])[0][0]\n",
    "            mb_df_idx2 = mb_df.shape[0]-1\n",
    "        else:\n",
    "            outbins_idx2 = outbins_df.shape[0]-1\n",
    "            mb_df_idx2 = np.where(outbins_df.loc[outbins_df.shape[0]-1,'bin_center_elev_m'] == mb_df['# bin_center_elev_m'])[0][0]\n",
    "    #     print('idx2:', \n",
    "    #           '\\noutbins:', outbins_idx2, outbins_df.loc[outbins_idx2,'bin_center_elev_m'],\n",
    "    #           '\\ndfbins:', mb_df_idx2, mb_df.loc[mb_df_idx2,'# bin_center_elev_m'])\n",
    "        outbins_df[' mb_bin_mean_mwea'] = np.nan\n",
    "        outbins_df[' mb_bin_std_mwea'] = np.nan\n",
    "        outbins_df[' mb_bin_area_valid_km2'] = np.nan\n",
    "        outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_mean_mwea'] = mb_df.loc[mb_df_idx1:mb_df_idx2+1,' mb_bin_mean_mwea']\n",
    "        outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_std_mwea'] = mb_df.loc[mb_df_idx1:mb_df_idx2+1,' mb_bin_std_mwea']\n",
    "        outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_area_valid_km2'] = mb_df.loc[mb_df_idx1:mb_df_idx2+1,' z1_bin_area_valid_km2']\n",
    "        try:\n",
    "            outbins_df['startyear'] = mb_df.loc[mb_df_idx1,'startyear']\n",
    "            outbins_df['endyear'] = mb_df.loc[mb_df_idx1,'endyear']\n",
    "        except:\n",
    "            outbins_df['startyear'] = 2000\n",
    "            outbins_df['endyear'] = 2012\n",
    "    \n",
    "    if exportcsv:\n",
    "        if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "            outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "        else:\n",
    "            outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "        outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "#         np.savetxt(outbins_fn, outbins, fmt=fmt, delimiter=',', header=outbins_header)\n",
    "    \n",
    "    outbins_df = pd.DataFrame(outbins, columns=outbins_header.split(','))\n",
    "    \n",
    "    return outbins_df, z_bin_edges\n",
    "#     return z_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy import ndimage\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "# from imview.lib import pltlib\n",
    "\n",
    "\n",
    "import globaldebris_input as input\n",
    "\n",
    "#INPUT\n",
    "# topdir='/Users/davidrounce/Documents/Dave_Rounce/HiMAT/DEMs/'\n",
    "#Output directory\n",
    "# outdir = '/Users/davidrounce/Documents/Dave_Rounce/HiMAT/DEMs/Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "\n",
    "outdir = input.output_fp + 'mb_bins/'\n",
    "outdir_fig = outdir + '/figures/'\n",
    "outdir_csv = outdir + '/csv/'\n",
    "\n",
    "if os.path.exists(outdir) == False:\n",
    "    os.makedirs(outdir)\n",
    "if os.path.exists(input.glac_shp_proj_fp) == False:\n",
    "    os.makedirs(input.glac_shp_proj_fp)\n",
    "if os.path.exists(outdir_csv) == False:\n",
    "    os.makedirs(outdir_csv)\n",
    "if os.path.exists(outdir_fig) == False:\n",
    "    os.makedirs(outdir_fig)\n",
    "\n",
    "\n",
    "csv_ending = '_mb_bins_wdc_emvel_offset.csv'\n",
    "verbose = False\n",
    "close_fig = True\n",
    "extra_layers = True\n",
    "\n",
    "# #RGI inventory\n",
    "# glac_str = '15.03473' # Ngozumpa\n",
    "\n",
    "# met_sample_fullfn = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/' + \n",
    "#                      'rounce_model/hma_data/' + input.roi + '_ERA5-metdata_2000_2018-z.nc')\n",
    "# debris_elevstats_fullfn = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/' +\n",
    "#                            'rounce_model/hma_data/' + input.roi + '_debris_elevstats.nc')\n",
    "\n",
    "# glac_shp_fn_dict = {'13':topdir + '../RGI/rgi60/13_rgi60_CentralAsia/13_rgi60_CentralAsia.shp',\n",
    "#                     '14':topdir + '../RGI/rgi60/14_rgi60_SouthAsiaWest/14_rgi60_SouthAsiaWest.shp',\n",
    "#                     '15':topdir + '../RGI/rgi60/15_rgi60_SouthAsiaEast/15_rgi60_SouthAsiaEast.shp'}\n",
    "\n",
    "# glac_shp_fn = glac_shp_fn_dict[region]\n",
    "# glacfeat_fn = outdir + 'glacfeat_list.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>DC_EndDate</th>\n",
       "      <th>DC_CTSmean</th>\n",
       "      <th>DC_Area_%</th>\n",
       "      <th>layer</th>\n",
       "      <th>path</th>\n",
       "      <th>area_singl</th>\n",
       "      <th>DC_Area_v2</th>\n",
       "      <th>DC_Area__1</th>\n",
       "      <th>geometry</th>\n",
       "      <th>CenLon_360</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-13.00604</td>\n",
       "      <td>G077997E35568N</td>\n",
       "      <td>20020802</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>77.994225</td>\n",
       "      <td>35.576353</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>9.855</td>\n",
       "      <td>5401</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>20.314421</td>\n",
       "      <td>6.274</td>\n",
       "      <td>Fixed geometries_13</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>178920</td>\n",
       "      <td>498099</td>\n",
       "      <td>5.054</td>\n",
       "      <td>MULTIPOLYGON (((77.97991 35.56762, 77.98057 35...</td>\n",
       "      <td>77.994225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RGI60-13.00611</td>\n",
       "      <td>G094298E30361N</td>\n",
       "      <td>19990721</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>94.297566</td>\n",
       "      <td>30.362306</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2.035</td>\n",
       "      <td>4133</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>14.447194</td>\n",
       "      <td>16.629</td>\n",
       "      <td>Fixed geometries_13</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>339441</td>\n",
       "      <td>339441</td>\n",
       "      <td>16.680</td>\n",
       "      <td>POLYGON ((94.29031 30.36096, 94.29062 30.36096...</td>\n",
       "      <td>94.297566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGI60-13.00643</td>\n",
       "      <td>G094928E30607N</td>\n",
       "      <td>19990923</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>94.924077</td>\n",
       "      <td>30.606840</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>28.533</td>\n",
       "      <td>4345</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>15.933888</td>\n",
       "      <td>11.582</td>\n",
       "      <td>Fixed geometries_13</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>2810534</td>\n",
       "      <td>3118320</td>\n",
       "      <td>10.929</td>\n",
       "      <td>MULTIPOLYGON (((94.90493 30.61977, 94.90524 30...</td>\n",
       "      <td>94.924077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RGI60-13.00713</td>\n",
       "      <td>G094777E30796N</td>\n",
       "      <td>19990923</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>94.776375</td>\n",
       "      <td>30.796349</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2.996</td>\n",
       "      <td>5085</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>35.635464</td>\n",
       "      <td>6.459</td>\n",
       "      <td>Fixed geometries_13</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>26102</td>\n",
       "      <td>168314</td>\n",
       "      <td>5.618</td>\n",
       "      <td>MULTIPOLYGON (((94.78556 30.79927, 94.78619 30...</td>\n",
       "      <td>94.776375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RGI60-13.00757</td>\n",
       "      <td>G094632E30674N</td>\n",
       "      <td>19990923</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>94.638690</td>\n",
       "      <td>30.669223</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2.887</td>\n",
       "      <td>4619</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>18.331045</td>\n",
       "      <td>8.324</td>\n",
       "      <td>Fixed geometries_13</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>111620</td>\n",
       "      <td>197136</td>\n",
       "      <td>6.828</td>\n",
       "      <td>MULTIPOLYGON (((94.64190 30.66558, 94.64252 30...</td>\n",
       "      <td>94.638690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>RGI60-15.13061</td>\n",
       "      <td>G097506E28969N</td>\n",
       "      <td>20091014</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>97.510296</td>\n",
       "      <td>28.965740</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4.332</td>\n",
       "      <td>4608</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.183309</td>\n",
       "      <td>23.622</td>\n",
       "      <td>Fixed geometries_15</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>45913</td>\n",
       "      <td>940764</td>\n",
       "      <td>21.717</td>\n",
       "      <td>MULTIPOLYGON (((97.51190 28.95634, 97.51344 28...</td>\n",
       "      <td>97.510296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>RGI60-15.13065</td>\n",
       "      <td>G097526E28985N</td>\n",
       "      <td>20091014</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>97.530043</td>\n",
       "      <td>28.986540</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6.516</td>\n",
       "      <td>4141</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.996689</td>\n",
       "      <td>6.464</td>\n",
       "      <td>Fixed geometries_15</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>38712</td>\n",
       "      <td>385319</td>\n",
       "      <td>5.913</td>\n",
       "      <td>MULTIPOLYGON (((97.53329 28.98960, 97.53360 28...</td>\n",
       "      <td>97.530043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>RGI60-15.13067</td>\n",
       "      <td>G097536E29002N</td>\n",
       "      <td>20091014</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>97.536678</td>\n",
       "      <td>29.002900</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2.788</td>\n",
       "      <td>4445</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.494829</td>\n",
       "      <td>8.651</td>\n",
       "      <td>Fixed geometries_15</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>81025</td>\n",
       "      <td>171952</td>\n",
       "      <td>6.168</td>\n",
       "      <td>MULTIPOLYGON (((97.54210 28.99809, 97.54241 28...</td>\n",
       "      <td>97.536678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>RGI60-15.13092</td>\n",
       "      <td>G097617E28935N</td>\n",
       "      <td>20091014</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>97.619880</td>\n",
       "      <td>28.934007</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4.619</td>\n",
       "      <td>4583</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.035735</td>\n",
       "      <td>15.257</td>\n",
       "      <td>Fixed geometries_15</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>550995</td>\n",
       "      <td>642827</td>\n",
       "      <td>13.917</td>\n",
       "      <td>MULTIPOLYGON (((97.62523 28.92939, 97.62554 28...</td>\n",
       "      <td>97.619880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>RGI60-15.13104</td>\n",
       "      <td>G079456E31052N</td>\n",
       "      <td>20090730</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>79.453200</td>\n",
       "      <td>31.048246</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>22.704</td>\n",
       "      <td>5235</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>66.676066</td>\n",
       "      <td>6.477</td>\n",
       "      <td>Fixed geometries_15</td>\n",
       "      <td>MultiPolygon?crs=EPSG:4326&amp;field=RGIId:string(...</td>\n",
       "      <td>1333229</td>\n",
       "      <td>1333229</td>\n",
       "      <td>5.872</td>\n",
       "      <td>POLYGON ((79.42237 31.07560, 79.42236 31.07614...</td>\n",
       "      <td>79.453200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2958 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               RGIId         GLIMSId   BgnDate   EndDate     CenLon  \\\n",
       "0     RGI60-13.00604  G077997E35568N  20020802  -9999999  77.994225   \n",
       "1     RGI60-13.00611  G094298E30361N  19990721  -9999999  94.297566   \n",
       "2     RGI60-13.00643  G094928E30607N  19990923  -9999999  94.924077   \n",
       "3     RGI60-13.00713  G094777E30796N  19990923  -9999999  94.776375   \n",
       "4     RGI60-13.00757  G094632E30674N  19990923  -9999999  94.638690   \n",
       "...              ...             ...       ...       ...        ...   \n",
       "2953  RGI60-15.13061  G097506E28969N  20091014  -9999999  97.510296   \n",
       "2954  RGI60-15.13065  G097526E28985N  20091014  -9999999  97.530043   \n",
       "2955  RGI60-15.13067  G097536E29002N  20091014  -9999999  97.536678   \n",
       "2956  RGI60-15.13092  G097617E28935N  20091014  -9999999  97.619880   \n",
       "2957  RGI60-15.13104  G079456E31052N  20090730  -9999999  79.453200   \n",
       "\n",
       "         CenLat O1Region O2Region    Area  Zmin  ...  DC_EndDate  DC_CTSmean  \\\n",
       "0     35.576353       13        5   9.855  5401  ...        2017   20.314421   \n",
       "1     30.362306       13        9   2.035  4133  ...        2017   14.447194   \n",
       "2     30.606840       13        9  28.533  4345  ...        2017   15.933888   \n",
       "3     30.796349       13        9   2.996  5085  ...        2017   35.635464   \n",
       "4     30.669223       13        9   2.887  4619  ...        2017   18.331045   \n",
       "...         ...      ...      ...     ...   ...  ...         ...         ...   \n",
       "2953  28.965740       15        3   4.332  4608  ...        2017    6.183309   \n",
       "2954  28.986540       15        3   6.516  4141  ...        2017    7.996689   \n",
       "2955  29.002900       15        3   2.788  4445  ...        2017    7.494829   \n",
       "2956  28.934007       15        3   4.619  4583  ...        2017    8.035735   \n",
       "2957  31.048246       15        1  22.704  5235  ...        2017   66.676066   \n",
       "\n",
       "      DC_Area_%                layer  \\\n",
       "0         6.274  Fixed geometries_13   \n",
       "1        16.629  Fixed geometries_13   \n",
       "2        11.582  Fixed geometries_13   \n",
       "3         6.459  Fixed geometries_13   \n",
       "4         8.324  Fixed geometries_13   \n",
       "...         ...                  ...   \n",
       "2953     23.622  Fixed geometries_15   \n",
       "2954      6.464  Fixed geometries_15   \n",
       "2955      8.651  Fixed geometries_15   \n",
       "2956     15.257  Fixed geometries_15   \n",
       "2957      6.477  Fixed geometries_15   \n",
       "\n",
       "                                                   path  area_singl  \\\n",
       "0     MultiPolygon?crs=EPSG:4326&field=RGIId:string(...      178920   \n",
       "1     MultiPolygon?crs=EPSG:4326&field=RGIId:string(...      339441   \n",
       "2     MultiPolygon?crs=EPSG:4326&field=RGIId:string(...     2810534   \n",
       "3     MultiPolygon?crs=EPSG:4326&field=RGIId:string(...       26102   \n",
       "4     MultiPolygon?crs=EPSG:4326&field=RGIId:string(...      111620   \n",
       "...                                                 ...         ...   \n",
       "2953  MultiPolygon?crs=EPSG:4326&field=RGIId:string(...       45913   \n",
       "2954  MultiPolygon?crs=EPSG:4326&field=RGIId:string(...       38712   \n",
       "2955  MultiPolygon?crs=EPSG:4326&field=RGIId:string(...       81025   \n",
       "2956  MultiPolygon?crs=EPSG:4326&field=RGIId:string(...      550995   \n",
       "2957  MultiPolygon?crs=EPSG:4326&field=RGIId:string(...     1333229   \n",
       "\n",
       "      DC_Area_v2  DC_Area__1  \\\n",
       "0         498099       5.054   \n",
       "1         339441      16.680   \n",
       "2        3118320      10.929   \n",
       "3         168314       5.618   \n",
       "4         197136       6.828   \n",
       "...          ...         ...   \n",
       "2953      940764      21.717   \n",
       "2954      385319       5.913   \n",
       "2955      171952       6.168   \n",
       "2956      642827      13.917   \n",
       "2957     1333229       5.872   \n",
       "\n",
       "                                               geometry  CenLon_360  \n",
       "0     MULTIPOLYGON (((77.97991 35.56762, 77.98057 35...   77.994225  \n",
       "1     POLYGON ((94.29031 30.36096, 94.29062 30.36096...   94.297566  \n",
       "2     MULTIPOLYGON (((94.90493 30.61977, 94.90524 30...   94.924077  \n",
       "3     MULTIPOLYGON (((94.78556 30.79927, 94.78619 30...   94.776375  \n",
       "4     MULTIPOLYGON (((94.64190 30.66558, 94.64252 30...   94.638690  \n",
       "...                                                 ...         ...  \n",
       "2953  MULTIPOLYGON (((97.51190 28.95634, 97.51344 28...   97.510296  \n",
       "2954  MULTIPOLYGON (((97.53329 28.98960, 97.53360 28...   97.530043  \n",
       "2955  MULTIPOLYGON (((97.54210 28.99809, 97.54241 28...   97.536678  \n",
       "2956  MULTIPOLYGON (((97.62523 28.92939, 97.62554 28...   97.619880  \n",
       "2957  POLYGON ((79.42237 31.07560, 79.42236 31.07614...   79.453200  \n",
       "\n",
       "[2958 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(input.debriscover_fp + input.debriscover_fn_dict[input.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > input.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > input.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > input.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "dc_shp_subset['CenLon_360'] = dc_shp_subset['CenLon']\n",
    "dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'] = 360 + dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360']\n",
    "dc_shp_subset\n",
    "\n",
    "# # # ===== LOAD RGI DATA (works for multiple regions together) =====\n",
    "# # rgi_fns = []\n",
    "# # for i in os.listdir(input.rgi_fp):\n",
    "# # #     print(i)\n",
    "# #     for reg_no in input.roi_rgidict[input.roi]:\n",
    "# #         reg_str = str(reg_no).zfill(2)\n",
    "# #         if i.startswith(reg_str) and i.endswith('.csv'):\n",
    "# #             rgi_fns.append(i)\n",
    "# # rgi_fns = sorted(rgi_fns)\n",
    "\n",
    "# # # Load RGI data\n",
    "# # rgi_data = None\n",
    "# # for i in rgi_fns:\n",
    "# #     rgi_reg = pd.read_csv(input.rgi_fp + i)\n",
    "    \n",
    "# #     if rgi_data is None:\n",
    "# #         rgi_data = rgi_reg\n",
    "# #     else:\n",
    "# #         rgi_data = pd.concat((rgi_data, rgi_reg), axis=0)\n",
    "# # rgi_data.reset_index(inplace=True, drop=True)\n",
    "# # rgi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LOAD GLACIERS WITH LARSEN DATA =====\n",
    "dc_shp_subset['larsen_fullfn'] = np.nan\n",
    "larsen_fullfn_dict = {}\n",
    "if 'larsen' in input.mb_datasets:\n",
    "    mb_summary = pd.read_csv(input.larsen_fp + input.larsen_fn)\n",
    "    \n",
    "    # Find glaciers that are debris-covered\n",
    "    larsen_dc_rgiid = [value for value in list(mb_summary.RGIId.values) \n",
    "                       if value in list(dc_shp_subset.RGIId.values)]\n",
    "\n",
    "    mb_summary_dc = mb_summary[mb_summary['RGIId'].isin(larsen_dc_rgiid)]\n",
    "    mb_summary_dc = mb_summary_dc.sort_values('RGIId')\n",
    "    mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "    mb_summary_dc.loc[mb_summary_dc['name'] == 'Maclaren', 'name'] = 'MacLaren'\n",
    "    mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila Fork', 'name'] = 'TlikakilaGlacierFork'\n",
    "    mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila N. Fork', 'name'] = 'TlikakilaNorthFork'\n",
    "    mb_summary_dc['larsen_fullfn'] = np.nan\n",
    "    \n",
    "    for n, glac_name in enumerate(mb_summary_dc.name.values):\n",
    "#     for n, glac_name in enumerate([mb_summary_dc.name.values[47]]):\n",
    "#         print(n, glac_name)\n",
    "            \n",
    "        glac_name = glac_name.replace(' ', '')\n",
    "        glac_fns = []\n",
    "        start_yr = []\n",
    "        end_yr = []\n",
    "        for i in os.listdir(input.larsen_binned_fp):\n",
    "            if i.startswith(glac_name):\n",
    "                glac_fns.append(i)\n",
    "                start_yr.append(i.split('.')[1][0:4])\n",
    "                end_yr.append(i.split('.')[2][0:4])\n",
    "                \n",
    "        if len(glac_fns) > 0:\n",
    "            yr_dif = np.array(end_yr).astype(int) - np.array(start_yr).astype(int)\n",
    "            mb_fn = glac_fns[np.where(yr_dif == yr_dif.max())[0][0]]\n",
    "            \n",
    "            # ===== Process Larsen dataset =====\n",
    "            larsen_data_raw = np.genfromtxt(input.larsen_binned_fp + mb_fn, skip_header=3)\n",
    "            larsen_data_header = ['E', 'DZ', 'DZ25', 'DZ75', 'AAD', 'MassChange', 'MassBal', 'NumData']\n",
    "            larsen_data = pd.DataFrame(larsen_data_raw, columns=larsen_data_header)\n",
    "            larsen_data['std from DZ25'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ25']) / 0.67\n",
    "            larsen_data['std from DZ75'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ75']) / 0.67\n",
    "            larsen_data[' dhdt_bin_std_ma'] = (larsen_data['std from DZ25'] + larsen_data['std from DZ75']) / 2\n",
    "            larsen_data[' mb_bin_std_mwea'] = larsen_data[' dhdt_bin_std_ma'] * 900 / 1000\n",
    "            larsen_data['AAD'] = larsen_data['AAD'] / 1e6\n",
    "            larsen_data['startyear'] = int(mb_fn.split('.')[1][0:4])\n",
    "            larsen_data['endyear'] = int(mb_fn.split('.')[2][0:4])\n",
    "            larsen_data = larsen_data.rename({'E': '# bin_center_elev_m',\n",
    "                                              'DZ': ' dhdt_bin_mean_ma',\n",
    "                                              'MassBal': ' mb_bin_mean_mwea',\n",
    "                                              'AAD': ' z1_bin_area_valid_km2',\n",
    "                                             }, axis='columns')\n",
    "            new_fn = mb_summary_dc.loc[n,'RGIId'].split('-')[1][1:] + '_larsen_mb_bins.csv'\n",
    "            larsen_data.to_csv(input.larsen_binned_fp + new_fn, index=False)\n",
    "            \n",
    "            mb_summary_dc.loc[n, 'larsen_fullfn'] = input.larsen_binned_fp + new_fn\n",
    "            \n",
    "        else:\n",
    "            print(n, glac_name, 'has no file\\n')\n",
    "\n",
    "    mb_summary_dc.dropna(subset=['larsen_fullfn'], inplace=True)\n",
    "    mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    print('Larsen debris-covered glaciers:', mb_summary_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "    larsen_fullfn_dict = dict(zip(mb_summary_dc['RGIId'].values, mb_summary_dc['larsen_fullfn'].values))\n",
    "#     print(larsen_fullfn_dict)\n",
    "    dc_shp_subset['larsen_fullfn'] = dc_shp_subset.RGIId.map(larsen_fullfn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LOAD GLACIERS WITH BRAUN DATA =====\n",
    "dc_shp_subset['braun_fullfn'] = np.nan\n",
    "braun_fullfn_dict = {}\n",
    "if 'braun' in input.mb_datasets:\n",
    "    mb_binned_fp = input.main_directory + '/../mb_data/Braun/binned_data/'\n",
    "    \n",
    "    mb_fns = []\n",
    "    braun_rgiids = []\n",
    "    for i in os.listdir(mb_binned_fp):\n",
    "        if i.endswith('_mb_bins.csv'):\n",
    "            mb_fns.append(mb_binned_fp + i)\n",
    "            rgiid_raw = i.split('_')[0]\n",
    "            rgiid = 'RGI60-' + rgiid_raw[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "            braun_rgiids.append(rgiid)\n",
    "    braun_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'braun_fn'])\n",
    "    braun_fn_df['RGIId'] = braun_rgiids\n",
    "    braun_fn_df['braun_fullfn'] = mb_fns\n",
    "    \n",
    "    # Find glaciers that are debris-covered\n",
    "    braun_dc_rgiid = [value for value in list(braun_fn_df.RGIId.values) \n",
    "                       if value in list(dc_shp_subset.RGIId.values)]\n",
    "    braun_fn_df_dc = braun_fn_df[braun_fn_df['RGIId'].isin(braun_dc_rgiid)]\n",
    "    braun_fn_df_dc = braun_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "    print('Braun debris-covered glaciers:', braun_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "    braun_fullfn_dict = dict(zip(braun_fn_df_dc['RGIId'].values, braun_fn_df_dc['braun_fullfn'].values))\n",
    "#     print(braun_fullfn_dict)\n",
    "\n",
    "    dc_shp_subset['braun_fullfn'] = dc_shp_subset.RGIId.map(braun_fullfn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shean debris-covered glaciers: 2935 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== LOAD GLACIERS WITH BRAUN DATA =====\n",
    "dc_shp_subset['shean_fullfn'] = np.nan\n",
    "shean_fullfn_dict = {}\n",
    "if 'shean' in input.mb_datasets:\n",
    "    mb_binned_fp = input.main_directory + '/../mb_data/Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "    \n",
    "    mb_fns = []\n",
    "    rgiids = []\n",
    "    for i in os.listdir(mb_binned_fp):\n",
    "        if i.endswith('_mb_bins.csv'):\n",
    "            mb_fns.append(mb_binned_fp + i)\n",
    "            rgiid_raw = i.split('_')[0]\n",
    "            rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "            rgiids.append(rgiid)\n",
    "    mb_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'mb_fn'])\n",
    "    mb_fn_df['RGIId'] = rgiids\n",
    "    mb_fn_df['mb_fullfn'] = mb_fns\n",
    "    \n",
    "    # Find glaciers that are debris-covered\n",
    "    mb_dc_rgiid = [value for value in list(mb_fn_df.RGIId.values) \n",
    "                   if value in list(dc_shp_subset.RGIId.values)]\n",
    "    mb_fn_df_dc = mb_fn_df[mb_fn_df['RGIId'].isin(mb_dc_rgiid)]\n",
    "    mb_fn_df_dc = mb_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "    print('shean debris-covered glaciers:', mb_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "    shean_fullfn_dict = dict(zip(mb_fn_df_dc['RGIId'].values, mb_fn_df_dc['mb_fullfn'].values))\n",
    "#     print(shea_fullfn_dict)\n",
    "    dc_shp_subset['shean_fullfn'] = dc_shp_subset.RGIId.map(shean_fullfn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dictionaries together\n",
    "mb_fn_dict = dict(list(larsen_fullfn_dict.items()) + list(braun_fullfn_dict.items()) + \n",
    "                  list(shean_fullfn_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique lat/lons: 690 \n",
      "\n",
      "\n",
      "[(44.75, 80.0), (44.0, 83.5), (44.0, 83.75), (44.0, 84.0), (43.75, 84.5), (43.75, 84.75), (43.75, 85.0), (43.75, 85.75), (43.5, 85.0), (43.25, 77.5), (43.0, 76.75), (43.0, 77.0), (43.0, 77.25), (43.0, 77.5), (43.0, 77.75), (42.75, 76.75), (42.75, 77.0), (42.75, 77.25), (42.75, 82.75), (42.5, 74.5), (42.5, 74.75), (42.5, 75.0), (42.5, 75.25), (42.5, 80.5), (42.5, 80.75), (42.5, 81.0), (42.5, 81.25), (42.5, 81.75), (42.5, 82.0), (42.5, 82.25), (42.5, 82.5), (42.5, 85.25), (42.25, 78.25), (42.25, 78.5), (42.25, 78.75), (42.25, 79.0), (42.25, 79.25), (42.25, 79.5), (42.25, 79.75), (42.25, 80.0), (42.25, 80.25), (42.25, 80.5), (42.25, 80.75), (42.25, 81.0), (42.25, 81.25), (42.25, 81.5), (42.25, 81.75), (42.0, 72.0), (42.0, 76.5), (42.0, 76.75), (42.0, 77.0), (42.0, 77.25), (42.0, 77.5), (42.0, 77.75), (42.0, 78.0), (42.0, 78.25), (42.0, 78.5), (42.0, 78.75), (42.0, 79.5), (42.0, 79.75), (42.0, 80.0), (42.0, 80.25), (42.0, 80.5), (42.0, 80.75), (41.75, 77.25), (41.75, 77.5), (41.75, 78.25), (41.75, 78.5), (41.75, 78.75), (41.75, 79.0), (41.75, 80.0), (41.75, 80.25), (41.5, 77.25), (41.5, 77.5), (41.5, 77.75), (41.5, 78.75), (41.25, 77.75), (41.25, 78.25), (41.25, 78.5), (41.0, 75.75), (41.0, 77.5), (41.0, 77.75), (40.75, 74.25), (40.75, 76.75), (40.0, 72.5), (39.75, 70.5), (39.75, 70.75), (39.75, 71.25), (39.75, 71.5), (39.75, 71.75), (39.75, 72.0), (39.75, 72.5), (39.5, 70.0), (39.5, 70.25), (39.5, 70.5), (39.5, 70.75), (39.5, 71.0), (39.5, 71.25), (39.5, 71.5), (39.5, 72.0), (39.5, 72.5), (39.5, 72.75), (39.5, 73.0), (39.5, 73.25), (39.5, 73.5), (39.5, 73.75), (39.5, 74.0), (39.25, 69.5), (39.25, 69.75), (39.25, 70.0), (39.25, 70.25), (39.25, 71.0), (39.25, 71.75), (39.25, 72.0), (39.25, 72.25), (39.25, 72.5), (39.25, 72.75), (39.25, 73.0), (39.25, 73.25), (39.25, 73.5), (39.25, 74.25), (39.25, 74.5), (39.25, 74.75), (39.25, 75.0), (39.0, 68.0), (39.0, 68.5), (39.0, 70.75), (39.0, 71.0), (39.0, 71.25), (39.0, 71.5), (39.0, 71.75), (39.0, 72.0), (39.0, 72.25), (39.0, 72.5), (39.0, 72.75), (39.0, 73.0), (39.0, 73.75), (39.0, 74.75), (39.0, 75.0), (38.75, 71.0), (38.75, 71.25), (38.75, 71.5), (38.75, 71.75), (38.75, 72.0), (38.75, 72.25), (38.75, 72.5), (38.75, 72.75), (38.75, 73.0), (38.75, 73.25), (38.75, 73.75), (38.75, 75.0), (38.75, 75.25), (38.75, 75.5), (38.5, 71.25), (38.5, 71.5), (38.5, 71.75), (38.5, 72.0), (38.5, 72.25), (38.5, 72.5), (38.5, 72.75), (38.5, 73.25), (38.5, 73.5), (38.5, 75.25), (38.5, 75.5), (38.25, 71.0), (38.25, 71.25), (38.25, 71.75), (38.25, 72.0), (38.25, 72.25), (38.25, 72.5), (38.25, 72.75), (38.25, 73.25), (38.25, 75.0), (38.25, 75.25), (38.25, 75.5), (38.0, 71.0), (38.0, 71.75), (38.0, 72.0), (38.0, 72.25), (38.0, 72.5), (38.0, 72.75), (38.0, 73.0), (38.0, 73.25), (38.0, 87.25), (38.0, 87.5), (37.75, 71.75), (37.75, 72.0), (37.75, 72.25), (37.75, 72.75), (37.5, 71.25), (37.5, 72.0), (37.5, 72.25), (37.5, 75.25), (37.25, 71.75), (37.25, 72.5), (37.25, 73.25), (37.25, 73.5), (37.25, 73.75), (37.25, 75.0), (37.25, 75.25), (37.25, 85.75), (37.25, 86.0), (37.0, 71.25), (37.0, 71.75), (37.0, 72.0), (37.0, 72.25), (37.0, 72.75), (37.0, 73.0), (37.0, 73.25), (37.0, 73.5), (37.0, 73.75), (37.0, 74.0), (37.0, 74.25), (37.0, 74.75), (37.0, 75.0), (37.0, 75.25), (36.75, 72.0), (36.75, 72.25), (36.75, 72.5), (36.75, 72.75), (36.75, 73.0), (36.75, 73.25), (36.75, 73.5), (36.75, 73.75), (36.75, 74.0), (36.75, 74.25), (36.75, 74.5), (36.75, 74.75), (36.75, 75.0), (36.75, 75.25), (36.75, 75.5), (36.75, 75.75), (36.75, 76.0), (36.75, 76.25), (36.75, 77.25), (36.75, 77.75), (36.75, 78.25), (36.75, 78.5), (36.75, 84.5), (36.75, 84.75), (36.75, 85.0), (36.75, 85.25), (36.5, 70.5), (36.5, 71.5), (36.5, 71.75), (36.5, 72.0), (36.5, 72.25), (36.5, 72.75), (36.5, 73.0), (36.5, 73.25), (36.5, 73.5), (36.5, 73.75), (36.5, 74.0), (36.5, 74.25), (36.5, 74.5), (36.5, 74.75), (36.5, 75.0), (36.5, 75.25), (36.5, 75.5), (36.5, 75.75), (36.5, 76.0), (36.5, 77.5), (36.5, 77.75), (36.5, 78.25), (36.25, 69.75), (36.25, 70.25), (36.25, 70.5), (36.25, 71.0), (36.25, 71.25), (36.25, 71.75), (36.25, 72.0), (36.25, 72.25), (36.25, 72.5), (36.25, 72.75), (36.25, 73.0), (36.25, 74.0), (36.25, 74.25), (36.25, 74.5), (36.25, 74.75), (36.25, 75.0), (36.25, 75.25), (36.25, 75.5), (36.25, 75.75), (36.25, 76.0), (36.25, 76.25), (36.25, 78.5), (36.25, 78.75), (36.25, 79.0), (36.25, 79.25), (36.25, 79.5), (36.25, 82.0), (36.25, 82.25), (36.25, 82.5), (36.0, 70.5), (36.0, 70.75), (36.0, 71.0), (36.0, 71.25), (36.0, 72.25), (36.0, 72.5), (36.0, 72.75), (36.0, 73.0), (36.0, 74.5), (36.0, 74.75), (36.0, 75.0), (36.0, 75.25), (36.0, 75.5), (36.0, 75.75), (36.0, 76.0), (36.0, 76.25), (36.0, 76.5), (36.0, 76.75), (36.0, 79.5), (36.0, 79.75), (36.0, 80.0), (36.0, 80.25), (36.0, 80.75), (36.0, 81.0), (36.0, 81.25), (36.0, 81.5), (36.0, 81.75), (35.75, 70.5), (35.75, 70.75), (35.75, 71.0), (35.75, 71.25), (35.75, 72.25), (35.75, 72.5), (35.75, 72.75), (35.75, 73.0), (35.75, 73.25), (35.75, 74.75), (35.75, 75.0), (35.75, 75.25), (35.75, 75.5), (35.75, 75.75), (35.75, 76.0), (35.75, 76.25), (35.75, 76.5), (35.75, 76.75), (35.75, 77.0), (35.75, 80.25), (35.75, 80.5), (35.5, 70.75), (35.5, 72.5), (35.5, 72.75), (35.5, 73.0), (35.5, 75.0), (35.5, 75.25), (35.5, 75.5), (35.5, 75.75), (35.5, 76.0), (35.5, 76.25), (35.5, 76.5), (35.5, 76.75), (35.5, 77.0), (35.5, 77.25), (35.5, 77.5), (35.5, 78.0), (35.5, 80.75), (35.5, 81.0), (35.25, 72.75), (35.25, 73.0), (35.25, 73.5), (35.25, 74.5), (35.25, 74.75), (35.25, 75.0), (35.25, 75.25), (35.25, 76.25), (35.25, 76.5), (35.25, 76.75), (35.25, 77.0), (35.25, 77.25), (35.25, 77.5), (35.25, 77.75), (35.0, 73.25), (35.0, 73.5), (35.0, 74.25), (35.0, 74.5), (35.0, 74.75), (35.0, 76.75), (35.0, 77.0), (35.0, 77.25), (35.0, 77.5), (35.0, 77.75), (35.0, 78.25), (34.75, 73.75), (34.75, 74.0), (34.75, 76.75), (34.75, 77.0), (34.75, 77.25), (34.75, 77.5), (34.75, 77.75), (34.75, 78.0), (34.75, 78.25), (34.75, 78.5), (34.5, 75.5), (34.5, 77.0), (34.5, 77.25), (34.5, 77.75), (34.5, 78.0), (34.5, 78.25), (34.25, 75.25), (34.25, 75.5), (34.25, 75.75), (34.25, 76.0), (34.25, 78.0), (34.25, 78.25), (34.25, 78.5), (34.0, 75.75), (34.0, 76.0), (34.0, 76.25), (34.0, 76.5), (34.0, 78.25), (33.75, 75.75), (33.75, 76.0), (33.75, 76.25), (33.75, 77.5), (33.75, 78.25), (33.75, 78.5), (33.5, 76.0), (33.5, 76.25), (33.5, 76.5), (33.5, 76.75), (33.5, 77.25), (33.5, 91.25), (33.5, 94.75), (33.25, 76.25), (33.25, 76.5), (33.25, 76.75), (33.25, 77.0), (33.25, 91.25), (33.25, 92.0), (33.0, 76.25), (33.0, 76.5), (33.0, 76.75), (33.0, 77.0), (33.0, 77.25), (33.0, 78.25), (33.0, 78.5), (33.0, 92.0), (32.75, 76.5), (32.75, 76.75), (32.75, 77.0), (32.75, 77.25), (32.75, 77.5), (32.75, 77.75), (32.5, 76.5), (32.5, 76.75), (32.5, 77.0), (32.5, 77.25), (32.5, 77.5), (32.5, 77.75), (32.5, 78.0), (32.5, 78.5), (32.5, 78.75), (32.5, 79.0), (32.25, 76.75), (32.25, 77.0), (32.25, 77.25), (32.25, 77.5), (32.25, 77.75), (32.25, 78.5), (32.0, 77.5), (32.0, 77.75), (32.0, 78.0), (32.0, 78.5), (32.0, 78.75), (31.75, 77.5), (31.75, 77.75), (31.75, 78.0), (31.75, 78.25), (31.75, 78.75), (31.75, 94.75), (31.75, 99.0), (31.5, 78.5), (31.5, 100.25), (31.25, 78.25), (31.25, 78.5), (31.25, 78.75), (31.0, 78.5), (31.0, 78.75), (31.0, 79.0), (31.0, 79.25), (31.0, 79.5), (31.0, 79.75), (31.0, 81.25), (31.0, 93.75), (30.75, 78.75), (30.75, 79.0), (30.75, 79.25), (30.75, 79.5), (30.75, 79.75), (30.75, 80.0), (30.75, 91.5), (30.75, 94.0), (30.75, 94.25), (30.75, 94.5), (30.75, 94.75), (30.75, 95.0), (30.75, 95.25), (30.75, 99.5), (30.5, 79.75), (30.5, 80.0), (30.5, 80.25), (30.5, 80.5), (30.5, 80.75), (30.5, 81.25), (30.5, 83.25), (30.5, 86.5), (30.5, 90.5), (30.5, 93.25), (30.5, 93.5), (30.5, 93.75), (30.5, 94.0), (30.5, 94.25), (30.5, 94.5), (30.5, 94.75), (30.5, 95.0), (30.5, 95.25), (30.5, 99.5), (30.25, 79.75), (30.25, 80.0), (30.25, 80.25), (30.25, 80.5), (30.25, 80.75), (30.25, 81.5), (30.25, 81.75), (30.25, 82.0), (30.25, 82.25), (30.25, 90.5), (30.25, 93.5), (30.25, 93.75), (30.25, 94.0), (30.25, 94.25), (30.25, 94.5), (30.25, 94.75), (30.25, 95.0), (30.25, 95.25), (30.25, 95.5), (30.25, 95.75), (30.0, 80.5), (30.0, 81.0), (30.0, 81.25), (30.0, 81.5), (30.0, 82.0), (30.0, 82.25), (30.0, 82.5), (30.0, 84.5), (30.0, 85.0), (30.0, 90.0), (30.0, 94.25), (30.0, 94.5), (30.0, 94.75), (30.0, 95.0), (30.0, 95.25), (30.0, 95.5), (30.0, 95.75), (30.0, 96.0), (29.75, 81.0), (29.75, 81.5), (29.75, 82.25), (29.75, 82.5), (29.75, 82.75), (29.75, 83.0), (29.75, 84.5), (29.75, 84.75), (29.75, 94.75), (29.75, 95.0), (29.75, 95.25), (29.75, 95.75), (29.75, 96.0), (29.75, 96.5), (29.75, 97.25), (29.75, 99.5), (29.75, 101.75), (29.75, 102.0), (29.5, 82.5), (29.5, 82.75), (29.5, 95.0), (29.5, 95.25), (29.5, 96.0), (29.5, 96.25), (29.5, 96.5), (29.5, 96.75), (29.5, 97.0), (29.5, 97.25), (29.5, 97.5), (29.5, 101.75), (29.5, 102.0), (29.25, 82.5), (29.25, 82.75), (29.25, 95.0), (29.25, 96.0), (29.25, 96.25), (29.25, 96.5), (29.25, 96.75), (29.25, 97.0), (29.25, 97.25), (29.0, 83.5), (29.0, 83.75), (29.0, 84.25), (29.0, 90.25), (29.0, 96.25), (29.0, 96.5), (29.0, 96.75), (29.0, 97.0), (29.0, 97.25), (29.0, 97.5), (29.0, 97.75), (28.75, 83.0), (28.75, 83.25), (28.75, 83.5), (28.75, 83.75), (28.75, 84.0), (28.75, 84.25), (28.75, 84.5), (28.75, 85.5), (28.75, 93.5), (28.75, 96.5), (28.75, 97.75), (28.75, 98.25), (28.5, 83.75), (28.5, 84.0), (28.5, 84.25), (28.5, 84.5), (28.5, 84.75), (28.5, 85.0), (28.5, 85.25), (28.5, 85.5), (28.5, 85.75), (28.5, 96.5), (28.5, 97.5), (28.5, 98.25), (28.5, 98.5), (28.5, 98.75), (28.25, 85.0), (28.25, 85.25), (28.25, 85.5), (28.25, 85.75), (28.25, 86.0), (28.25, 86.25), (28.25, 86.5), (28.25, 86.75), (28.25, 87.5), (28.25, 90.0), (28.25, 90.25), (28.25, 90.5), (28.25, 90.75), (28.25, 91.25), (28.25, 91.5), (28.25, 92.75), (28.25, 97.0), (28.25, 97.5), (28.25, 98.75), (28.0, 86.0), (28.0, 86.25), (28.0, 86.5), (28.0, 86.75), (28.0, 87.0), (28.0, 87.25), (28.0, 87.5), (28.0, 87.75), (28.0, 88.0), (28.0, 88.25), (28.0, 88.5), (28.0, 88.75), (28.0, 89.0), (28.0, 89.5), (28.0, 89.75), (28.0, 90.0), (28.0, 90.25), (28.0, 90.5), (28.0, 90.75), (28.0, 91.25), (28.0, 91.5), (28.0, 91.75), (28.0, 92.5), (28.0, 92.75), (27.75, 86.5), (27.75, 86.75), (27.75, 87.0), (27.75, 87.25), (27.75, 87.75), (27.75, 88.0), (27.75, 88.25), (27.75, 88.75), (27.75, 89.25), (27.75, 92.25), (27.75, 92.5), (27.5, 88.0), (27.5, 88.25)]\n"
     ]
    }
   ],
   "source": [
    "# ===== SELECT GLACIERS WITH DATA ====\n",
    "dc_shp_subset_wdata = dc_shp_subset.dropna(subset=['larsen_fullfn', 'braun_fullfn', 'shean_fullfn'], how='all').copy()\n",
    "dc_shp_subset_wdata.reset_index(inplace=True, drop=True)\n",
    "ds = xr.open_dataset(input.metdata_fp + '../' + input.metdata_elev_fn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(dc_shp_subset_wdata['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(dc_shp_subset_wdata['CenLon_360'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "dc_shp_subset_wdata['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "dc_shp_subset_wdata['latlon_unique_no'] = dc_shp_subset_wdata['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(dc_shp_subset_wdata['latlon_unique_no'])), '\\n\\n')\n",
    "# print(dc_shp_subset_wdata.loc[0:5,['RGIId', 'CenLat', 'CenLon', 'larsen_fn', 'braun_fn', 'latlon_unique_no']])\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "print(latlon_list)\n",
    "\n",
    "# Pickle unique lat/lons that will be used for melt model\n",
    "with open(input.latlon_unique_fp + input.latlon_unique_dict[input.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090 glaciers in region 13 are included in this model run: ['00604', '00611', '00643', '00713', '00757', '00761', '00763', '00777', '00788', '00809', '00830', '00834', '00838', '00880', '00884', '00885', '00891', '00905', '00906', '00940', '00949', '00951', '00954', '00956', '00964', '00965', '00967', '00972', '00982', '00995', '00997', '00999', '01019', '01022', '01023', '01027', '01038', '01044', '01045', '01050', '01098', '01099', '01113', '01124', '01129', '01136', '01144', '01145', '01148', '01150'] and more\n",
      "1041 glaciers in region 14 are included in this model run: ['00005', '00018', '00032', '00036', '00043', '00057', '00072', '00104', '00145', '00163', '00222', '00287', '00353', '00363', '00471', '00543', '00548', '00555', '00595', '00700', '00722', '00742', '00764', '00767', '00796', '00805', '00850', '00891', '00899', '00952', '01001', '01022', '01070', '01075', '01165', '01191', '01206', '01226', '01228', '01244', '01285', '01361', '01379', '01391', '01400', '01409', '01425', '01454', '01474', '01489'] and more\n",
      "804 glaciers in region 15 are included in this model run: ['00026', '00055', '00057', '00186', '00232', '00233', '00234', '00355', '00356', '00368', '00379', '00399', '00406', '00423', '00475', '00503', '00612', '00617', '00621', '00655', '00835', '00850', '00868', '00869', '00872', '00880', '00881', '00885', '00894', '00898', '00899', '00909', '00910', '00911', '00920', '00957', '00996', '01004', '01024', '01030', '01031', '01032', '01062', '01077', '01078', '01087', '01089', '01094', '01096', '01098'] and more\n",
      "This study is focusing on 2935 glaciers in region [13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# ===== Load Glaciers =====\n",
    "rgiid_list = [x.split('-')[1] for x in dc_shp_subset_wdata['RGIId'].values]\n",
    "main_glac_rgi = input.selectglaciersrgitable(rgiid_list)\n",
    "# add filenames\n",
    "main_glac_rgi['mb_fn'] = np.nan\n",
    "main_glac_rgi['mb_fn'] = main_glac_rgi.RGIId.map(mb_fn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n\\nDELETE ME AFTER TESTING\\n\\n')\n",
    "# # rgiid_list = ['01.15645']\n",
    "# rgiid_list = ['15.03473']\n",
    "# main_glac_rgi = input.selectglaciersrgitable(rgiid_list)\n",
    "# # add filenames\n",
    "# main_glac_rgi['mb_fn'] = np.nan\n",
    "# main_glac_rgi['mb_fn'] = main_glac_rgi.RGIId.map(mb_fn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 RGI60-13.00604\n",
      "1 1 RGI60-13.00611\n",
      "2 2 RGI60-13.00643\n",
      "3 3 RGI60-13.00713\n",
      "4 4 RGI60-13.00757\n",
      "5 5 RGI60-13.00761\n",
      "6 6 RGI60-13.00763\n",
      "7 7 RGI60-13.00777\n",
      "8 8 RGI60-13.00788\n",
      "9 9 RGI60-13.00809\n",
      "10 10 RGI60-13.00830\n",
      "11 11 RGI60-13.00834\n",
      "12 12 RGI60-13.00838\n",
      "13 13 RGI60-13.00880\n",
      "14 14 RGI60-13.00884\n",
      "15 15 RGI60-13.00885\n",
      "16 16 RGI60-13.00891\n",
      "17 17 RGI60-13.00905\n",
      "18 18 RGI60-13.00906\n",
      "19 19 RGI60-13.00940\n",
      "20 20 RGI60-13.00949\n",
      "21 21 RGI60-13.00951\n",
      "22 22 RGI60-13.00954\n",
      "23 23 RGI60-13.00956\n",
      "24 24 RGI60-13.00964\n",
      "25 25 RGI60-13.00965\n",
      "26 26 RGI60-13.00967\n",
      "27 27 RGI60-13.00972\n",
      "28 28 RGI60-13.00982\n",
      "29 29 RGI60-13.00995\n",
      "30 30 RGI60-13.00997\n",
      "31 31 RGI60-13.00999\n",
      "32 32 RGI60-13.01019\n",
      "33 33 RGI60-13.01022\n",
      "34 34 RGI60-13.01023\n",
      "35 35 RGI60-13.01027\n",
      "36 36 RGI60-13.01038\n",
      "37 37 RGI60-13.01044\n",
      "38 38 RGI60-13.01045\n",
      "39 39 RGI60-13.01050\n",
      "40 40 RGI60-13.01098\n",
      "41 41 RGI60-13.01099\n",
      "42 42 RGI60-13.01113\n",
      "43 43 RGI60-13.01124\n",
      "44 44 RGI60-13.01129\n",
      "45 45 RGI60-13.01136\n",
      "46 46 RGI60-13.01144\n",
      "47 47 RGI60-13.01145\n",
      "48 48 RGI60-13.01148\n",
      "49 49 RGI60-13.01150\n",
      "50 50 RGI60-13.01157\n",
      "51 51 RGI60-13.01175\n",
      "52 52 RGI60-13.01176\n",
      "53 53 RGI60-13.01184\n",
      "54 54 RGI60-13.01186\n",
      "55 55 RGI60-13.01228\n",
      "56 56 RGI60-13.01231\n",
      "57 57 RGI60-13.01232\n",
      "58 58 RGI60-13.01235\n",
      "59 59 RGI60-13.01260\n",
      "60 60 RGI60-13.01265\n",
      "61 61 RGI60-13.01267\n",
      "62 62 RGI60-13.01268\n",
      "63 63 RGI60-13.01296\n",
      "64 64 RGI60-13.01316\n",
      "65 65 RGI60-13.01317\n",
      "66 66 RGI60-13.01325\n",
      "67 67 RGI60-13.01326\n",
      "68 68 RGI60-13.01328\n",
      "69 69 RGI60-13.01329\n",
      "70 70 RGI60-13.01333\n",
      "71 71 RGI60-13.01337\n",
      "72 72 RGI60-13.01357\n",
      "73 73 RGI60-13.01391\n",
      "74 74 RGI60-13.01392\n",
      "75 75 RGI60-13.01394\n",
      "76 76 RGI60-13.01403\n",
      "77 77 RGI60-13.01409\n",
      "78 78 RGI60-13.01410\n",
      "79 79 RGI60-13.01428\n",
      "80 80 RGI60-13.01430\n",
      "81 81 RGI60-13.01432\n",
      "82 82 RGI60-13.01443\n",
      "83 83 RGI60-13.01456\n",
      "84 84 RGI60-13.01458\n",
      "85 85 RGI60-13.01480\n",
      "86 86 RGI60-13.01492\n",
      "87 87 RGI60-13.01500\n",
      "88 88 RGI60-13.01530\n",
      "89 89 RGI60-13.01536\n",
      "90 90 RGI60-13.01605\n",
      "91 91 RGI60-13.01804\n",
      "92 92 RGI60-13.01836\n",
      "93 93 RGI60-13.01841\n",
      "94 94 RGI60-13.01863\n",
      "95 95 RGI60-13.01877\n",
      "96 96 RGI60-13.01920\n",
      "97 97 RGI60-13.01921\n",
      "98 98 RGI60-13.01937\n",
      "99 99 RGI60-13.01953\n",
      "100 100 RGI60-13.01956\n",
      "101 101 RGI60-13.01964\n",
      "102 102 RGI60-13.01969\n",
      "103 103 RGI60-13.01980\n",
      "104 104 RGI60-13.01981\n",
      "105 105 RGI60-13.01982\n",
      "106 106 RGI60-13.01983\n",
      "107 107 RGI60-13.01990\n",
      "108 108 RGI60-13.01991\n",
      "109 109 RGI60-13.01993\n",
      "110 110 RGI60-13.02141\n",
      "111 111 RGI60-13.02176\n",
      "112 112 RGI60-13.02180\n",
      "113 113 RGI60-13.02182\n",
      "114 114 RGI60-13.02191\n",
      "115 115 RGI60-13.02192\n",
      "116 116 RGI60-13.02223\n",
      "117 117 RGI60-13.02225\n",
      "118 118 RGI60-13.02411\n",
      "119 119 RGI60-13.02425\n",
      "120 120 RGI60-13.02432\n",
      "121 121 RGI60-13.02444\n",
      "122 122 RGI60-13.02445\n",
      "123 123 RGI60-13.02452\n",
      "124 124 RGI60-13.02453\n",
      "125 125 RGI60-13.02566\n",
      "126 126 RGI60-13.02569\n",
      "127 127 RGI60-13.02586\n",
      "128 128 RGI60-13.02596\n",
      "129 129 RGI60-13.02631\n",
      "130 130 RGI60-13.02632\n",
      "131 131 RGI60-13.02643\n",
      "132 132 RGI60-13.02645\n",
      "133 133 RGI60-13.02647\n",
      "134 134 RGI60-13.02655\n",
      "135 135 RGI60-13.02675\n",
      "136 136 RGI60-13.02768\n",
      "137 137 RGI60-13.02790\n",
      "138 138 RGI60-13.02843\n",
      "139 139 RGI60-13.02844\n",
      "140 140 RGI60-13.02848\n",
      "141 141 RGI60-13.02938\n",
      "142 142 RGI60-13.02954\n",
      "143 143 RGI60-13.02968\n",
      "144 144 RGI60-13.02974\n",
      "145 145 RGI60-13.02976\n",
      "146 146 RGI60-13.02979\n",
      "147 147 RGI60-13.02996\n",
      "148 148 RGI60-13.03024\n",
      "149 149 RGI60-13.03034\n",
      "150 150 RGI60-13.03038\n",
      "151 151 RGI60-13.03307\n",
      "152 152 RGI60-13.03308\n",
      "153 153 RGI60-13.03309\n",
      "154 154 RGI60-13.03319\n",
      "155 155 RGI60-13.03377\n",
      "156 156 RGI60-13.03489\n",
      "157 157 RGI60-13.03755\n",
      "158 158 RGI60-13.03762\n",
      "159 159 RGI60-13.03776\n",
      "160 160 RGI60-13.03860\n",
      "161 161 RGI60-13.03866\n",
      "162 162 RGI60-13.03870\n",
      "163 163 RGI60-13.04224\n",
      "164 164 RGI60-13.04872\n",
      "165 165 RGI60-13.04933\n",
      "166 166 RGI60-13.04934\n",
      "167 167 RGI60-13.04937\n",
      "168 168 RGI60-13.04943\n",
      "169 169 RGI60-13.04946\n",
      "170 170 RGI60-13.04957\n",
      "171 171 RGI60-13.04960\n",
      "172 172 RGI60-13.04985\n",
      "173 173 RGI60-13.05000\n",
      "174 174 RGI60-13.05009\n",
      "175 175 RGI60-13.05012\n",
      "176 176 RGI60-13.05038\n",
      "177 177 RGI60-13.05060\n",
      "178 178 RGI60-13.05111\n",
      "179 179 RGI60-13.05112\n",
      "180 180 RGI60-13.05323\n",
      "181 181 RGI60-13.05875\n",
      "182 182 RGI60-13.05924\n",
      "183 183 RGI60-13.05930\n",
      "184 184 RGI60-13.05937\n",
      "185 185 RGI60-13.05978\n",
      "186 186 RGI60-13.05982\n",
      "187 187 RGI60-13.06047\n",
      "188 188 RGI60-13.06052\n",
      "189 189 RGI60-13.06060\n",
      "190 190 RGI60-13.06199\n",
      "191 191 RGI60-13.06218\n",
      "192 192 RGI60-13.06251\n",
      "193 193 RGI60-13.06266\n",
      "194 194 RGI60-13.06301\n",
      "195 195 RGI60-13.06359\n",
      "196 196 RGI60-13.06361\n",
      "197 197 RGI60-13.06432\n",
      "198 198 RGI60-13.06466\n",
      "199 199 RGI60-13.06509\n",
      "200 200 RGI60-13.06532\n",
      "201 201 RGI60-13.06564\n",
      "202 202 RGI60-13.06567\n",
      "203 203 RGI60-13.06589\n",
      "204 204 RGI60-13.06591\n",
      "205 205 RGI60-13.06592\n",
      "206 206 RGI60-13.06608\n",
      "207 207 RGI60-13.06621\n",
      "208 208 RGI60-13.06638\n",
      "209 209 RGI60-13.06653\n",
      "210 210 RGI60-13.06674\n",
      "211 211 RGI60-13.06684\n",
      "212 212 RGI60-13.06733\n",
      "213 213 RGI60-13.06756\n",
      "214 214 RGI60-13.06792\n",
      "215 215 RGI60-13.06861\n",
      "216 216 RGI60-13.06868\n",
      "217 217 RGI60-13.06955\n",
      "218 218 RGI60-13.07062\n",
      "219 219 RGI60-13.07077\n",
      "220 220 RGI60-13.07079\n",
      "221 221 RGI60-13.07084\n",
      "222 222 RGI60-13.07091\n",
      "223 223 RGI60-13.07093\n",
      "224 224 RGI60-13.07133\n",
      "225 225 RGI60-13.07204\n",
      "226 226 RGI60-13.07234\n",
      "227 227 RGI60-13.07247\n",
      "228 228 RGI60-13.07294\n",
      "229 229 RGI60-13.07339\n",
      "230 230 RGI60-13.07344\n",
      "231 231 RGI60-13.07373\n",
      "232 232 RGI60-13.07498\n",
      "233 233 RGI60-13.07499\n",
      "234 234 RGI60-13.07512\n",
      "235 235 RGI60-13.07652\n",
      "236 236 RGI60-13.07732\n",
      "237 237 RGI60-13.07735\n",
      "238 238 RGI60-13.07738\n",
      "239 239 RGI60-13.07741\n",
      "240 240 RGI60-13.07743\n",
      "241 241 RGI60-13.07745\n",
      "242 242 RGI60-13.07763\n",
      "243 243 RGI60-13.07789\n",
      "244 244 RGI60-13.07858\n",
      "245 245 RGI60-13.07863\n",
      "246 246 RGI60-13.07873\n",
      "247 247 RGI60-13.07875\n",
      "248 248 RGI60-13.07901\n",
      "249 249 RGI60-13.07904\n",
      "250 250 RGI60-13.07916\n",
      "251 251 RGI60-13.07920\n",
      "252 252 RGI60-13.07925\n",
      "253 253 RGI60-13.07931\n",
      "254 254 RGI60-13.07946\n",
      "255 255 RGI60-13.07980\n",
      "256 256 RGI60-13.08031\n",
      "257 257 RGI60-13.08056\n",
      "258 258 RGI60-13.08077\n",
      "259 259 RGI60-13.08078\n",
      "260 260 RGI60-13.08084\n",
      "261 261 RGI60-13.08085\n",
      "262 262 RGI60-13.08086\n",
      "263 263 RGI60-13.08196\n",
      "264 264 RGI60-13.08253\n",
      "265 265 RGI60-13.08289\n",
      "266 266 RGI60-13.08291\n",
      "267 267 RGI60-13.08301\n",
      "268 268 RGI60-13.08306\n",
      "269 269 RGI60-13.08335\n",
      "270 270 RGI60-13.08392\n",
      "271 271 RGI60-13.08396\n",
      "272 272 RGI60-13.08443\n",
      "273 273 RGI60-13.08465\n",
      "274 274 RGI60-13.08471\n",
      "275 275 RGI60-13.08476\n",
      "276 276 RGI60-13.08482\n",
      "277 277 RGI60-13.08504\n",
      "278 278 RGI60-13.08511\n",
      "279 279 RGI60-13.08519\n",
      "280 280 RGI60-13.08528\n",
      "281 281 RGI60-13.08530\n",
      "282 282 RGI60-13.08559\n",
      "283 283 RGI60-13.08624\n",
      "284 284 RGI60-13.08629\n",
      "285 285 RGI60-13.08630\n",
      "286 286 RGI60-13.08634\n",
      "287 287 RGI60-13.08635\n",
      "288 288 RGI60-13.08637\n",
      "289 289 RGI60-13.08665\n",
      "290 290 RGI60-13.08672\n",
      "291 291 RGI60-13.08682\n",
      "292 292 RGI60-13.08697\n",
      "293 293 RGI60-13.08701\n",
      "294 294 RGI60-13.08703\n",
      "295 295 RGI60-13.08710\n",
      "296 296 RGI60-13.08722\n",
      "297 297 RGI60-13.08732\n",
      "298 298 RGI60-13.08778\n",
      "299 299 RGI60-13.08967\n",
      "300 300 RGI60-13.09129\n",
      "301 301 RGI60-13.09143\n",
      "302 302 RGI60-13.09191\n",
      "303 303 RGI60-13.09210\n",
      "304 304 RGI60-13.09315\n",
      "305 305 RGI60-13.09316\n",
      "306 306 RGI60-13.09317\n",
      "307 307 RGI60-13.09479\n",
      "308 308 RGI60-13.09552\n",
      "309 309 RGI60-13.09561\n",
      "310 310 RGI60-13.09720\n",
      "311 311 RGI60-13.09732\n",
      "312 312 RGI60-13.09755\n",
      "313 313 RGI60-13.09761\n",
      "314 314 RGI60-13.09783\n",
      "315 315 RGI60-13.09794\n",
      "316 316 RGI60-13.09895\n",
      "317 317 RGI60-13.09942\n",
      "318 318 RGI60-13.10055\n",
      "319 319 RGI60-13.10144\n",
      "320 320 RGI60-13.10361\n",
      "321 321 RGI60-13.10541\n",
      "322 322 RGI60-13.10822\n",
      "323 323 RGI60-13.10830\n",
      "324 324 RGI60-13.11066\n",
      "325 325 RGI60-13.11414\n",
      "326 326 RGI60-13.11432\n",
      "327 327 RGI60-13.11461\n",
      "328 328 RGI60-13.11503\n",
      "329 329 RGI60-13.11527\n",
      "330 330 RGI60-13.11530\n",
      "331 331 RGI60-13.11534\n",
      "332 332 RGI60-13.11604\n",
      "333 333 RGI60-13.11647\n",
      "334 334 RGI60-13.12063\n",
      "335 335 RGI60-13.12240\n",
      "336 336 RGI60-13.12244\n",
      "337 337 RGI60-13.12254\n",
      "338 338 RGI60-13.12485\n",
      "339 339 RGI60-13.12497\n",
      "340 340 RGI60-13.12507\n",
      "341 341 RGI60-13.12508\n",
      "342 342 RGI60-13.12509\n",
      "343 343 RGI60-13.12666\n",
      "344 344 RGI60-13.12672\n",
      "345 345 RGI60-13.12719\n",
      "346 346 RGI60-13.12722\n",
      "347 347 RGI60-13.12734\n",
      "348 348 RGI60-13.12745\n",
      "349 349 RGI60-13.12751\n",
      "350 350 RGI60-13.12753\n",
      "351 351 RGI60-13.12760\n",
      "352 352 RGI60-13.12771\n",
      "353 353 RGI60-13.12781\n",
      "354 354 RGI60-13.12798\n",
      "355 355 RGI60-13.12818\n",
      "356 356 RGI60-13.12845\n",
      "357 357 RGI60-13.12877\n",
      "358 358 RGI60-13.12950\n",
      "359 359 RGI60-13.12983\n",
      "360 360 RGI60-13.13002\n",
      "361 361 RGI60-13.13004\n",
      "362 362 RGI60-13.13013\n",
      "363 363 RGI60-13.13015\n",
      "364 364 RGI60-13.13025\n",
      "365 365 RGI60-13.13026\n",
      "366 366 RGI60-13.13043\n",
      "367 367 RGI60-13.13061\n",
      "368 368 RGI60-13.13064\n",
      "369 369 RGI60-13.13068\n",
      "370 370 RGI60-13.13078\n",
      "371 371 RGI60-13.13080\n",
      "372 372 RGI60-13.13167\n",
      "373 373 RGI60-13.13197\n",
      "374 374 RGI60-13.13201\n",
      "375 375 RGI60-13.13202\n",
      "376 376 RGI60-13.13203\n",
      "377 377 RGI60-13.13224\n",
      "378 378 RGI60-13.13235\n",
      "379 379 RGI60-13.13250\n",
      "380 380 RGI60-13.13251\n",
      "381 381 RGI60-13.13252\n",
      "382 382 RGI60-13.13258\n",
      "383 383 RGI60-13.13259\n",
      "384 384 RGI60-13.13260\n",
      "385 385 RGI60-13.13261\n",
      "386 386 RGI60-13.13265\n",
      "387 387 RGI60-13.13268\n",
      "388 388 RGI60-13.13321\n",
      "389 389 RGI60-13.13327\n",
      "390 390 RGI60-13.13402\n",
      "391 391 RGI60-13.13413\n",
      "392 392 RGI60-13.13415\n",
      "393 393 RGI60-13.13438\n",
      "394 394 RGI60-13.13496\n",
      "395 395 RGI60-13.13574\n",
      "396 396 RGI60-13.13589\n",
      "397 397 RGI60-13.13600\n",
      "398 398 RGI60-13.13612\n",
      "399 399 RGI60-13.13622\n",
      "400 400 RGI60-13.13636\n",
      "401 401 RGI60-13.13639\n",
      "402 402 RGI60-13.13650\n",
      "403 403 RGI60-13.13729\n",
      "404 404 RGI60-13.13747\n",
      "405 405 RGI60-13.13769\n",
      "406 406 RGI60-13.13776\n",
      "407 407 RGI60-13.13779\n",
      "408 408 RGI60-13.13791\n",
      "409 409 RGI60-13.13800\n",
      "410 410 RGI60-13.13810\n",
      "411 411 RGI60-13.13812\n",
      "412 412 RGI60-13.13876\n",
      "413 413 RGI60-13.13884\n",
      "414 414 RGI60-13.13896\n",
      "415 415 RGI60-13.13942\n",
      "416 416 RGI60-13.13985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 417 RGI60-13.13986\n",
      "418 418 RGI60-13.13989\n",
      "419 419 RGI60-13.13994\n",
      "420 420 RGI60-13.14006\n",
      "421 421 RGI60-13.14011\n",
      "422 422 RGI60-13.14019\n",
      "423 423 RGI60-13.14032\n",
      "424 424 RGI60-13.14145\n",
      "425 425 RGI60-13.14155\n",
      "426 426 RGI60-13.14159\n",
      "427 427 RGI60-13.14191\n",
      "428 428 RGI60-13.14273\n",
      "429 429 RGI60-13.14320\n",
      "430 430 RGI60-13.14321\n",
      "431 431 RGI60-13.14330\n",
      "432 432 RGI60-13.14335\n",
      "433 433 RGI60-13.14338\n",
      "434 434 RGI60-13.14370\n",
      "435 435 RGI60-13.14375\n",
      "436 436 RGI60-13.14441\n",
      "437 437 RGI60-13.14483\n",
      "438 438 RGI60-13.14501\n",
      "439 439 RGI60-13.14505\n",
      "440 440 RGI60-13.14507\n",
      "441 441 RGI60-13.14587\n",
      "442 442 RGI60-13.14589\n",
      "443 443 RGI60-13.14628\n",
      "444 444 RGI60-13.14662\n",
      "445 445 RGI60-13.14675\n",
      "446 446 RGI60-13.14690\n",
      "447 447 RGI60-13.14704\n",
      "448 448 RGI60-13.14715\n",
      "449 449 RGI60-13.14717\n",
      "450 450 RGI60-13.14739\n",
      "451 451 RGI60-13.14759\n",
      "452 452 RGI60-13.14771\n",
      "453 453 RGI60-13.14829\n",
      "454 454 RGI60-13.14900\n",
      "455 455 RGI60-13.14943\n",
      "456 456 RGI60-13.15127\n",
      "457 457 RGI60-13.15167\n",
      "458 458 RGI60-13.15171\n",
      "459 459 RGI60-13.15392\n",
      "460 460 RGI60-13.15430\n",
      "461 461 RGI60-13.15431\n",
      "462 462 RGI60-13.15432\n",
      "463 463 RGI60-13.15459\n",
      "464 464 RGI60-13.15469\n",
      "465 465 RGI60-13.15470\n",
      "466 466 RGI60-13.15483\n",
      "467 467 RGI60-13.15493\n",
      "468 468 RGI60-13.15505\n",
      "469 469 RGI60-13.15507\n",
      "470 470 RGI60-13.15526\n",
      "471 471 RGI60-13.15554\n",
      "472 472 RGI60-13.15561\n",
      "473 473 RGI60-13.16040\n",
      "474 474 RGI60-13.16045\n",
      "475 475 RGI60-13.16049\n",
      "476 476 RGI60-13.16050\n",
      "477 477 RGI60-13.16107\n",
      "478 478 RGI60-13.16115\n",
      "479 479 RGI60-13.16124\n",
      "480 480 RGI60-13.16165\n",
      "481 481 RGI60-13.16207\n",
      "482 482 RGI60-13.16273\n",
      "483 483 RGI60-13.16346\n",
      "484 484 RGI60-13.16390\n",
      "485 485 RGI60-13.16461\n",
      "486 486 RGI60-13.16511\n",
      "487 487 RGI60-13.16534\n",
      "488 488 RGI60-13.16594\n",
      "489 489 RGI60-13.16596\n",
      "490 490 RGI60-13.16662\n",
      "491 491 RGI60-13.16675\n",
      "492 492 RGI60-13.16688\n",
      "493 493 RGI60-13.16705\n",
      "494 494 RGI60-13.16722\n",
      "495 495 RGI60-13.16723\n",
      "496 496 RGI60-13.16725\n",
      "497 497 RGI60-13.16732\n",
      "498 498 RGI60-13.16745\n",
      "499 499 RGI60-13.16747\n",
      "500 500 RGI60-13.16786\n",
      "501 501 RGI60-13.16857\n",
      "502 502 RGI60-13.16990\n",
      "503 503 RGI60-13.17122\n",
      "504 504 RGI60-13.17130\n",
      "505 505 RGI60-13.17243\n",
      "506 506 RGI60-13.17291\n",
      "507 507 RGI60-13.17301\n",
      "508 508 RGI60-13.17335\n",
      "509 509 RGI60-13.17395\n",
      "510 510 RGI60-13.17423\n",
      "511 511 RGI60-13.17425\n",
      "512 512 RGI60-13.17439\n",
      "513 513 RGI60-13.17440\n",
      "514 514 RGI60-13.17441\n",
      "515 515 RGI60-13.17538\n",
      "516 516 RGI60-13.17542\n",
      "517 517 RGI60-13.17573\n",
      "518 518 RGI60-13.17579\n",
      "519 519 RGI60-13.17585\n",
      "520 520 RGI60-13.17672\n",
      "521 521 RGI60-13.17686\n",
      "522 522 RGI60-13.17710\n",
      "523 523 RGI60-13.17711\n",
      "524 524 RGI60-13.17773\n",
      "525 525 RGI60-13.17785\n",
      "526 526 RGI60-13.17803\n",
      "527 527 RGI60-13.17805\n",
      "528 528 RGI60-13.17817\n",
      "529 529 RGI60-13.17820\n",
      "530 530 RGI60-13.17821\n",
      "531 531 RGI60-13.17829\n",
      "532 532 RGI60-13.17856\n",
      "533 533 RGI60-13.17860\n",
      "534 534 RGI60-13.17868\n",
      "535 535 RGI60-13.17869\n",
      "536 536 RGI60-13.17870\n",
      "537 537 RGI60-13.17898\n",
      "538 538 RGI60-13.17928\n",
      "539 539 RGI60-13.17947\n",
      "540 540 RGI60-13.17951\n",
      "541 541 RGI60-13.17963\n",
      "542 542 RGI60-13.18021\n",
      "543 543 RGI60-13.18030\n",
      "544 544 RGI60-13.18039\n",
      "545 545 RGI60-13.18087\n",
      "546 546 RGI60-13.18107\n",
      "547 547 RGI60-13.18142\n",
      "548 548 RGI60-13.18150\n",
      "549 549 RGI60-13.18177\n",
      "550 550 RGI60-13.18180\n",
      "551 551 RGI60-13.18196\n",
      "552 552 RGI60-13.18197\n",
      "553 553 RGI60-13.18260\n",
      "554 554 RGI60-13.18317\n",
      "555 555 RGI60-13.18348\n",
      "556 556 RGI60-13.18353\n",
      "557 557 RGI60-13.18354\n",
      "558 558 RGI60-13.18362\n",
      "559 559 RGI60-13.18371\n",
      "560 560 RGI60-13.18385\n",
      "561 561 RGI60-13.18393\n",
      "562 562 RGI60-13.18418\n",
      "563 563 RGI60-13.18469\n",
      "564 564 RGI60-13.18475\n",
      "565 565 RGI60-13.18477\n",
      "566 566 RGI60-13.18483\n",
      "567 567 RGI60-13.18518\n",
      "568 568 RGI60-13.18541\n",
      "569 569 RGI60-13.18598\n",
      "570 570 RGI60-13.18633\n",
      "571 571 RGI60-13.18671\n",
      "572 572 RGI60-13.18677\n",
      "573 573 RGI60-13.18688\n",
      "574 574 RGI60-13.18710\n",
      "575 575 RGI60-13.18735\n",
      "576 576 RGI60-13.18758\n",
      "577 577 RGI60-13.18772\n",
      "578 578 RGI60-13.18782\n",
      "579 579 RGI60-13.18789\n",
      "580 580 RGI60-13.18809\n",
      "581 581 RGI60-13.18816\n",
      "582 582 RGI60-13.18832\n",
      "583 583 RGI60-13.18834\n",
      "584 584 RGI60-13.18835\n",
      "585 585 RGI60-13.18887\n",
      "586 586 RGI60-13.18923\n",
      "587 587 RGI60-13.18925\n",
      "588 588 RGI60-13.18930\n",
      "589 589 RGI60-13.18939\n",
      "590 590 RGI60-13.18940\n",
      "591 591 RGI60-13.18943\n",
      "592 592 RGI60-13.18950\n",
      "593 593 RGI60-13.18951\n",
      "594 594 RGI60-13.18958\n",
      "595 595 RGI60-13.18959\n",
      "596 596 RGI60-13.18961\n",
      "597 597 RGI60-13.18971\n",
      "598 598 RGI60-13.18976\n",
      "599 599 RGI60-13.19006\n",
      "600 600 RGI60-13.19011\n",
      "601 601 RGI60-13.19039\n",
      "602 602 RGI60-13.19049\n",
      "603 603 RGI60-13.19053\n",
      "604 604 RGI60-13.19065\n",
      "605 605 RGI60-13.19070\n",
      "606 606 RGI60-13.19075\n",
      "607 607 RGI60-13.19080\n",
      "608 608 RGI60-13.19153\n",
      "609 609 RGI60-13.19160\n",
      "610 610 RGI60-13.19167\n",
      "611 611 RGI60-13.19175\n",
      "612 612 RGI60-13.19184\n",
      "613 613 RGI60-13.19271\n",
      "614 614 RGI60-13.19273\n",
      "615 615 RGI60-13.19275\n",
      "616 616 RGI60-13.19288\n",
      "617 617 RGI60-13.19296\n",
      "618 618 RGI60-13.19297\n",
      "619 619 RGI60-13.19298\n",
      "620 620 RGI60-13.19305\n",
      "621 621 RGI60-13.19321\n",
      "622 622 RGI60-13.19329\n",
      "623 623 RGI60-13.19340\n",
      "624 624 RGI60-13.19360\n",
      "625 625 RGI60-13.19370\n",
      "626 626 RGI60-13.19410\n",
      "627 627 RGI60-13.19419\n",
      "628 628 RGI60-13.19450\n",
      "629 629 RGI60-13.19492\n",
      "630 630 RGI60-13.19515\n",
      "631 631 RGI60-13.19539\n",
      "632 632 RGI60-13.19542\n",
      "633 633 RGI60-13.19568\n",
      "634 634 RGI60-13.19594\n",
      "635 635 RGI60-13.19599\n",
      "636 636 RGI60-13.19631\n",
      "637 637 RGI60-13.19632\n",
      "638 638 RGI60-13.19634\n",
      "639 639 RGI60-13.19641\n",
      "640 640 RGI60-13.19643\n",
      "641 641 RGI60-13.19645\n",
      "642 642 RGI60-13.19648\n",
      "643 643 RGI60-13.19649\n",
      "644 644 RGI60-13.19651\n",
      "645 645 RGI60-13.19661\n",
      "646 646 RGI60-13.19664\n",
      "647 647 RGI60-13.19669\n",
      "648 648 RGI60-13.19691\n",
      "649 649 RGI60-13.19692\n",
      "650 650 RGI60-13.19698\n",
      "651 651 RGI60-13.19750\n",
      "652 652 RGI60-13.19757\n",
      "653 653 RGI60-13.19758\n",
      "654 654 RGI60-13.19763\n",
      "655 655 RGI60-13.19776\n",
      "656 656 RGI60-13.19795\n",
      "657 657 RGI60-13.19797\n",
      "658 658 RGI60-13.19806\n",
      "659 659 RGI60-13.19807\n",
      "660 660 RGI60-13.19824\n",
      "661 661 RGI60-13.19847\n",
      "662 662 RGI60-13.19851\n",
      "663 663 RGI60-13.19863\n",
      "664 664 RGI60-13.19869\n",
      "665 665 RGI60-13.19874\n",
      "666 666 RGI60-13.19875\n",
      "667 667 RGI60-13.19878\n",
      "668 668 RGI60-13.19891\n",
      "669 669 RGI60-13.19897\n",
      "670 670 RGI60-13.19920\n",
      "671 671 RGI60-13.19942\n",
      "672 672 RGI60-13.19943\n",
      "673 673 RGI60-13.19981\n",
      "674 674 RGI60-13.20005\n",
      "675 675 RGI60-13.20012\n",
      "676 676 RGI60-13.20035\n",
      "677 677 RGI60-13.20038\n",
      "678 678 RGI60-13.20043\n",
      "679 679 RGI60-13.20111\n",
      "680 680 RGI60-13.20112\n",
      "681 681 RGI60-13.20114\n",
      "682 682 RGI60-13.20139\n",
      "683 683 RGI60-13.20143\n",
      "684 684 RGI60-13.20147\n",
      "685 685 RGI60-13.20170\n",
      "686 686 RGI60-13.20210\n",
      "687 687 RGI60-13.20217\n",
      "688 688 RGI60-13.20218\n",
      "689 689 RGI60-13.20222\n",
      "690 690 RGI60-13.20231\n",
      "691 691 RGI60-13.20238\n",
      "692 692 RGI60-13.20239\n",
      "693 693 RGI60-13.20255\n",
      "694 694 RGI60-13.20268\n",
      "695 695 RGI60-13.20272\n",
      "696 696 RGI60-13.20283\n",
      "697 697 RGI60-13.20293\n",
      "698 698 RGI60-13.20301\n",
      "699 699 RGI60-13.20324\n",
      "700 700 RGI60-13.20466\n",
      "701 701 RGI60-13.20471\n",
      "702 702 RGI60-13.20484\n",
      "703 703 RGI60-13.20494\n",
      "704 704 RGI60-13.20500\n",
      "705 705 RGI60-13.20530\n",
      "706 706 RGI60-13.20556\n",
      "707 707 RGI60-13.20557\n",
      "708 708 RGI60-13.20561\n",
      "709 709 RGI60-13.20571\n",
      "710 710 RGI60-13.20592\n",
      "711 711 RGI60-13.20608\n",
      "712 712 RGI60-13.20626\n",
      "713 713 RGI60-13.20920\n",
      "714 714 RGI60-13.21192\n",
      "715 715 RGI60-13.21194\n",
      "716 716 RGI60-13.21197\n",
      "717 717 RGI60-13.21216\n",
      "718 718 RGI60-13.21219\n",
      "719 719 RGI60-13.21324\n",
      "720 720 RGI60-13.21357\n",
      "721 721 RGI60-13.21451\n",
      "722 722 RGI60-13.21523\n",
      "723 723 RGI60-13.21538\n",
      "724 724 RGI60-13.21551\n",
      "725 725 RGI60-13.21552\n",
      "726 726 RGI60-13.21556\n",
      "727 727 RGI60-13.21579\n",
      "728 728 RGI60-13.21582\n",
      "729 729 RGI60-13.21583\n",
      "730 730 RGI60-13.21595\n",
      "731 731 RGI60-13.21703\n",
      "732 732 RGI60-13.22248\n",
      "733 733 RGI60-13.22260\n",
      "734 734 RGI60-13.22267\n",
      "735 735 RGI60-13.22268\n",
      "736 736 RGI60-13.22276\n",
      "737 737 RGI60-13.22289\n",
      "738 738 RGI60-13.22293\n",
      "739 739 RGI60-13.22297\n",
      "740 740 RGI60-13.22317\n",
      "741 741 RGI60-13.22319\n",
      "742 742 RGI60-13.22329\n",
      "743 743 RGI60-13.22359\n",
      "744 744 RGI60-13.22373\n",
      "745 745 RGI60-13.22375\n",
      "746 746 RGI60-13.22391\n",
      "747 747 RGI60-13.22394\n",
      "748 748 RGI60-13.22444\n",
      "749 749 RGI60-13.22514\n",
      "750 750 RGI60-13.22516\n",
      "751 751 RGI60-13.22559\n",
      "752 752 RGI60-13.22563\n",
      "753 753 RGI60-13.22573\n",
      "754 754 RGI60-13.22617\n",
      "755 755 RGI60-13.22645\n",
      "756 756 RGI60-13.22661\n",
      "757 757 RGI60-13.22803\n",
      "758 758 RGI60-13.22898\n",
      "759 759 RGI60-13.23272\n",
      "760 760 RGI60-13.23346\n",
      "761 761 RGI60-13.23358\n",
      "762 762 RGI60-13.24480\n",
      "763 763 RGI60-13.24609\n",
      "764 764 RGI60-13.24655\n",
      "765 765 RGI60-13.25208\n",
      "766 766 RGI60-13.25841\n",
      "767 767 RGI60-13.25900\n",
      "768 768 RGI60-13.25912\n",
      "769 769 RGI60-13.25920\n",
      "770 770 RGI60-13.26239\n",
      "771 771 RGI60-13.26378\n",
      "772 772 RGI60-13.26415\n",
      "773 773 RGI60-13.26909\n",
      "774 774 RGI60-13.26911\n",
      "775 775 RGI60-13.26922\n",
      "776 776 RGI60-13.26923\n",
      "777 777 RGI60-13.26932\n",
      "778 778 RGI60-13.26954\n",
      "779 779 RGI60-13.26961\n",
      "780 780 RGI60-13.27561\n",
      "781 781 RGI60-13.27587\n",
      "782 782 RGI60-13.27618\n",
      "783 783 RGI60-13.27693\n",
      "784 784 RGI60-13.28457\n",
      "785 785 RGI60-13.28988\n",
      "786 786 RGI60-13.28996\n",
      "787 787 RGI60-13.29096\n",
      "788 788 RGI60-13.29451\n",
      "789 789 RGI60-13.30140\n",
      "790 790 RGI60-13.30301\n",
      "791 791 RGI60-13.30346\n",
      "792 792 RGI60-13.30360\n",
      "793 793 RGI60-13.30392\n",
      "794 794 RGI60-13.30407\n",
      "795 795 RGI60-13.30416\n",
      "796 796 RGI60-13.30654\n",
      "797 797 RGI60-13.30692\n",
      "798 798 RGI60-13.30875\n",
      "799 799 RGI60-13.30878\n",
      "800 800 RGI60-13.30887\n",
      "801 801 RGI60-13.30888\n",
      "802 802 RGI60-13.30913\n",
      "803 803 RGI60-13.30943\n",
      "804 804 RGI60-13.31067\n",
      "805 805 RGI60-13.31071\n",
      "806 806 RGI60-13.31079\n",
      "807 807 RGI60-13.31095\n",
      "808 808 RGI60-13.31120\n",
      "809 809 RGI60-13.31151\n",
      "810 810 RGI60-13.31201\n",
      "811 811 RGI60-13.31210\n",
      "812 812 RGI60-13.31227\n",
      "813 813 RGI60-13.31255\n",
      "814 814 RGI60-13.31276\n",
      "815 815 RGI60-13.31285\n",
      "816 816 RGI60-13.31303\n",
      "817 817 RGI60-13.35663\n",
      "818 818 RGI60-13.35771\n",
      "819 819 RGI60-13.36364\n",
      "820 820 RGI60-13.36391\n",
      "821 821 RGI60-13.36475\n",
      "822 822 RGI60-13.36488\n",
      "823 823 RGI60-13.36495\n",
      "824 824 RGI60-13.36513\n",
      "825 825 RGI60-13.36523\n",
      "826 826 RGI60-13.36529\n",
      "827 827 RGI60-13.36534\n",
      "828 828 RGI60-13.36578\n",
      "829 829 RGI60-13.36584\n",
      "830 830 RGI60-13.36592\n",
      "831 831 RGI60-13.36603\n",
      "832 832 RGI60-13.36613\n",
      "833 833 RGI60-13.36620\n",
      "834 834 RGI60-13.36625\n",
      "835 835 RGI60-13.36656\n",
      "836 836 RGI60-13.36662\n",
      "837 837 RGI60-13.36686\n",
      "838 838 RGI60-13.36690\n",
      "839 839 RGI60-13.36691\n",
      "840 840 RGI60-13.36754\n",
      "841 841 RGI60-13.36755\n",
      "842 842 RGI60-13.36767\n",
      "843 843 RGI60-13.36768\n",
      "844 844 RGI60-13.36790\n",
      "845 845 RGI60-13.36799\n",
      "846 846 RGI60-13.37134\n",
      "847 847 RGI60-13.37143\n",
      "848 848 RGI60-13.37145\n",
      "849 849 RGI60-13.37166\n",
      "850 850 RGI60-13.37184\n",
      "851 851 RGI60-13.37187\n",
      "852 852 RGI60-13.37188\n",
      "853 853 RGI60-13.37193\n",
      "854 854 RGI60-13.37226\n",
      "855 855 RGI60-13.37228\n",
      "856 856 RGI60-13.37234\n",
      "857 857 RGI60-13.37236\n",
      "858 858 RGI60-13.37246\n",
      "859 859 RGI60-13.37251\n",
      "860 860 RGI60-13.37258\n",
      "861 861 RGI60-13.37269\n",
      "862 862 RGI60-13.37368\n",
      "863 863 RGI60-13.37370\n",
      "864 864 RGI60-13.37377\n",
      "865 865 RGI60-13.37387\n",
      "866 866 RGI60-13.37418\n",
      "867 867 RGI60-13.37419\n",
      "868 868 RGI60-13.37423\n",
      "869 869 RGI60-13.37682\n",
      "870 870 RGI60-13.37753\n",
      "871 871 RGI60-13.37967\n",
      "872 872 RGI60-13.38005\n",
      "873 873 RGI60-13.38008\n",
      "874 874 RGI60-13.38704\n",
      "875 875 RGI60-13.38733\n",
      "876 876 RGI60-13.38750\n",
      "877 877 RGI60-13.38768\n",
      "878 878 RGI60-13.38803\n",
      "879 879 RGI60-13.38870\n",
      "880 880 RGI60-13.38924\n",
      "881 881 RGI60-13.38932\n",
      "882 882 RGI60-13.38986\n",
      "883 883 RGI60-13.39081\n",
      "884 884 RGI60-13.39100\n",
      "885 885 RGI60-13.39107\n",
      "886 886 RGI60-13.39217\n",
      "887 887 RGI60-13.40303\n",
      "888 888 RGI60-13.40337\n",
      "889 889 RGI60-13.40442\n",
      "890 890 RGI60-13.40528\n",
      "891 891 RGI60-13.40536\n",
      "892 892 RGI60-13.40548\n",
      "893 893 RGI60-13.40580\n",
      "894 894 RGI60-13.40583\n",
      "895 895 RGI60-13.40649\n",
      "896 896 RGI60-13.40659\n",
      "897 897 RGI60-13.40696\n",
      "898 898 RGI60-13.40768\n",
      "899 899 RGI60-13.41247\n",
      "900 900 RGI60-13.41279\n",
      "901 901 RGI60-13.41283\n",
      "902 902 RGI60-13.41411\n",
      "903 903 RGI60-13.41415\n",
      "904 904 RGI60-13.41416\n",
      "905 905 RGI60-13.41549\n",
      "906 906 RGI60-13.41615\n",
      "907 907 RGI60-13.41617\n",
      "908 908 RGI60-13.41618\n",
      "909 909 RGI60-13.41621\n",
      "910 910 RGI60-13.41623\n",
      "911 911 RGI60-13.41633\n",
      "912 912 RGI60-13.41657\n",
      "913 913 RGI60-13.41670\n",
      "914 914 RGI60-13.41682\n",
      "915 915 RGI60-13.41683\n",
      "916 916 RGI60-13.41695\n",
      "917 917 RGI60-13.41704\n",
      "918 918 RGI60-13.41724\n",
      "919 919 RGI60-13.41737\n",
      "920 920 RGI60-13.41740\n",
      "921 921 RGI60-13.41756\n",
      "922 922 RGI60-13.41757\n",
      "923 923 RGI60-13.41762\n",
      "924 924 RGI60-13.41765\n",
      "925 925 RGI60-13.41767\n",
      "926 926 RGI60-13.41777\n",
      "927 927 RGI60-13.41801\n",
      "928 928 RGI60-13.41803\n",
      "929 929 RGI60-13.41818\n",
      "930 930 RGI60-13.41825\n",
      "931 931 RGI60-13.41846\n",
      "932 932 RGI60-13.41851\n",
      "933 933 RGI60-13.41901\n",
      "934 934 RGI60-13.41903\n",
      "935 935 RGI60-13.41940\n",
      "936 936 RGI60-13.42066\n",
      "937 937 RGI60-13.42072\n",
      "938 938 RGI60-13.42103\n",
      "939 939 RGI60-13.42110\n",
      "940 940 RGI60-13.42153\n",
      "941 941 RGI60-13.42174\n",
      "942 942 RGI60-13.42187\n",
      "943 943 RGI60-13.42193\n",
      "944 944 RGI60-13.42198\n",
      "945 945 RGI60-13.42199\n",
      "946 946 RGI60-13.42204\n",
      "947 947 RGI60-13.42205\n",
      "948 948 RGI60-13.42206\n",
      "949 949 RGI60-13.42209\n",
      "950 950 RGI60-13.42210\n",
      "951 951 RGI60-13.42211\n",
      "952 952 RGI60-13.42222\n",
      "953 953 RGI60-13.42240\n",
      "954 954 RGI60-13.42274\n",
      "955 955 RGI60-13.42280\n",
      "956 956 RGI60-13.42282\n",
      "957 957 RGI60-13.42285\n",
      "958 958 RGI60-13.42291\n",
      "959 959 RGI60-13.42301\n",
      "960 960 RGI60-13.42307\n",
      "961 961 RGI60-13.42308\n",
      "962 962 RGI60-13.42320\n",
      "963 963 RGI60-13.42321\n",
      "964 964 RGI60-13.42322\n",
      "965 965 RGI60-13.42324\n",
      "966 966 RGI60-13.42331\n",
      "967 967 RGI60-13.42334\n",
      "968 968 RGI60-13.42348\n",
      "969 969 RGI60-13.42355\n",
      "970 970 RGI60-13.42369\n",
      "971 971 RGI60-13.42381\n",
      "972 972 RGI60-13.42458\n",
      "973 973 RGI60-13.42494\n",
      "974 974 RGI60-13.42495\n",
      "975 975 RGI60-13.42497\n",
      "976 976 RGI60-13.42513\n",
      "977 977 RGI60-13.42516\n",
      "978 978 RGI60-13.42525\n",
      "979 979 RGI60-13.42537\n",
      "980 980 RGI60-13.42551\n",
      "981 981 RGI60-13.42676\n",
      "982 982 RGI60-13.42780\n",
      "983 983 RGI60-13.42791\n",
      "984 984 RGI60-13.42821\n",
      "985 985 RGI60-13.42932\n",
      "986 986 RGI60-13.42994\n",
      "987 987 RGI60-13.42999\n",
      "988 988 RGI60-13.43015\n",
      "989 989 RGI60-13.43033\n",
      "990 990 RGI60-13.43103\n",
      "991 991 RGI60-13.43127\n",
      "992 992 RGI60-13.43149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993 993 RGI60-13.43150\n",
      "994 994 RGI60-13.43153\n",
      "995 995 RGI60-13.43163\n",
      "996 996 RGI60-13.43164\n",
      "997 997 RGI60-13.43172\n",
      "998 998 RGI60-13.43174\n",
      "999 999 RGI60-13.43185\n",
      "1000 1000 RGI60-13.43207\n",
      "1001 1001 RGI60-13.43232\n",
      "1002 1002 RGI60-13.43239\n",
      "1003 1003 RGI60-13.43242\n",
      "1004 1004 RGI60-13.43252\n",
      "1005 1005 RGI60-13.43256\n",
      "1006 1006 RGI60-13.43259\n",
      "1007 1007 RGI60-13.43261\n",
      "1008 1008 RGI60-13.43263\n",
      "1009 1009 RGI60-13.43266\n",
      "1010 1010 RGI60-13.43267\n",
      "1011 1011 RGI60-13.43274\n",
      "1012 1012 RGI60-13.43277\n",
      "1013 1013 RGI60-13.43295\n",
      "1014 1014 RGI60-13.43307\n",
      "1015 1015 RGI60-13.43308\n",
      "1016 1016 RGI60-13.43319\n",
      "1017 1017 RGI60-13.43328\n",
      "1018 1018 RGI60-13.43355\n",
      "1019 1019 RGI60-13.43380\n",
      "1020 1020 RGI60-13.43388\n",
      "1021 1021 RGI60-13.43427\n",
      "1022 1022 RGI60-13.43433\n",
      "1023 1023 RGI60-13.43453\n",
      "1024 1024 RGI60-13.43460\n",
      "1025 1025 RGI60-13.43462\n",
      "1026 1026 RGI60-13.43464\n",
      "1027 1027 RGI60-13.43466\n",
      "1028 1028 RGI60-13.43469\n",
      "1029 1029 RGI60-13.43471\n",
      "1030 1030 RGI60-13.43474\n",
      "1031 1031 RGI60-13.43483\n",
      "1032 1032 RGI60-13.43491\n",
      "1033 1033 RGI60-13.43496\n",
      "1034 1034 RGI60-13.43501\n",
      "1035 1035 RGI60-13.43508\n",
      "1036 1036 RGI60-13.43509\n",
      "1037 1037 RGI60-13.43528\n",
      "1038 1038 RGI60-13.43551\n",
      "1039 1039 RGI60-13.43552\n",
      "1040 1040 RGI60-13.43556\n",
      "1041 1041 RGI60-13.43563\n",
      "1042 1042 RGI60-13.43569\n",
      "1043 1043 RGI60-13.43578\n",
      "1044 1044 RGI60-13.43613\n",
      "1045 1045 RGI60-13.43626\n",
      "1046 1046 RGI60-13.43639\n",
      "1047 1047 RGI60-13.43641\n",
      "1048 1048 RGI60-13.43663\n",
      "1049 1049 RGI60-13.43711\n",
      "1050 1050 RGI60-13.43784\n",
      "1051 1051 RGI60-13.43787\n",
      "1052 1052 RGI60-13.43790\n",
      "1053 1053 RGI60-13.43803\n",
      "1054 1054 RGI60-13.43863\n",
      "1055 1055 RGI60-13.43866\n",
      "1056 1056 RGI60-13.43870\n",
      "1057 1057 RGI60-13.43893\n",
      "1058 1058 RGI60-13.43896\n",
      "1059 1059 RGI60-13.43897\n",
      "1060 1060 RGI60-13.43901\n",
      "1061 1061 RGI60-13.43928\n",
      "1062 1062 RGI60-13.43942\n",
      "1063 1063 RGI60-13.43951\n",
      "1064 1064 RGI60-13.43955\n",
      "1065 1065 RGI60-13.43962\n",
      "1066 1066 RGI60-13.43964\n",
      "1067 1067 RGI60-13.44010\n",
      "1068 1068 RGI60-13.44848\n",
      "1069 1069 RGI60-13.44861\n",
      "1070 1070 RGI60-13.45930\n",
      "1071 1071 RGI60-13.46390\n",
      "1072 1072 RGI60-13.46910\n",
      "1073 1073 RGI60-13.47119\n",
      "1074 1074 RGI60-13.47152\n",
      "1075 1075 RGI60-13.47187\n",
      "1076 1076 RGI60-13.47202\n",
      "1077 1077 RGI60-13.47423\n",
      "1078 1078 RGI60-13.47540\n",
      "1079 1079 RGI60-13.47598\n",
      "1080 1080 RGI60-13.47605\n",
      "1081 1081 RGI60-13.49384\n",
      "1082 1082 RGI60-13.49394\n",
      "1083 1083 RGI60-13.49770\n",
      "1084 1084 RGI60-13.49789\n",
      "1085 1085 RGI60-13.50127\n",
      "1086 1086 RGI60-13.50649\n",
      "1087 1087 RGI60-13.50654\n",
      "1088 1088 RGI60-13.50712\n",
      "1089 1089 RGI60-13.54431\n",
      "1090 1090 RGI60-14.00005\n",
      "1091 1091 RGI60-14.00018\n",
      "1092 1092 RGI60-14.00032\n",
      "1093 1093 RGI60-14.00036\n",
      "1094 1094 RGI60-14.00043\n",
      "1095 1095 RGI60-14.00057\n",
      "1096 1096 RGI60-14.00072\n",
      "1097 1097 RGI60-14.00104\n",
      "1098 1098 RGI60-14.00145\n",
      "1099 1099 RGI60-14.00163\n",
      "1100 1100 RGI60-14.00222\n",
      "1101 1101 RGI60-14.00287\n",
      "1102 1102 RGI60-14.00353\n",
      "1103 1103 RGI60-14.00363\n",
      "1104 1104 RGI60-14.00471\n",
      "1105 1105 RGI60-14.00543\n",
      "1106 1106 RGI60-14.00548\n",
      "1107 1107 RGI60-14.00555\n",
      "1108 1108 RGI60-14.00595\n",
      "1109 1109 RGI60-14.00700\n",
      "1110 1110 RGI60-14.00722\n",
      "1111 1111 RGI60-14.00742\n",
      "1112 1112 RGI60-14.00764\n",
      "1113 1113 RGI60-14.00767\n",
      "1114 1114 RGI60-14.00796\n",
      "1115 1115 RGI60-14.00805\n",
      "1116 1116 RGI60-14.00850\n",
      "1117 1117 RGI60-14.00891\n",
      "1118 1118 RGI60-14.00899\n",
      "1119 1119 RGI60-14.00952\n",
      "1120 1120 RGI60-14.01001\n",
      "1121 1121 RGI60-14.01022\n",
      "1122 1122 RGI60-14.01070\n",
      "1123 1123 RGI60-14.01075\n",
      "1124 1124 RGI60-14.01165\n",
      "1125 1125 RGI60-14.01191\n",
      "1126 1126 RGI60-14.01206\n",
      "1127 1127 RGI60-14.01226\n",
      "1128 1128 RGI60-14.01228\n",
      "1129 1129 RGI60-14.01244\n",
      "1130 1130 RGI60-14.01285\n",
      "1131 1131 RGI60-14.01361\n",
      "1132 1132 RGI60-14.01379\n",
      "1133 1133 RGI60-14.01391\n",
      "1134 1134 RGI60-14.01400\n",
      "1135 1135 RGI60-14.01409\n",
      "1136 1136 RGI60-14.01425\n",
      "1137 1137 RGI60-14.01454\n",
      "1138 1138 RGI60-14.01474\n",
      "1139 1139 RGI60-14.01489\n",
      "1140 1140 RGI60-14.01511\n",
      "1141 1141 RGI60-14.01517\n",
      "1142 1142 RGI60-14.01519\n",
      "1143 1143 RGI60-14.01541\n",
      "1144 1144 RGI60-14.01549\n",
      "1145 1145 RGI60-14.01565\n",
      "1146 1146 RGI60-14.01580\n",
      "1147 1147 RGI60-14.01586\n",
      "1148 1148 RGI60-14.01589\n",
      "1149 1149 RGI60-14.01597\n",
      "1150 1150 RGI60-14.01606\n",
      "1151 1151 RGI60-14.01618\n",
      "1152 1152 RGI60-14.01623\n",
      "1153 1153 RGI60-14.01649\n",
      "1154 1154 RGI60-14.01653\n",
      "1155 1155 RGI60-14.01670\n",
      "1156 1156 RGI60-14.01709\n",
      "1157 1157 RGI60-14.01733\n",
      "1158 1158 RGI60-14.01771\n",
      "1159 1159 RGI60-14.01798\n",
      "1160 1160 RGI60-14.01807\n",
      "1161 1161 RGI60-14.01823\n",
      "1162 1162 RGI60-14.01840\n",
      "1163 1163 RGI60-14.01847\n",
      "1164 1164 RGI60-14.01853\n",
      "1165 1165 RGI60-14.01869\n",
      "1166 1166 RGI60-14.01893\n",
      "1167 1167 RGI60-14.01904\n",
      "1168 1168 RGI60-14.01910\n",
      "1169 1169 RGI60-14.01922\n",
      "1170 1170 RGI60-14.01940\n",
      "1171 1171 RGI60-14.01960\n",
      "1172 1172 RGI60-14.01964\n",
      "1173 1173 RGI60-14.01974\n",
      "1174 1174 RGI60-14.01996\n",
      "1175 1175 RGI60-14.01998\n",
      "1176 1176 RGI60-14.02010\n",
      "1177 1177 RGI60-14.02024\n",
      "1178 1178 RGI60-14.02029\n",
      "1179 1179 RGI60-14.02036\n",
      "1180 1180 RGI60-14.02047\n",
      "1181 1181 RGI60-14.02071\n",
      "1182 1182 RGI60-14.02091\n",
      "1183 1183 RGI60-14.02113\n",
      "1184 1184 RGI60-14.02122\n",
      "1185 1185 RGI60-14.02132\n",
      "1186 1186 RGI60-14.02136\n",
      "1187 1187 RGI60-14.02141\n",
      "1188 1188 RGI60-14.02144\n",
      "1189 1189 RGI60-14.02150\n",
      "1190 1190 RGI60-14.02172\n",
      "1191 1191 RGI60-14.02183\n",
      "1192 1192 RGI60-14.02188\n",
      "1193 1193 RGI60-14.02192\n",
      "1194 1194 RGI60-14.02205\n",
      "1195 1195 RGI60-14.02221\n",
      "1196 1196 RGI60-14.02238\n",
      "1197 1197 RGI60-14.02249\n",
      "1198 1198 RGI60-14.02261\n",
      "1199 1199 RGI60-14.02289\n",
      "1200 1200 RGI60-14.02307\n",
      "1201 1201 RGI60-14.02328\n",
      "1202 1202 RGI60-14.02333\n",
      "1203 1203 RGI60-14.02343\n",
      "1204 1204 RGI60-14.02357\n",
      "1205 1205 RGI60-14.02371\n",
      "1206 1206 RGI60-14.02381\n",
      "1207 1207 RGI60-14.02398\n",
      "1208 1208 RGI60-14.02411\n",
      "1209 1209 RGI60-14.02418\n",
      "1210 1210 RGI60-14.02428\n",
      "1211 1211 RGI60-14.02454\n",
      "1212 1212 RGI60-14.02482\n",
      "1213 1213 RGI60-14.02515\n",
      "1214 1214 RGI60-14.02535\n",
      "1215 1215 RGI60-14.02539\n",
      "1216 1216 RGI60-14.02543\n",
      "1217 1217 RGI60-14.02549\n",
      "1218 1218 RGI60-14.02550\n",
      "1219 1219 RGI60-14.02554\n",
      "1220 1220 RGI60-14.02568\n",
      "1221 1221 RGI60-14.02587\n",
      "1222 1222 RGI60-14.02624\n",
      "1223 1223 RGI60-14.02653\n",
      "1224 1224 RGI60-14.02674\n",
      "1225 1225 RGI60-14.02701\n",
      "1226 1226 RGI60-14.02717\n",
      "1227 1227 RGI60-14.02761\n",
      "1228 1228 RGI60-14.02764\n",
      "1229 1229 RGI60-14.02765\n",
      "1230 1230 RGI60-14.02794\n",
      "1231 1231 RGI60-14.02806\n",
      "1232 1232 RGI60-14.02849\n",
      "1233 1233 RGI60-14.02863\n",
      "1234 1234 RGI60-14.02882\n",
      "1235 1235 RGI60-14.02898\n",
      "1236 1236 RGI60-14.02920\n",
      "1237 1237 RGI60-14.02963\n",
      "1238 1238 RGI60-14.02976\n",
      "1239 1239 RGI60-14.03007\n",
      "1240 1240 RGI60-14.03017\n",
      "1241 1241 RGI60-14.03042\n",
      "1242 1242 RGI60-14.03055\n",
      "1243 1243 RGI60-14.03061\n",
      "1244 1244 RGI60-14.03092\n",
      "1245 1245 RGI60-14.03121\n",
      "1246 1246 RGI60-14.03123\n",
      "1247 1247 RGI60-14.03138\n",
      "1248 1248 RGI60-14.03154\n",
      "1249 1249 RGI60-14.03188\n",
      "1250 1250 RGI60-14.03204\n",
      "1251 1251 RGI60-14.03224\n",
      "1252 1252 RGI60-14.03238\n",
      "1253 1253 RGI60-14.03250\n",
      "1254 1254 RGI60-14.03263\n",
      "1255 1255 RGI60-14.03326\n",
      "1256 1256 RGI60-14.03334\n",
      "1257 1257 RGI60-14.03350\n",
      "1258 1258 RGI60-14.03394\n",
      "1259 1259 RGI60-14.03405\n",
      "1260 1260 RGI60-14.03408\n",
      "1261 1261 RGI60-14.03439\n",
      "1262 1262 RGI60-14.03513\n",
      "1263 1263 RGI60-14.03658\n",
      "1264 1264 RGI60-14.03683\n",
      "1265 1265 RGI60-14.03694\n",
      "1266 1266 RGI60-14.03801\n",
      "1267 1267 RGI60-14.03827\n",
      "1268 1268 RGI60-14.03837\n",
      "1269 1269 RGI60-14.03869\n",
      "1270 1270 RGI60-14.03870\n",
      "1271 1271 RGI60-14.03893\n",
      "1272 1272 RGI60-14.03912\n",
      "1273 1273 RGI60-14.03950\n",
      "1274 1274 RGI60-14.04004\n",
      "1275 1275 RGI60-14.04021\n",
      "1276 1276 RGI60-14.04028\n",
      "1277 1277 RGI60-14.04040\n",
      "1278 1278 RGI60-14.04053\n",
      "1279 1279 RGI60-14.04068\n",
      "1280 1280 RGI60-14.04081\n",
      "1281 1281 RGI60-14.04085\n",
      "1282 1282 RGI60-14.04105\n",
      "1283 1283 RGI60-14.04120\n",
      "1284 1284 RGI60-14.04139\n",
      "1285 1285 RGI60-14.04160\n",
      "1286 1286 RGI60-14.04167\n",
      "1287 1287 RGI60-14.04178\n",
      "1288 1288 RGI60-14.04197\n",
      "1289 1289 RGI60-14.04209\n",
      "1290 1290 RGI60-14.04254\n",
      "1291 1291 RGI60-14.04277\n",
      "1292 1292 RGI60-14.04291\n",
      "1293 1293 RGI60-14.04328\n",
      "1294 1294 RGI60-14.04404\n",
      "1295 1295 RGI60-14.04411\n",
      "1296 1296 RGI60-14.04445\n",
      "1297 1297 RGI60-14.04449\n",
      "1298 1298 RGI60-14.04451\n",
      "1299 1299 RGI60-14.04452\n",
      "1300 1300 RGI60-14.04471\n",
      "1301 1301 RGI60-14.04473\n",
      "1302 1302 RGI60-14.04477\n",
      "1303 1303 RGI60-14.04498\n",
      "1304 1304 RGI60-14.04505\n",
      "1305 1305 RGI60-14.04515\n",
      "1306 1306 RGI60-14.04531\n",
      "1307 1307 RGI60-14.04533\n",
      "1308 1308 RGI60-14.04557\n",
      "1309 1309 RGI60-14.04570\n",
      "1310 1310 RGI60-14.04585\n",
      "1311 1311 RGI60-14.04587\n",
      "1312 1312 RGI60-14.04590\n",
      "1313 1313 RGI60-14.04593\n",
      "1314 1314 RGI60-14.04610\n",
      "1315 1315 RGI60-14.04621\n",
      "1316 1316 RGI60-14.04622\n",
      "1317 1317 RGI60-14.04625\n",
      "1318 1318 RGI60-14.04628\n",
      "1319 1319 RGI60-14.04638\n",
      "1320 1320 RGI60-14.04643\n",
      "1321 1321 RGI60-14.04668\n",
      "1322 1322 RGI60-14.04680\n",
      "1323 1323 RGI60-14.04690\n",
      "1324 1324 RGI60-14.04697\n",
      "1325 1325 RGI60-14.04701\n",
      "1326 1326 RGI60-14.04706\n",
      "1327 1327 RGI60-14.04731\n",
      "1328 1328 RGI60-14.04744\n",
      "1329 1329 RGI60-14.04756\n",
      "1330 1330 RGI60-14.04766\n",
      "1331 1331 RGI60-14.04777\n",
      "1332 1332 RGI60-14.04800\n",
      "1333 1333 RGI60-14.04807\n",
      "1334 1334 RGI60-14.04818\n",
      "1335 1335 RGI60-14.04825\n",
      "1336 1336 RGI60-14.04828\n",
      "1337 1337 RGI60-14.04840\n",
      "1338 1338 RGI60-14.04856\n",
      "1339 1339 RGI60-14.04868\n",
      "1340 1340 RGI60-14.04869\n",
      "1341 1341 RGI60-14.04872\n",
      "1342 1342 RGI60-14.04881\n",
      "1343 1343 RGI60-14.04884\n",
      "1344 1344 RGI60-14.04900\n",
      "1345 1345 RGI60-14.04908\n",
      "1346 1346 RGI60-14.04933\n",
      "1347 1347 RGI60-14.04942\n",
      "1348 1348 RGI60-14.04944\n",
      "1349 1349 RGI60-14.04945\n",
      "1350 1350 RGI60-14.04952\n",
      "1351 1351 RGI60-14.04963\n",
      "1352 1352 RGI60-14.04975\n",
      "1353 1353 RGI60-14.04980\n",
      "1354 1354 RGI60-14.04984\n",
      "1355 1355 RGI60-14.04989\n",
      "1356 1356 RGI60-14.04996\n",
      "1357 1357 RGI60-14.05006\n",
      "1358 1358 RGI60-14.05029\n",
      "1359 1359 RGI60-14.05033\n",
      "1360 1360 RGI60-14.05048\n",
      "1361 1361 RGI60-14.05085\n",
      "1362 1362 RGI60-14.05088\n",
      "1363 1363 RGI60-14.05096\n",
      "1364 1364 RGI60-14.05099\n",
      "1365 1365 RGI60-14.05153\n",
      "1366 1366 RGI60-14.05162\n",
      "1367 1367 RGI60-14.05269\n",
      "1368 1368 RGI60-14.05287\n",
      "1369 1369 RGI60-14.05374\n",
      "1370 1370 RGI60-14.05429\n",
      "1371 1371 RGI60-14.05440\n",
      "1372 1372 RGI60-14.05444\n",
      "1373 1373 RGI60-14.05446\n",
      "1374 1374 RGI60-14.05480\n",
      "1375 1375 RGI60-14.05485\n",
      "1376 1376 RGI60-14.05507\n",
      "1377 1377 RGI60-14.05537\n",
      "1378 1378 RGI60-14.05540\n",
      "1379 1379 RGI60-14.05543\n",
      "1380 1380 RGI60-14.05548\n",
      "1381 1381 RGI60-14.05551\n",
      "1382 1382 RGI60-14.05553\n",
      "1383 1383 RGI60-14.05560\n",
      "1384 1384 RGI60-14.05568\n",
      "1385 1385 RGI60-14.05618\n",
      "1386 1386 RGI60-14.05668\n",
      "1387 1387 RGI60-14.05671\n",
      "1388 1388 RGI60-14.05675\n",
      "1389 1389 RGI60-14.05684\n",
      "1390 1390 RGI60-14.05734\n",
      "1391 1391 RGI60-14.05784\n",
      "1392 1392 RGI60-14.05810\n",
      "1393 1393 RGI60-14.05869\n",
      "1394 1394 RGI60-14.05872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395 1395 RGI60-14.05890\n",
      "1396 1396 RGI60-14.05913\n",
      "1397 1397 RGI60-14.05916\n",
      "1398 1398 RGI60-14.05964\n",
      "1399 1399 RGI60-14.05985\n",
      "1400 1400 RGI60-14.06463\n",
      "1401 1401 RGI60-14.06487\n",
      "1402 1402 RGI60-14.06580\n",
      "1403 1403 RGI60-14.06625\n",
      "1404 1404 RGI60-14.06675\n",
      "1405 1405 RGI60-14.06794\n",
      "1406 1406 RGI60-14.06960\n",
      "1407 1407 RGI60-14.06963\n",
      "1408 1408 RGI60-14.06969\n",
      "1409 1409 RGI60-14.07017\n",
      "1410 1410 RGI60-14.07073\n",
      "1411 1411 RGI60-14.07136\n",
      "1412 1412 RGI60-14.07176\n",
      "1413 1413 RGI60-14.07177\n",
      "1414 1414 RGI60-14.07192\n",
      "1415 1415 RGI60-14.07195\n",
      "1416 1416 RGI60-14.07232\n",
      "1417 1417 RGI60-14.07239\n",
      "1418 1418 RGI60-14.07253\n",
      "1419 1419 RGI60-14.07290\n",
      "1420 1420 RGI60-14.07297\n",
      "1421 1421 RGI60-14.07309\n",
      "1422 1422 RGI60-14.07342\n",
      "1423 1423 RGI60-14.07380\n",
      "1424 1424 RGI60-14.07416\n",
      "1425 1425 RGI60-14.07474\n",
      "1426 1426 RGI60-14.07481\n",
      "1427 1427 RGI60-14.07500\n",
      "1428 1428 RGI60-14.07523\n",
      "1429 1429 RGI60-14.07524\n",
      "1430 1430 RGI60-14.07566\n",
      "1431 1431 RGI60-14.07571\n",
      "1432 1432 RGI60-14.07585\n",
      "1433 1433 RGI60-14.07603\n",
      "1434 1434 RGI60-14.07606\n",
      "1435 1435 RGI60-14.07613\n",
      "1436 1436 RGI60-14.07625\n",
      "1437 1437 RGI60-14.07646\n",
      "1438 1438 RGI60-14.07655\n",
      "1439 1439 RGI60-14.07684\n",
      "1440 1440 RGI60-14.07706\n",
      "1441 1441 RGI60-14.07725\n",
      "1442 1442 RGI60-14.07756\n",
      "1443 1443 RGI60-14.07779\n",
      "1444 1444 RGI60-14.07785\n",
      "1445 1445 RGI60-14.07794\n",
      "1446 1446 RGI60-14.07870\n",
      "1447 1447 RGI60-14.07872\n",
      "1448 1448 RGI60-14.07896\n",
      "1449 1449 RGI60-14.07915\n",
      "1450 1450 RGI60-14.07931\n",
      "1451 1451 RGI60-14.07968\n",
      "1452 1452 RGI60-14.07987\n",
      "1453 1453 RGI60-14.08046\n",
      "1454 1454 RGI60-14.08073\n",
      "1455 1455 RGI60-14.08075\n",
      "1456 1456 RGI60-14.08081\n",
      "1457 1457 RGI60-14.08083\n",
      "1458 1458 RGI60-14.08088\n",
      "1459 1459 RGI60-14.08091\n",
      "1460 1460 RGI60-14.08100\n",
      "1461 1461 RGI60-14.08107\n",
      "1462 1462 RGI60-14.08137\n",
      "1463 1463 RGI60-14.08160\n",
      "1464 1464 RGI60-14.08167\n",
      "1465 1465 RGI60-14.08184\n",
      "1466 1466 RGI60-14.08228\n",
      "1467 1467 RGI60-14.08260\n",
      "1468 1468 RGI60-14.08285\n",
      "1469 1469 RGI60-14.08295\n",
      "1470 1470 RGI60-14.08300\n",
      "1471 1471 RGI60-14.08324\n",
      "1472 1472 RGI60-14.08340\n",
      "1473 1473 RGI60-14.08351\n",
      "1474 1474 RGI60-14.08373\n",
      "1475 1475 RGI60-14.08380\n",
      "1476 1476 RGI60-14.08400\n",
      "1477 1477 RGI60-14.08412\n",
      "1478 1478 RGI60-14.08428\n",
      "1479 1479 RGI60-14.08445\n",
      "1480 1480 RGI60-14.08450\n",
      "1481 1481 RGI60-14.08475\n",
      "1482 1482 RGI60-14.08485\n",
      "1483 1483 RGI60-14.08496\n",
      "1484 1484 RGI60-14.08505\n",
      "1485 1485 RGI60-14.08512\n",
      "1486 1486 RGI60-14.08516\n",
      "1487 1487 RGI60-14.08520\n",
      "1488 1488 RGI60-14.08527\n",
      "1489 1489 RGI60-14.08530\n",
      "1490 1490 RGI60-14.08531\n",
      "1491 1491 RGI60-14.08536\n",
      "1492 1492 RGI60-14.08542\n",
      "1493 1493 RGI60-14.08548\n",
      "1494 1494 RGI60-14.08551\n",
      "1495 1495 RGI60-14.08555\n",
      "1496 1496 RGI60-14.08557\n",
      "1497 1497 RGI60-14.08610\n",
      "1498 1498 RGI60-14.08628\n",
      "1499 1499 RGI60-14.08653\n",
      "1500 1500 RGI60-14.08656\n",
      "1501 1501 RGI60-14.08682\n",
      "1502 1502 RGI60-14.08708\n",
      "1503 1503 RGI60-14.08755\n",
      "1504 1504 RGI60-14.08780\n",
      "1505 1505 RGI60-14.08800\n",
      "1506 1506 RGI60-14.08910\n",
      "1507 1507 RGI60-14.08916\n",
      "1508 1508 RGI60-14.08941\n",
      "1509 1509 RGI60-14.08943\n",
      "1510 1510 RGI60-14.08958\n",
      "1511 1511 RGI60-14.08981\n",
      "1512 1512 RGI60-14.09082\n",
      "1513 1513 RGI60-14.09090\n",
      "1514 1514 RGI60-14.09113\n",
      "1515 1515 RGI60-14.09117\n",
      "1516 1516 RGI60-14.09125\n",
      "1517 1517 RGI60-14.09504\n",
      "1518 1518 RGI60-14.09510\n",
      "1519 1519 RGI60-14.09677\n",
      "1520 1520 RGI60-14.09679\n",
      "1521 1521 RGI60-14.09800\n",
      "1522 1522 RGI60-14.09816\n",
      "1523 1523 RGI60-14.09826\n",
      "1524 1524 RGI60-14.09829\n",
      "1525 1525 RGI60-14.09874\n",
      "1526 1526 RGI60-14.09896\n",
      "1527 1527 RGI60-14.09898\n",
      "1528 1528 RGI60-14.09904\n",
      "1529 1529 RGI60-14.09952\n",
      "1530 1530 RGI60-14.09993\n",
      "1531 1531 RGI60-14.10020\n",
      "1532 1532 RGI60-14.10056\n",
      "1533 1533 RGI60-14.10092\n",
      "1534 1534 RGI60-14.10189\n",
      "1535 1535 RGI60-14.10555\n",
      "1536 1536 RGI60-14.10570\n",
      "1537 1537 RGI60-14.10629\n",
      "1538 1538 RGI60-14.10638\n",
      "1539 1539 RGI60-14.10672\n",
      "1540 1540 RGI60-14.10824\n",
      "1541 1541 RGI60-14.10904\n",
      "1542 1542 RGI60-14.11033\n",
      "1543 1543 RGI60-14.11264\n",
      "1544 1544 RGI60-14.11301\n",
      "1545 1545 RGI60-14.11349\n",
      "1546 1546 RGI60-14.11485\n",
      "1547 1547 RGI60-14.11566\n",
      "1548 1548 RGI60-14.11567\n",
      "1549 1549 RGI60-14.11571\n",
      "1550 1550 RGI60-14.11573\n",
      "1551 1551 RGI60-14.11577\n",
      "1552 1552 RGI60-14.11584\n",
      "1553 1553 RGI60-14.11591\n",
      "1554 1554 RGI60-14.11593\n",
      "1555 1555 RGI60-14.11606\n",
      "1556 1556 RGI60-14.11611\n",
      "1557 1557 RGI60-14.11617\n",
      "1558 1558 RGI60-14.11634\n",
      "1559 1559 RGI60-14.11637\n",
      "1560 1560 RGI60-14.11638\n",
      "1561 1561 RGI60-14.11639\n",
      "1562 1562 RGI60-14.11696\n",
      "1563 1563 RGI60-14.11709\n",
      "1564 1564 RGI60-14.11715\n",
      "1565 1565 RGI60-14.11720\n",
      "1566 1566 RGI60-14.11724\n",
      "1567 1567 RGI60-14.11744\n",
      "1568 1568 RGI60-14.11751\n",
      "1569 1569 RGI60-14.11759\n",
      "1570 1570 RGI60-14.11760\n",
      "1571 1571 RGI60-14.11770\n",
      "1572 1572 RGI60-14.11771\n",
      "1573 1573 RGI60-14.11812\n",
      "1574 1574 RGI60-14.11815\n",
      "1575 1575 RGI60-14.11841\n",
      "1576 1576 RGI60-14.11844\n",
      "1577 1577 RGI60-14.11848\n",
      "1578 1578 RGI60-14.11856\n",
      "1579 1579 RGI60-14.11859\n",
      "1580 1580 RGI60-14.11861\n",
      "1581 1581 RGI60-14.11862\n",
      "1582 1582 RGI60-14.11864\n",
      "1583 1583 RGI60-14.11886\n",
      "1584 1584 RGI60-14.12171\n",
      "1585 1585 RGI60-14.12187\n",
      "1586 1586 RGI60-14.12198\n",
      "1587 1587 RGI60-14.12202\n",
      "1588 1588 RGI60-14.12234\n",
      "1589 1589 RGI60-14.12253\n",
      "1590 1590 RGI60-14.12261\n",
      "1591 1591 RGI60-14.12280\n",
      "1592 1592 RGI60-14.12281\n",
      "1593 1593 RGI60-14.12323\n",
      "1594 1594 RGI60-14.12331\n",
      "1595 1595 RGI60-14.12349\n",
      "1596 1596 RGI60-14.12355\n",
      "1597 1597 RGI60-14.12361\n",
      "1598 1598 RGI60-14.12365\n",
      "1599 1599 RGI60-14.12373\n",
      "1600 1600 RGI60-14.12374\n",
      "1601 1601 RGI60-14.12386\n",
      "1602 1602 RGI60-14.12401\n",
      "1603 1603 RGI60-14.12402\n",
      "1604 1604 RGI60-14.12409\n",
      "1605 1605 RGI60-14.12434\n",
      "1606 1606 RGI60-14.12443\n",
      "1607 1607 RGI60-14.12455\n",
      "1608 1608 RGI60-14.12456\n",
      "1609 1609 RGI60-14.12457\n",
      "1610 1610 RGI60-14.12459\n",
      "1611 1611 RGI60-14.12466\n",
      "1612 1612 RGI60-14.12467\n",
      "1613 1613 RGI60-14.12469\n",
      "1614 1614 RGI60-14.12833\n",
      "1615 1615 RGI60-14.12902\n",
      "1616 1616 RGI60-14.12948\n",
      "1617 1617 RGI60-14.13103\n",
      "1618 1618 RGI60-14.13118\n",
      "1619 1619 RGI60-14.13361\n",
      "1620 1620 RGI60-14.13559\n",
      "1621 1621 RGI60-14.13809\n",
      "1622 1622 RGI60-14.13966\n",
      "1623 1623 RGI60-14.14018\n",
      "1624 1624 RGI60-14.14024\n",
      "1625 1625 RGI60-14.14077\n",
      "1626 1626 RGI60-14.14082\n",
      "1627 1627 RGI60-14.14155\n",
      "1628 1628 RGI60-14.14160\n",
      "1629 1629 RGI60-14.14161\n",
      "1630 1630 RGI60-14.14164\n",
      "1631 1631 RGI60-14.14167\n",
      "1632 1632 RGI60-14.14235\n",
      "1633 1633 RGI60-14.14269\n",
      "1634 1634 RGI60-14.14278\n",
      "1635 1635 RGI60-14.14286\n",
      "1636 1636 RGI60-14.14289\n",
      "1637 1637 RGI60-14.14293\n",
      "1638 1638 RGI60-14.14311\n",
      "1639 1639 RGI60-14.14402\n",
      "1640 1640 RGI60-14.14606\n",
      "1641 1641 RGI60-14.14711\n",
      "1642 1642 RGI60-14.14720\n",
      "1643 1643 RGI60-14.14725\n",
      "1644 1644 RGI60-14.14768\n",
      "1645 1645 RGI60-14.14781\n",
      "1646 1646 RGI60-14.14785\n",
      "1647 1647 RGI60-14.14815\n",
      "1648 1648 RGI60-14.14816\n",
      "1649 1649 RGI60-14.14817\n",
      "1650 1650 RGI60-14.14820\n",
      "1651 1651 RGI60-14.14831\n",
      "1652 1652 RGI60-14.14868\n",
      "1653 1653 RGI60-14.14898\n",
      "1654 1654 RGI60-14.14905\n",
      "1655 1655 RGI60-14.14909\n",
      "1656 1656 RGI60-14.14910\n",
      "1657 1657 RGI60-14.14913\n",
      "1658 1658 RGI60-14.14920\n",
      "1659 1659 RGI60-14.14925\n",
      "1660 1660 RGI60-14.14942\n",
      "1661 1661 RGI60-14.14944\n",
      "1662 1662 RGI60-14.14948\n",
      "1663 1663 RGI60-14.14963\n",
      "1664 1664 RGI60-14.14969\n",
      "1665 1665 RGI60-14.14970\n",
      "1666 1666 RGI60-14.14980\n",
      "1667 1667 RGI60-14.14986\n",
      "1668 1668 RGI60-14.15000\n",
      "1669 1669 RGI60-14.15006\n",
      "1670 1670 RGI60-14.15008\n",
      "1671 1671 RGI60-14.15009\n",
      "1672 1672 RGI60-14.15010\n",
      "1673 1673 RGI60-14.15011\n",
      "1674 1674 RGI60-14.15022\n",
      "1675 1675 RGI60-14.15026\n",
      "1676 1676 RGI60-14.15027\n",
      "1677 1677 RGI60-14.15036\n",
      "1678 1678 RGI60-14.15039\n",
      "1679 1679 RGI60-14.15047\n",
      "1680 1680 RGI60-14.15048\n",
      "1681 1681 RGI60-14.15049\n",
      "1682 1682 RGI60-14.15053\n",
      "1683 1683 RGI60-14.15099\n",
      "1684 1684 RGI60-14.15100\n",
      "1685 1685 RGI60-14.15110\n",
      "1686 1686 RGI60-14.15115\n",
      "1687 1687 RGI60-14.15173\n",
      "1688 1688 RGI60-14.15302\n",
      "1689 1689 RGI60-14.15308\n",
      "1690 1690 RGI60-14.15319\n",
      "1691 1691 RGI60-14.15324\n",
      "1692 1692 RGI60-14.15339\n",
      "1693 1693 RGI60-14.15340\n",
      "1694 1694 RGI60-14.15375\n",
      "1695 1695 RGI60-14.15395\n",
      "1696 1696 RGI60-14.15396\n",
      "1697 1697 RGI60-14.15421\n",
      "1698 1698 RGI60-14.15446\n",
      "1699 1699 RGI60-14.15447\n",
      "1700 1700 RGI60-14.15455\n",
      "1701 1701 RGI60-14.15491\n",
      "1702 1702 RGI60-14.15524\n",
      "1703 1703 RGI60-14.15528\n",
      "1704 1704 RGI60-14.15536\n",
      "1705 1705 RGI60-14.15544\n",
      "1706 1706 RGI60-14.15567\n",
      "1707 1707 RGI60-14.15601\n",
      "1708 1708 RGI60-14.15613\n",
      "1709 1709 RGI60-14.15614\n",
      "1710 1710 RGI60-14.15623\n",
      "1711 1711 RGI60-14.15624\n",
      "1712 1712 RGI60-14.15634\n",
      "1713 1713 RGI60-14.15637\n",
      "1714 1714 RGI60-14.15643\n",
      "1715 1715 RGI60-14.15647\n",
      "1716 1716 RGI60-14.15654\n",
      "1717 1717 RGI60-14.15664\n",
      "1718 1718 RGI60-14.15666\n",
      "1719 1719 RGI60-14.15671\n",
      "1720 1720 RGI60-14.15686\n",
      "1721 1721 RGI60-14.15705\n",
      "1722 1722 RGI60-14.15725\n",
      "1723 1723 RGI60-14.15726\n",
      "1724 1724 RGI60-14.15734\n",
      "1725 1725 RGI60-14.15737\n",
      "1726 1726 RGI60-14.15834\n",
      "1727 1727 RGI60-14.15849\n",
      "1728 1728 RGI60-14.15856\n",
      "1729 1729 RGI60-14.15864\n",
      "1730 1730 RGI60-14.15869\n",
      "1731 1731 RGI60-14.15875\n",
      "1732 1732 RGI60-14.15894\n",
      "1733 1733 RGI60-14.15895\n",
      "1734 1734 RGI60-14.15896\n",
      "1735 1735 RGI60-14.15900\n",
      "1736 1736 RGI60-14.15933\n",
      "1737 1737 RGI60-14.15934\n",
      "1738 1738 RGI60-14.15936\n",
      "1739 1739 RGI60-14.15938\n",
      "1740 1740 RGI60-14.15952\n",
      "1741 1741 RGI60-14.15966\n",
      "1742 1742 RGI60-14.15968\n",
      "1743 1743 RGI60-14.15987\n",
      "1744 1744 RGI60-14.15988\n",
      "1745 1745 RGI60-14.15989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746 1746 RGI60-14.15990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747 1747 RGI60-14.15993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748 1748 RGI60-14.16005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749 1749 RGI60-14.16016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750 1750 RGI60-14.16030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751 1751 RGI60-14.16036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752 1752 RGI60-14.16041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753 1753 RGI60-14.16042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754 1754 RGI60-14.16065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755 1755 RGI60-14.16068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756 1756 RGI60-14.16084\n"
     ]
    }
   ],
   "source": [
    "for nglac, glac_idx in enumerate(main_glac_rgi.index.values):\n",
    "# for nglac, glac_idx in enumerate(main_glac_rgi.index.values[784:]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi.index.values[502]]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi.index.values[0]]):\n",
    "    glac_str = main_glac_rgi.loc[glac_idx,'rgino_str']\n",
    "    rgiid = main_glac_rgi.loc[glac_idx,'RGIId']\n",
    "    \n",
    "    print(nglac, glac_idx, rgiid)\n",
    "    \n",
    "    out_csv_fn = os.path.join(outdir_csv, glac_str + csv_ending)\n",
    "    if verbose:\n",
    "        print('output_fn:', out_csv_fn)\n",
    "\n",
    "    if not os.path.exists(out_csv_fn):\n",
    "    \n",
    "        region = glac_str.split('.')[0]\n",
    "\n",
    "        # Shape layer processing\n",
    "        glac_shp_init = gpd.read_file(input.glac_shp_fn_dict[region])\n",
    "        dc_shp_init = gpd.read_file(input.debriscover_fp + input.debriscover_fn_dict[input.roi])\n",
    "        if verbose:\n",
    "            print('Shp init crs:', glac_shp_init.crs)\n",
    "\n",
    "        glac_shp_single = glac_shp_init[glac_shp_init['RGIId'] == rgiid]\n",
    "        glac_shp_single = glac_shp_single.reset_index()\n",
    "        dc_shp_single = dc_shp_init[dc_shp_init['RGIId'] == rgiid]\n",
    "        dc_shp_single = dc_shp_single.reset_index()\n",
    "\n",
    "        # Project shapefile\n",
    "        huss_dir = input.huss_dir_sample.replace('XXXX',str(region.zfill(2)))\n",
    "        huss_fn = input.huss_fn_sample.replace('XXXX',glac_str)\n",
    "\n",
    "        proj_fn = os.path.join(huss_dir, huss_fn) # THIS PROJECTION IS KEY!\n",
    "        ds = gdal.Open(proj_fn)\n",
    "        prj = ds.GetProjection()\n",
    "        srs = osr.SpatialReference(wkt=prj)\n",
    "        aea_srs = srs\n",
    "\n",
    "        # If projected shapefile already exists, then skip projection\n",
    "        glac_shp_proj_fn = input.glac_shp_proj_fp + glac_str + '_crs' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp'\n",
    "        dc_shp_proj_fn = input.glac_shp_proj_fp + glac_str + '_dc_crs' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp'\n",
    "\n",
    "        if os.path.exists(glac_shp_proj_fn) == False:\n",
    "            glac_shp_proj = glac_shp_single.to_crs({'init': 'epsg:' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "            glac_shp_proj.to_file(glac_shp_proj_fn)\n",
    "            \n",
    "        if os.path.exists(dc_shp_proj_fn) == False:\n",
    "            dc_shp_proj = dc_shp_single.to_crs({'init': 'epsg:' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "            dc_shp_proj.to_file(dc_shp_proj_fn)\n",
    "        \n",
    "\n",
    "        glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "        glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "        #This should be contained in features\n",
    "        glac_shp_srs = glac_shp_lyr.GetSpatialRef()\n",
    "        feat_count = glac_shp_lyr.GetFeatureCount()\n",
    "        if verbose:\n",
    "            print(\"Input glacier polygon count: %i\" % feat_count)\n",
    "            \n",
    "        dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "        dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "        #This should be contained in features\n",
    "        dc_shp_srs = dc_shp_lyr.GetSpatialRef()\n",
    "        feat_count = dc_shp_lyr.GetFeatureCount()\n",
    "        if verbose:\n",
    "            print(\"Input glacier polygon count (debris cover): %i\" % feat_count)\n",
    "\n",
    "        # Load DEM\n",
    "        z1_dir = input.z1_dir_sample.replace('XXXX',str(region.zfill(2)))\n",
    "        z1_fn = input.z1_fn_sample.replace('XXXX',glac_str)\n",
    "        z1_ds = gdal.Open(z1_dir + z1_fn)\n",
    "        z1_int_geom = geolib.ds_geom_intersection([z1_ds, z1_ds], t_srs=glac_shp_srs)\n",
    "\n",
    "        glacfeat_list = []\n",
    "        glacname_fieldname = \"Name\"\n",
    "        #RGIId (String) = RGI50-01.00004\n",
    "        glacnum_fieldname = \"RGIId\"\n",
    "        glacnum_fmt = '%08.5f'\n",
    "\n",
    "        for n, feat in enumerate(glac_shp_lyr):\n",
    "            gf = GlacFeat(feat, glacname_fieldname, glacnum_fieldname)\n",
    "            if verbose:\n",
    "                print(\"%i of %i: %s\" % (n+1, feat_count, gf.feat_fn))\n",
    "            #NOTE: Input must be in projected coordinate system, ideally equal area\n",
    "            #Should check this and reproject\n",
    "            gf.geom_attributes(srs=aea_srs)\n",
    "            glacfeat_list.append(gf)\n",
    "\n",
    "        if verbose:\n",
    "            print(gf.feat_fn)\n",
    "        \n",
    "        fn_dict = OrderedDict()\n",
    "        #We at least want to warp the two input DEMs\n",
    "        fn_dict['z1'] = os.path.join(z1_dir, z1_fn)\n",
    "\n",
    "        if extra_layers and (gf.glac_area_km2 > input.min_glac_area_writeout):\n",
    "            if verbose:\n",
    "                print(gf.glacnum)\n",
    "\n",
    "            # Ice thickness data\n",
    "            ice_thick_fn = os.path.join(huss_dir, huss_fn)\n",
    "            if os.path.exists(ice_thick_fn):\n",
    "                fn_dict['ice_thick'] = ice_thick_fn\n",
    "\n",
    "            if verbose:\n",
    "                print(fn_dict['ice_thick'])\n",
    "\n",
    "            # Surface velocity\n",
    "            if os.path.exists(input.v_dir + input.vx_fn_dict[input.roi]):\n",
    "                fn_dict['vx'] = input.v_dir + input.vx_fn_dict[input.roi]\n",
    "                fn_dict['vy'] = input.v_dir + input.vy_fn_dict[input.roi]\n",
    "                \n",
    "\n",
    "    #         if os.path.exists(ts_fullfn):\n",
    "    #             fn_dict['ts'] = ts_fullfn\n",
    "\n",
    "    #         if os.path.exists(debris_fullfn):\n",
    "    #             fn_dict['debris_thick_ts'] = debris_fullfn\n",
    "\n",
    "        #Expand extent to include buffered region around glacier polygon\n",
    "        warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=input.buff_dist)\n",
    "        if verbose:\n",
    "            print(\"Expanding extent\")\n",
    "            print(gf.glac_geom_extent)\n",
    "            print(warp_extent)\n",
    "            print(aea_srs)\n",
    "\n",
    "        #Warp everything to common res/extent/proj\n",
    "        ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res='min', \\\n",
    "                extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "                r='cubic')\n",
    "\n",
    "        ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "        if verbose:\n",
    "            print(ds_list)\n",
    "            print(fn_dict.keys())\n",
    "\n",
    "        #Prepare mask for all glaciers within buffered area, not just the current glacier polygon\n",
    "        glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "        glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "        \n",
    "        dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "        dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "\n",
    "        #Get global glacier mask\n",
    "        #Want this to be True over ALL glacier surfaces, not just the current polygon\n",
    "        glac_shp_lyr_mask = geolib.lyr2mask(glac_shp_lyr, ds_dict['ice_thick'])\n",
    "        dc_shp_lyr_mask = geolib.lyr2mask(dc_shp_lyr, ds_dict['ice_thick'])\n",
    "\n",
    "        #Create buffer around glacier polygon\n",
    "        glac_geom_buff = gf.glac_geom.Buffer(input.buff_dist)\n",
    "        #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "        glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "\n",
    "        # ds masks\n",
    "        ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "        dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "        dems_mask = dem1.mask\n",
    "        if verbose:\n",
    "            print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "        #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "        static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "        static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "        \n",
    "        if 'z1' in ds_dict:\n",
    "            #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "            glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "            gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']))\n",
    "            #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "            \n",
    "            # Debris cover\n",
    "            dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "            gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=dc_mask)\n",
    "\n",
    "            # Check if DEM has huge errors or not - replace if necessary\n",
    "            if input.roi in ['01']:\n",
    "                \n",
    "                gf.z1_check = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "                if gf.z1_check.min() < 0:\n",
    "                    \n",
    "                    # Add backup DEM for regions with known poor quality (ex. Alaska)\n",
    "                    print('switching DEMs')\n",
    "                    fn_dict['z1_backup'] = input.z1_backup_dict[input.roi]\n",
    "                    # Warp everything to common res/extent/proj (a second time)\n",
    "                    ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res='min', \\\n",
    "                            extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "                            r='cubic')\n",
    "                    ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "#                     glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "#                     gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']))\n",
    "                    \n",
    "#                     # Debris cover\n",
    "#                     dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "#                     gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=dc_mask)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(ds_list)\n",
    "                        print(fn_dict.keys())\n",
    "\n",
    "                    #Prepare mask for all glaciers within buffered area, not just the current glacier polygon\n",
    "                    glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "                    glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "\n",
    "                    dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "                    dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "\n",
    "                    #Get global glacier mask\n",
    "                    #Want this to be True over ALL glacier surfaces, not just the current polygon\n",
    "                    glac_shp_lyr_mask = geolib.lyr2mask(glac_shp_lyr, ds_dict['ice_thick'])\n",
    "                    dc_shp_lyr_mask = geolib.lyr2mask(dc_shp_lyr, ds_dict['ice_thick'])\n",
    "\n",
    "                    #Create buffer around glacier polygon\n",
    "                    glac_geom_buff = gf.glac_geom.Buffer(input.buff_dist)\n",
    "                    #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                    glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "\n",
    "                    # ds masks\n",
    "                    ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "                    dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "                    dems_mask = dem1.mask\n",
    "                    if verbose:\n",
    "                        print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "                    #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "                    static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "                    static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "                    \n",
    "                    #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                    glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1_backup'])\n",
    "                    gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']))\n",
    "                    #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "                    # Debris cover\n",
    "                    dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "                    gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=dc_mask)\n",
    "\n",
    "\n",
    "            if verbose:\n",
    "                print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "            if gf.z1.count() == 0:\n",
    "                if verbose:\n",
    "                    print(\"No z1 pixels\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Unable to load z1 ds\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        if nglac == 0:\n",
    "            print('\\n\\nHACK TO BYPASS VALID AREA\\n\\n')\n",
    "        gf.valid_area_perc = 100\n",
    "\n",
    "        if gf.valid_area_perc < (100. * input.min_valid_area_perc):\n",
    "            if verbose:\n",
    "                print(\"Not enough valid pixels. %0.1f%% percent of glacier polygon area\" % (gf.valid_area_perc))\n",
    "        #     return None\n",
    "\n",
    "        else:\n",
    "            #Filter dz - throw out abs differences >150 m\n",
    "\n",
    "            #Compute dz, volume change, mass balance and stats\n",
    "            gf.z1_stats = malib.get_stats(gf.z1)\n",
    "            z1_elev_med = gf.z1_stats[5]\n",
    "            z1_elev_min, z1_elev_max = malib.calcperc(gf.z1, (0.1, 99.9))\n",
    "\n",
    "            #Caluclate stats for aspect and slope using z2\n",
    "            #Requires GDAL 2.1+\n",
    "            gf.z1_aspect = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='aspect', returnma=True), mask=glac_geom_mask)\n",
    "            gf.z1_aspect_stats = malib.get_stats(gf.z1_aspect)\n",
    "            z1_aspect_med = gf.z1_aspect_stats[5]\n",
    "            gf.z1_slope = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='slope', returnma=True), mask=glac_geom_mask)\n",
    "            gf.z1_slope_stats = malib.get_stats(gf.z1_slope)\n",
    "            z1_slope_med = gf.z1_slope_stats[5]\n",
    "\n",
    "            #Can estimate ELA values computed from hypsometry and typical AAR\n",
    "            #For now, assume ELA is mean\n",
    "            gf.z1_ela = None\n",
    "            gf.z1_ela = gf.z1_stats[3]\n",
    "            #Note: in theory, the ELA should get higher with mass loss\n",
    "            #In practice, using mean and same polygon, ELA gets lower as glacier surface thins\n",
    "\n",
    "            if extra_layers and (gf.glac_area_km2 > input.min_glac_area_writeout):\n",
    "                if 'ice_thick' in ds_dict:\n",
    "                    #Load ice thickness\n",
    "                    gf.H = np.ma.array(iolib.ds_getma(ds_dict['ice_thick']), mask=glac_geom_mask)\n",
    "                    gf.H_mean = gf.H.mean()\n",
    "                    if verbose:\n",
    "                        print('mean ice thickness [m]:', gf.H_mean)\n",
    "\n",
    "                if 'vx' in ds_dict and 'vy' in ds_dict:\n",
    "                    #Load surface velocity maps\n",
    "                    gf.vx = np.ma.array(iolib.ds_getma(ds_dict['vx']), mask=glac_geom_mask)\n",
    "                    gf.vy = np.ma.array(iolib.ds_getma(ds_dict['vy']), mask=glac_geom_mask)\n",
    "                    gf.vm = np.ma.sqrt(gf.vx**2 + gf.vy**2)\n",
    "                    gf.vm_mean = gf.vm.mean()\n",
    "                    if verbose:\n",
    "                        print('mean velocity [m/s]:', gf.vm_mean)\n",
    "\n",
    "                    if gf.H is not None:\n",
    "                        #Compute flux\n",
    "                        gf.Q = gf.H * input.v_col_f * np.array([gf.vx, gf.vy])\n",
    "                        #Note: np.gradient returns derivatives relative to axis number, so (y, x) in this case\n",
    "                        #Want x-derivative of x component\n",
    "                        gf.divQ = np.gradient(gf.Q[0])[1] + np.gradient(gf.Q[1])[0]\n",
    "\n",
    "        #                 gf.divQ = gf.H*(np.gradient(v_col_f*gf.vx)[1] + np.gradient(v_col_f*gf.vy)[0]) \\\n",
    "        #                         + v_col_f*gf.vx*(np.gradient(gf.H)[1]) + v_col_f*gf.vy*(np.gradient(gf.H)[0])\n",
    "\n",
    "                        #Should smooth divQ, better handling of data gaps\n",
    "                \n",
    "\n",
    "                if 'ts' in ds_dict:\n",
    "                    #Load surface temperature maps\n",
    "                    gf.ts = np.ma.array(iolib.ds_getma(ds_dict['ts']), mask=glac_geom_mask)\n",
    "                else:\n",
    "                    gf.ts = None\n",
    "\n",
    "                if 'debris_thick_ts' in ds_dict:\n",
    "                    # Load debris thickness map\n",
    "                    gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "                    gf.meltfactor_ts = None\n",
    "                else:\n",
    "                    gf.debris_thick_ts = None\n",
    "                    gf.meltfactor_ts = None\n",
    "\n",
    "            if verbose:\n",
    "                print('Area [km2]:', gf.glac_area / 1e6)\n",
    "                print('-------------------------------')\n",
    "\n",
    "\n",
    "            # Plots\n",
    "    #         titles = ['Z1']\n",
    "    #         z1_full2plot = gf.z1\n",
    "    #         z1_full2plot.mask = dems_mask\n",
    "    #         clim = malib.calcperc(z1_full2plot, (2,98))\n",
    "    #         plot_array(z1_full2plot, clim, titles, 'inferno', 'Elevation (m WGS84)', fn=outdir_fig + glac_str + '_dem.png')\n",
    "\n",
    "            #Now apply glacier mask AND mask NaN values\n",
    "            glac_geom_mask = np.ma.mask_or(glac_geom_mask, dems_mask)\n",
    "            # nan_mask = np.ma.masked_invalid(gf.dz)\n",
    "            # glac_geom_mask = np.ma.mask_or(glac_geom_mask, nan_mask.mask)\n",
    "            gf.z1 = np.ma.array(gf.z1, mask=glac_geom_mask)\n",
    "            \n",
    "#             # Debris cover mask\n",
    "#             dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "\n",
    "            gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "            titles = ['Z1 (masked)']\n",
    "            clim = malib.calcperc(gf.z1, (2,98))\n",
    "            plot_array(gf.z1, clim, titles, 'inferno', 'Elevation (m WGS84)', fn=outdir_fig + glac_str + '_dem.png')\n",
    "\n",
    "            if verbose:\n",
    "                print(gf.z1.shape)\n",
    "                \n",
    "#             titles = ['Vx']\n",
    "#             var_full2plot = gf.vx\n",
    "#             var_full2plot.mask = glac_geom_mask\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'vx', fn=outdir_fig + gf.feat_fn +'_vx.png')\n",
    "\n",
    "#             titles = ['Vy']\n",
    "#             var_full2plot = gf.vy\n",
    "#             var_full2plot.mask = glac_geom_mask\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'vy', fn=outdir_fig + gf.feat_fn +'_vy.png')\n",
    "\n",
    "            gf.vtot = (gf.vx**2 + gf.vy**2)**0.5\n",
    "\n",
    "            titles = ['Velocity (m/yr)']\n",
    "            var_full2plot = gf.vtot\n",
    "            var_full2plot.mask = glac_geom_mask\n",
    "            clim = malib.calcperc(var_full2plot, (2,98))\n",
    "            plot_array(var_full2plot, clim, titles, 'inferno', 'Velocity (m/yr)', fn=outdir_fig + glac_str +'_velocity.png',\n",
    "                       close_fig=close_fig)\n",
    "\n",
    "            titles = ['Ice thickness']\n",
    "            var_full2plot = gf.H\n",
    "            var_full2plot.mask = glac_geom_mask\n",
    "#             var_full2plot.mask = dc_mask\n",
    "            clim = malib.calcperc(var_full2plot, (2,98))\n",
    "            plot_array(var_full2plot, clim, titles, 'inferno', 'H', fn=outdir_fig + gf.feat_fn +'_ice_thickness.png',\n",
    "                      close_fig=close_fig)\n",
    "        \n",
    "            \n",
    "            titles = ['Debris cover']\n",
    "            var_full2plot = gf.dc_area\n",
    "            clim = (0,1)\n",
    "            plot_array(var_full2plot, clim, titles, 'inferno', '', fn=outdir_fig + gf.feat_fn +'_debriscover.png',\n",
    "                      close_fig=close_fig)\n",
    "            \n",
    "            titles = ['Flux']\n",
    "            divQ_full2plot = gf.divQ\n",
    "            divQ_full2plot.mask = glac_geom_mask\n",
    "            clim = malib.calcperc(divQ_full2plot, (2,98))\n",
    "            plot_array(divQ_full2plot, clim, titles, 'inferno', 'divQ', fn=outdir_fig + glac_str +'_divQ.png')\n",
    "\n",
    "            # ===== \"COREGISTER\" SURFACE LOWERING WITH DEM USED FOR ICE THICKNESS =====\n",
    "            # Load Mass Balance Data and find displacement =====\n",
    "            if verbose:\n",
    "                print('\\nREALLY THIS SHOULD BE DONE BY COREGISTRATION OF THE TWO DEMS\\n')\n",
    "            mb_df = pd.read_csv(main_glac_rgi.loc[glac_idx, 'mb_fn'])\n",
    "            mb_df.loc[:,:] = mb_df.values.astype(np.float64)\n",
    "            try:\n",
    "                mb_bin0_km2 = mb_df.loc[0,' z1_bin_area_perc'] / 100 * main_glac_rgi.loc[glac_idx,'Area']\n",
    "            except:\n",
    "                mb_bin0_km2 = mb_df.loc[0,' z1_bin_area_valid_km2']\n",
    "            mb_bin_size = mb_df.loc[1,'# bin_center_elev_m'] - mb_df.loc[0,'# bin_center_elev_m']\n",
    "            pix_km2 = gf.res[0] * gf.res[1] / (1000)**2\n",
    "            if verbose:\n",
    "                print('total glacier area [km2]:', main_glac_rgi.loc[glac_idx,'Area'])\n",
    "                print('initial bin area [km2]:', mb_bin0_km2)\n",
    "                print('bin size [m]:', mb_bin_size)\n",
    "                print('pixel size [km2]:', pix_km2)\n",
    "            # Find displacement\n",
    "            if len(gf.z1.compressed()) > 0:\n",
    "                z1 = gf.z1.compressed()\n",
    "                z1_min = z1[z1>0].min()\n",
    "                z1_max = z1[z1>0].max()\n",
    "                z1_km2 = 0\n",
    "                elev = int(z1_min)\n",
    "                while z1_km2 < mb_bin0_km2 and elev < z1_max:\n",
    "                    elev += 1\n",
    "                    z1_idx = np.where((z1 > 0) & (z1 < elev))\n",
    "                    if len(z1_idx[0]) > 0:\n",
    "                        z1_km2 = len(z1_idx[0]) * pix_km2\n",
    "#                         print(elev, z1_km2)        \n",
    "                if verbose:\n",
    "                    print(elev, z1_km2, 'vs', mb_df.loc[0,'# bin_center_elev_m'], mb_bin0_km2)\n",
    "                mb_bin0_upper =  mb_df.loc[0,'# bin_center_elev_m'] + mb_bin_size / 2\n",
    "                z1_offset = elev - mb_bin0_upper\n",
    "                if verbose:\n",
    "                    print('z1_offset:', z1_offset)\n",
    "                # Update z1 with the offset\n",
    "                mask_offset = np.ma.array(np.zeros(gf.z1.mask.shape) - z1_offset, mask=np.ma.getmask(gf.z1))\n",
    "                gf.z1[~gf.z1.mask] = gf.z1[~gf.z1.mask] + mask_offset[~mask_offset.mask]\n",
    "                \n",
    "                mask_offset_dc = np.ma.array(np.zeros(gf.dc_area.mask.shape) - z1_offset, mask=np.ma.getmask(gf.dc_area))\n",
    "                gf.dc_area[~gf.dc_area.mask] = gf.dc_area[~gf.dc_area.mask] + mask_offset[~mask_offset_dc.mask]\n",
    "\n",
    "                # ===== EMERGENCE VELOCITY =====\n",
    "                vx = np.ma.filled(gf.vx,0)\n",
    "                vy = np.ma.filled(gf.vy,0)\n",
    "                H = np.ma.filled(gf.H,0)\n",
    "                vx[gf.z1 > gf.z1.max()] = 0\n",
    "                vy[gf.z1 > gf.z1.max()] = 0\n",
    "                H[gf.z1 > gf.z1.max()] = 0\n",
    "                vmax = np.nanmax((vx**2 + vy**2)**0.5)\n",
    "\n",
    "                # Emergence computation\n",
    "                emvel = emergence_pixels(gf, vx, vy, H, gf.res[0], gf.res[1], \n",
    "                                         positive_is_east=True, positive_is_north=True, \n",
    "                                         constant_icethickness=False, max_velocity=vmax, vel_min=0, debug=False)\n",
    "                # 3x3 filter to reduce\n",
    "                if input.emvel_filter_pixsize > 0:\n",
    "                    emvel = ndimage.filters.convolve(emvel, weights=np.full((input.emvel_filter_pixsize, input.emvel_filter_pixsize), \n",
    "                                                                            1.0/input.emvel_filter_pixsize**2))\n",
    "                # Add to glacier feature\n",
    "                gf.emvel = np.ma.masked_array(emvel, mask=np.ma.getmask(gf.z1))\n",
    "\n",
    "                # ===== EXPORT BINNED STATISTICS =====\n",
    "                #Do AED for all\n",
    "                #Compute mb using scaled AED vs. polygon\n",
    "                #Check for valid pixel count vs. feature area, fill if appropriate\n",
    "                if gf.glac_area_km2 > input.min_glac_area_writeout:\n",
    "                    outbins_df, z_bin_edges = hist_plot(gf, bin_width=mb_bin_size, csv_ending=csv_ending,\n",
    "                                                        mb_df=mb_df)\n",
    "\n",
    "#                     if verbose:\n",
    "#                         print(outbins_df.loc[0:10,['bin_center_elev_m', ' vm_med',' vm_mad', ' H_mean', ' H_std', \n",
    "#                                                    ' emvel_mean', ' emvel_std',' emvel_med', ' emvel_mad']])\n",
    "            else:\n",
    "                print('\\n' + glac_str + ' HAS NO GLACIER AREA!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1745 1745 RGI60-14.15989\n",
    "\n",
    "print('\\n\\n\\nDONE\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DEBRIS ELEVATION STATS ====================================================================================\n",
    "# Glaciers with data\n",
    "glac_wobs_fns = []\n",
    "rgiid_wobs = []\n",
    "for i in os.listdir(outdir_csv):\n",
    "    if i.endswith('_mb_bins_wdc_emvel_offset.csv'):\n",
    "        rgiid_reg = int(i.split('.')[0])\n",
    "        if int(rgiid_reg) in input.roi_rgidict[input.roi]:\n",
    "            glac_wobs_fns.append(i)\n",
    "            if rgiid_reg < 10:\n",
    "                rgiid_wobs.append(i[0:7])\n",
    "            else:\n",
    "                rgiid_wobs.append(i[0:8])\n",
    "        \n",
    "glac_wobs_fns = sorted(glac_wobs_fns)\n",
    "rgiid_wobs = sorted(rgiid_wobs)\n",
    "\n",
    "# ===== SELECT GLACIERS WITH DATA =====\n",
    "main_glac_rgi_wobs = input.selectglaciersrgitable(rgiid_wobs)\n",
    "main_glac_rgi_wobs['mb_bin_fn'] = glac_wobs_fns \n",
    "main_glac_rgi_wobs['CenLon_360'] = 360 + main_glac_rgi_wobs['CenLon']\n",
    "main_glac_rgi_wobs['CenLon_360'] = main_glac_rgi_wobs['CenLon']\n",
    "main_glac_rgi_wobs.loc[main_glac_rgi_wobs['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + main_glac_rgi_wobs.loc[main_glac_rgi_wobs['CenLon_360'] < 0, 'CenLon_360'])\n",
    "ds = xr.open_dataset(input.metdata_fp + '../' + input.metdata_elev_fn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(main_glac_rgi_wobs['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(main_glac_rgi_wobs['CenLon_360'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "main_glac_rgi_wobs['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_wobs['latlon_unique_no'] = main_glac_rgi_wobs['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_wobs['latlon_unique_no'])), '\\n\\n')\n",
    "# print(dc_shp_subset_wdata.loc[0:5,['RGIId', 'CenLat', 'CenLon', 'larsen_fn', 'braun_fn', 'latlon_unique_no']])\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# ===== CALCULATE DEBRIS ELEVATION STATS FOR GLACIERS WITH DATA FOR EACH UNIQUE LAT/LON ======\n",
    "elev_stats_latlon_dict = {}\n",
    "latlon_list_updated = []\n",
    "for nlatlon, latlon_unique in enumerate(np.unique(main_glac_rgi_wobs.latlon_unique_no)):\n",
    "# for nlatlon, latlon_unique in enumerate([np.unique(main_glac_rgi_wobs.latlon_unique_no)[6]]):\n",
    "\n",
    "    main_glac_rgi_subset = main_glac_rgi_wobs[main_glac_rgi_wobs['latlon_unique_no'] == latlon_unique]\n",
    "    \n",
    "    # Debris elevation stats should be done by lat/lon\n",
    "    df_all = None\n",
    "    elev_list_all = []\n",
    "    df_idx_count = 0\n",
    "    for nglac, glac_fn in enumerate(main_glac_rgi_subset.mb_bin_fn.values):\n",
    "        df_raw = pd.read_csv(outdir_csv + glac_fn)\n",
    "        df = df_raw.dropna(subset=[' mb_bin_mean_mwea'])\n",
    "        df_debris = df[(df[' vm_med'] < input.vel_threshold) & (df['debris_perc'] > input.debrisperc_threshold)\n",
    "                       & (df[' dc_bin_count_valid'] > 0)]\n",
    "\n",
    "        df_idx = df_debris.index.values\n",
    "        df_idx_count += len(df_idx)\n",
    "        \n",
    "        if len(df_idx) > 0:\n",
    "            # only work with terminus\n",
    "            df_idx_dif = list(df_idx[1:] - df_idx[:-1])\n",
    "            if np.sum(df_idx_dif) == len(df_idx)-1:\n",
    "                df_idx_nojump = df_idx\n",
    "            else:\n",
    "                idx_jumpinbins = df_idx_dif.index(next(filter(lambda x: x>1, df_idx_dif)))\n",
    "                df_idx_nojump = df_idx[0:idx_jumpinbins+1]\n",
    "\n",
    "            df_debris_nojump = df_debris.loc[df_idx_nojump,:]\n",
    "            df_debris_nojump.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "            for nelev, elev in enumerate(list(df_debris_nojump['bin_center_elev_m'].values)):\n",
    "                elev_list_single = list(np.repeat(elev, df_debris_nojump.loc[nelev,' dc_bin_count_valid']))\n",
    "                elev_list_all.extend(elev_list_single)\n",
    "        \n",
    "    if df_idx_count > 0:\n",
    "        dc_zmean = np.mean(elev_list_all)\n",
    "        dc_zstd = np.std(elev_list_all)\n",
    "        dc_zmed = malib.fast_median(elev_list_all)\n",
    "        dc_zmad = malib.mad(elev_list_all)\n",
    "\n",
    "        lat_deg = float(ds.latitude[latlon_unique_dict_reversed[latlon_unique][0]].values)\n",
    "        lon_deg = float(ds.longitude[latlon_unique_dict_reversed[latlon_unique][1]].values)\n",
    "        elev_stats_latlon_dict[lat_deg,lon_deg] = [dc_zmean, dc_zstd, dc_zmed, dc_zmad]\n",
    "        latlon_list_updated.append((lat_deg, lon_deg))\n",
    "\n",
    "# Update pickle of unique lat/lons that will be used for melt model\n",
    "with open(input.latlon_unique_fp + input.latlon_unique_dict[input.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list_updated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nCHECK THE HMA DATA AND SEE IF IT NEEDS TO ADD THESE STATS - I BELIEVE IT DOES')\n",
    "print('  --> grab a copy of files first just in case\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.75 213.0 exists\n",
      "63.5 212.5 exists\n",
      "63.5 213.25 exists\n",
      "63.5 213.5 exists\n",
      "63.5 214.5 exists\n",
      "63.25 209.5 exists\n",
      "63.25 214.5 exists\n",
      "63.0 209.25 exists\n",
      "63.0 210.0 exists\n",
      "62.75 208.0 exists\n",
      "62.75 208.25 exists\n",
      "62.75 208.5 exists\n",
      "62.75 208.75 exists\n",
      "62.75 209.25 exists\n",
      "62.5 207.75 exists\n",
      "61.75 212.5 exists\n",
      "61.5 212.0 exists\n",
      "61.5 213.0 exists\n",
      "61.5 217.0 exists\n",
      "61.5 219.0 exists\n",
      "61.25 213.0 exists\n",
      "61.25 218.5 exists\n",
      "61.25 219.75 exists\n",
      "61.0 207.25 exists\n",
      "61.0 214.25 exists\n",
      "61.0 214.75 exists\n",
      "61.0 219.5 exists\n",
      "61.0 220.25 exists\n",
      "60.75 206.5 exists\n",
      "60.75 206.75 exists\n",
      "60.75 214.75 exists\n",
      "60.75 219.25 exists\n",
      "60.75 221.0 exists\n",
      "60.5 215.0 exists\n",
      "60.5 218.0 exists\n",
      "60.25 219.5 exists\n",
      "60.0 207.0 exists\n",
      "60.0 220.25 exists\n",
      "60.0 220.75 exists\n",
      "60.0 221.0 exists\n",
      "60.0 221.75 exists\n",
      "60.0 222.0 exists\n",
      "59.75 220.5 exists\n",
      "59.75 220.75 exists\n",
      "59.75 221.0 exists\n",
      "59.75 221.25 exists\n",
      "59.75 221.75 exists\n",
      "59.75 222.25 exists\n",
      "59.75 222.5 exists\n",
      "59.75 222.75 exists\n",
      "59.75 223.25 exists\n",
      "59.75 223.75 exists\n",
      "59.75 224.25 exists\n",
      "59.75 224.5 exists\n",
      "59.75 224.75 exists\n",
      "59.5 221.0 exists\n",
      "59.5 221.25 exists\n",
      "59.5 221.5 exists\n",
      "59.5 221.75 exists\n",
      "59.5 222.0 exists\n",
      "59.5 222.25 exists\n",
      "59.5 222.5 exists\n",
      "59.5 222.75 exists\n",
      "59.5 223.0 exists\n",
      "59.5 223.25 exists\n",
      "59.5 223.5 exists\n",
      "59.5 224.0 exists\n",
      "59.5 224.25 exists\n",
      "59.5 224.5 exists\n",
      "59.5 224.75 exists\n",
      "59.5 225.0 exists\n",
      "59.5 225.25 exists\n",
      "59.5 225.5 exists\n",
      "59.25 221.5 exists\n",
      "59.25 221.75 exists\n",
      "59.25 222.0 exists\n",
      "59.25 222.25 exists\n",
      "59.25 222.75 exists\n",
      "59.25 223.0 exists\n",
      "59.25 223.25 exists\n",
      "59.25 223.5 exists\n",
      "59.25 223.75 exists\n",
      "59.25 224.0 exists\n",
      "59.25 224.25 exists\n",
      "59.25 224.5 exists\n",
      "59.25 224.75 exists\n",
      "59.25 225.0 exists\n",
      "59.25 225.25 exists\n",
      "59.25 225.5 exists\n",
      "59.25 225.75 exists\n",
      "59.0 206.5 exists\n",
      "59.0 222.25 exists\n",
      "59.0 222.75 exists\n",
      "59.0 223.0 exists\n",
      "59.0 223.25 exists\n",
      "59.0 223.5 exists\n",
      "59.0 223.75 exists\n",
      "59.0 224.0 exists\n",
      "59.0 224.25 exists\n",
      "59.0 224.5 exists\n",
      "59.0 225.0 exists\n",
      "59.0 225.25 exists\n",
      "59.0 225.75 exists\n",
      "59.0 226.0 exists\n",
      "59.0 226.25 exists\n",
      "59.0 226.5 exists\n",
      "58.75 206.25 exists\n",
      "58.75 222.25 exists\n",
      "58.75 222.5 exists\n",
      "58.75 223.0 exists\n",
      "58.75 223.25 exists\n",
      "58.75 223.5 exists\n",
      "58.75 223.75 exists\n",
      "58.75 224.0 exists\n",
      "58.75 224.25 exists\n",
      "58.75 224.5 exists\n",
      "58.75 225.25 exists\n",
      "58.75 225.5 exists\n",
      "58.75 225.75 exists\n",
      "58.75 226.0 exists\n",
      "58.75 226.25 exists\n",
      "58.75 226.5 exists\n",
      "58.5 205.5 exists\n",
      "58.5 222.75 exists\n",
      "58.5 223.0 exists\n",
      "58.5 223.5 exists\n",
      "58.5 224.5 exists\n",
      "58.5 224.75 exists\n",
      "58.5 226.25 exists\n",
      "58.5 226.5 exists\n",
      "58.5 226.75 exists\n",
      "58.5 227.0 exists\n",
      "58.5 227.25 exists\n",
      "58.5 227.5 exists\n",
      "58.25 204.5 exists\n",
      "58.25 204.75 exists\n",
      "58.25 205.0 exists\n",
      "58.25 205.25 exists\n",
      "58.25 205.5 exists\n",
      "58.25 226.0 exists\n",
      "58.25 226.25 exists\n",
      "58.25 226.75 exists\n",
      "58.25 227.0 exists\n",
      "58.25 227.25 exists\n",
      "58.25 227.5 exists\n",
      "58.0 227.0 exists\n",
      "58.0 227.25 exists\n",
      "58.0 227.5 exists\n",
      "58.0 227.75 exists\n",
      "58.0 228.0 exists\n",
      "57.75 226.5 exists\n",
      "57.75 227.0 exists\n",
      "57.75 227.5 exists\n",
      "57.75 227.75 exists\n",
      "57.75 228.0 exists\n",
      "57.75 229.25 exists\n",
      "57.75 229.5 exists\n",
      "57.5 227.0 exists\n",
      "57.5 227.25 exists\n",
      "57.5 227.5 exists\n",
      "57.5 227.75 exists\n",
      "57.5 228.0 exists\n",
      "57.5 228.5 exists\n",
      "57.5 228.75 exists\n",
      "57.5 229.25 exists\n",
      "57.25 227.25 exists\n",
      "57.25 227.5 exists\n",
      "57.25 227.75 exists\n",
      "57.25 228.0 exists\n",
      "57.25 228.25 exists\n",
      "57.25 228.5 exists\n",
      "57.25 228.75 exists\n",
      "57.25 229.0 exists\n",
      "57.25 229.25 exists\n",
      "57.25 229.5 exists\n",
      "57.25 230.0 exists\n",
      "57.25 230.75 exists\n",
      "57.0 225.0 exists\n",
      "57.0 227.5 exists\n",
      "57.0 228.0 exists\n",
      "57.0 228.5 exists\n",
      "57.0 228.75 exists\n",
      "57.0 229.0 exists\n",
      "57.0 229.25 exists\n",
      "57.0 229.5 exists\n",
      "57.0 230.0 exists\n",
      "57.0 230.25 exists\n",
      "57.0 230.5 exists\n",
      "57.0 230.75 exists\n",
      "56.75 227.75 exists\n",
      "56.75 228.5 exists\n",
      "56.75 228.75 exists\n",
      "56.75 229.0 exists\n",
      "56.75 229.5 exists\n",
      "56.75 230.5 exists\n",
      "56.75 230.75 exists\n",
      "56.5 228.25 exists\n",
      "56.5 228.5 exists\n",
      "56.5 228.75 exists\n",
      "56.5 229.0 exists\n",
      "56.5 229.25 exists\n",
      "56.5 229.5 exists\n",
      "56.5 229.75 exists\n",
      "56.5 230.0 exists\n",
      "56.25 228.75 exists\n",
      "56.25 229.5 exists\n",
      "56.25 229.75 exists\n",
      "56.25 230.0 exists\n",
      "56.25 230.25 exists\n",
      "56.25 230.5 exists\n",
      "56.0 229.5 exists\n",
      "56.0 229.75 exists\n",
      "56.0 230.25 exists\n",
      "56.0 230.5 exists\n",
      "55.75 230.25 exists\n",
      "55.75 230.75 exists\n",
      "55.25 230.5 exists\n",
      "55.25 230.75 exists\n"
     ]
    }
   ],
   "source": [
    "# ===== ADD DEBRIS ELEVATION STATS TO MET DATA ======\n",
    "for nlatlon, latlon in enumerate(latlon_list_updated):\n",
    "# for nlatlon, latlon in enumerate([latlon_list_updated[0]]):\n",
    "    \n",
    "    lat_deg = latlon[0]\n",
    "    lon_deg = latlon[1]\n",
    "\n",
    "    # ===== Meteorological data =====\n",
    "    metdata_fn = input.metdata_fn_sample.replace('XXXX', \n",
    "                                                 str(int(lat_deg*100)) + 'N-' + str(int(lon_deg*100)) + 'E-')\n",
    "    \n",
    "    ds = xr.open_dataset(input.metdata_fp + metdata_fn)\n",
    "    if 'dc_zmean' not in list(ds.keys()):\n",
    "        # Add stats\n",
    "        ds['dc_zmean'] = elev_stats_latlon_dict[latlon][0]\n",
    "        ds['dc_zmean'].attrs = {'units':'m a.s.l.', 'long_name':'Mean debris cover elevation', 'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zstd'] = elev_stats_latlon_dict[latlon][1]\n",
    "        ds['dc_zstd'].attrs = {'units':'m a.s.l.', 'long_name':'Standard deviation of debris cover elevation', 'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmed'] = elev_stats_latlon_dict[latlon][2]\n",
    "        ds['dc_zmed'].attrs = {'units':'m a.s.l.', 'long_name':'Median debris cover elevation', 'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmad'] = elev_stats_latlon_dict[latlon][3]\n",
    "        ds['dc_zmad'].attrs = {'units':'m a.s.l.', 'long_name':'Median absolute deviation of debris cover elevation', 'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "\n",
    "        try:\n",
    "            ds.close()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Export updated dataset\n",
    "        ds.to_netcdf(input.metdata_fp + metdata_fn, mode='a')\n",
    "    else:\n",
    "        print(lat_deg, lon_deg, 'exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO-DO LIST:\n",
      "- Isolate the debris-covered areas for dh/dt (add as separate column to have the option)\n",
      "  --> requires the raw dh/dt grids for the region (ex. dont have for Larsen)\n"
     ]
    }
   ],
   "source": [
    "print('TO-DO LIST:')\n",
    "print('- Isolate the debris-covered areas for dh/dt (add as separate column to have the option)')\n",
    "print('  --> requires the raw dh/dt grids for the region (ex. dont have for Larsen)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgiid_list = []\n",
    "# rgiid_fn_list = []\n",
    "# for i in os.listdir(outdir):\n",
    "#     if i.endswith('mb_bins.csv'):\n",
    "#         rgiid_list.append(i[0:8])\n",
    "#         rgiid_fn_list.append(i)\n",
    "        \n",
    "# rgiid_list = sorted(rgiid_list)\n",
    "# rgiid_fn_list = sorted(rgiid_fn_list)\n",
    "\n",
    "# print(len(rgiid_list))\n",
    "\n",
    "# main_glac_rgi = selectglaciersrgitable(rgiid_list)\n",
    "# main_glac_rgi['bin_fn'] = rgiid_fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(main_glac_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group datasets by nearest lat/lon\n",
    "# ds = xr.open_dataset(met_sample_fullfn)\n",
    "# #  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "# lat_nearidx = (np.abs(main_glac_rgi['CenLat'].values[:,np.newaxis] - \n",
    "#                       ds['latitude'][:].values).argmin(axis=1))\n",
    "# lon_nearidx = (np.abs(main_glac_rgi['CenLon'].values[:,np.newaxis] - \n",
    "#                       ds['longitude'][:].values).argmin(axis=1))\n",
    "\n",
    "# latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "# latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "\n",
    "# main_glac_rgi['latlon_nearidx'] = latlon_nearidx\n",
    "# latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "# latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "# main_glac_rgi['latlon_unique_no'] = main_glac_rgi['latlon_nearidx'].map(latlon_unique_dict)\n",
    "# print(main_glac_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process each group and derive elevation statistics for the debris cover\n",
    "# elevstats_mean = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "# elevstats_std = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "# elevstats_med = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "# elevstats_mad = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "# elevstats_min = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "# elevstats_max = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "\n",
    "# for nlatlon, latlon_idx in enumerate(list(np.arange(0,len(latlon_nearidx_unique)))):\n",
    "# # for nlatlon, latlon_idx in enumerate([251]):\n",
    "#     main_glac_rgi_subset = main_glac_rgi[main_glac_rgi['latlon_unique_no'] == latlon_idx]\n",
    "#     bin_fns = main_glac_rgi_subset['bin_fn'].values\n",
    "    \n",
    "#     lat_idx, lon_idx = latlon_unique_dict_reversed[latlon_idx]\n",
    "#     print(nlatlon, lat_idx, lon_idx)\n",
    "\n",
    "#     df_all = None\n",
    "#     for n, i in enumerate(bin_fns):\n",
    "#         df = pd.read_csv(outdir + i)\n",
    "        \n",
    "# #         print(i)\n",
    "        \n",
    "#         # Process only glaciers with debris\n",
    "#         debris_switch=False\n",
    "#         if ' perc_debris' in df.columns:\n",
    "#             # Process dataframe\n",
    "#             output_cns = ['# bin_center_elev_m', ' z1_bin_area_valid_km2', ' perc_debris']\n",
    "#             df = df[output_cns]\n",
    "#             df['# bin_center_elev_m'] = df['# bin_center_elev_m'].astype(np.float) \n",
    "#             df[' z1_bin_area_valid_km2'] = df[' z1_bin_area_valid_km2'].astype(np.float)\n",
    "            \n",
    "#             # Remove nan values\n",
    "#             df[' perc_debris'] = df[' perc_debris'].astype(np.float)\n",
    "#             df.fillna(0, inplace=True)\n",
    "            \n",
    "# #             print(i, df[' perc_debris'].max())\n",
    "            \n",
    "#             df['area_debris_km2'] = df[' z1_bin_area_valid_km2'] * df[' perc_debris'] / 100\n",
    "            \n",
    "#             if df[' perc_debris'].max() > 10:\n",
    "#                 debris_switch = True\n",
    "#                 debris_idx = np.where(df[' perc_debris'] > 50)[0]\n",
    "                \n",
    "#         if debris_switch:\n",
    "# #             print('processing', i)\n",
    "\n",
    "#             elev_min = df['# bin_center_elev_m'].values[0]\n",
    "#             elev_max = df['# bin_center_elev_m'].values[-1]\n",
    "\n",
    "#             binsize = df['# bin_center_elev_m'].values[1] - df['# bin_center_elev_m'].values[0]\n",
    "\n",
    "#             # Merge datasets together to compute elevation stats for each lat/lon\n",
    "#             if df_all is None:\n",
    "#                 df_all = df\n",
    "#                 if len(debris_idx) > 1:\n",
    "#                     zmin_debris = df['# bin_center_elev_m'].values[debris_idx[0]]\n",
    "#                     zmax_debris = df['# bin_center_elev_m'].values[debris_idx[-1]]\n",
    "#             else:\n",
    "#                 # If new min elevation lower than min old elevation\n",
    "#                 if elev_min < df_all['# bin_center_elev_m'].values[0]:\n",
    "#                     elev2add = np.arange(elev_min,df_all['# bin_center_elev_m'].values[0], binsize)\n",
    "#                     df_all_add = pd.DataFrame(np.zeros((len(elev2add), len(df.columns))), columns=df.columns)\n",
    "#                     df_all_add['# bin_center_elev_m'] = elev2add\n",
    "#                     df_all = pd.concat([df_all,df_all_add], axis=0)\n",
    "#                     df_all.sort_values('# bin_center_elev_m', inplace=True)\n",
    "\n",
    "#                 # If new max elevation higher than max old elevation\n",
    "#                 if elev_max > df_all['# bin_center_elev_m'].values[-1]:\n",
    "#                     elev2add = np.arange(df_all['# bin_center_elev_m'].values[-1] + binsize, elev_max + 1, binsize)\n",
    "#                     df_all_add = pd.DataFrame(np.zeros((len(elev2add), len(df.columns))), columns=df.columns)\n",
    "#                     df_all_add['# bin_center_elev_m'] = elev2add\n",
    "#                     df_all = pd.concat([df_all,df_all_add], axis=0)\n",
    "#                     df_all.sort_values('# bin_center_elev_m', inplace=True)\n",
    "\n",
    "#                 # If new min elevation higher than min old elevation\n",
    "#                 if df_all['# bin_center_elev_m'].values[0] < elev_min:\n",
    "#                     elev2add = np.arange(df_all['# bin_center_elev_m'].values[0], elev_min, binsize)\n",
    "#                     df_add = pd.DataFrame(np.zeros((len(elev2add), len(df.columns))), columns=df.columns)\n",
    "#                     df_add['# bin_center_elev_m'] = elev2add\n",
    "#                     df = pd.concat([df,df_add], axis=0)\n",
    "#                     df.sort_values('# bin_center_elev_m', inplace=True)\n",
    "\n",
    "#                 # If new max elevation lower than max old elevation \n",
    "#                 if df_all['# bin_center_elev_m'].values[-1] > elev_max:\n",
    "#                     elev2add = np.arange(elev_max + binsize, df_all['# bin_center_elev_m'].values[-1] + 1, binsize)\n",
    "#                     df_add = pd.DataFrame(np.zeros((len(elev2add), len(df.columns))), columns=df.columns)\n",
    "#                     df_add['# bin_center_elev_m'] = elev2add\n",
    "#                     df = pd.concat([df,df_add], axis=0)\n",
    "#                     df.sort_values('# bin_center_elev_m', inplace=True)\n",
    "\n",
    "#                 df_all.reset_index(inplace=True, drop=True)\n",
    "#                 df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#                 # Merge bins (area-weighted)\n",
    "#                 df_all[' z1_bin_area_valid_km2'] = df_all[' z1_bin_area_valid_km2'] + df[' z1_bin_area_valid_km2']\n",
    "#                 df_all['area_debris_km2'] = df_all['area_debris_km2'] + df['area_debris_km2']\n",
    "#                 df_all[' perc_debris'] = df_all['area_debris_km2'] / df_all[' z1_bin_area_valid_km2'] * 100\n",
    "                \n",
    "#                 if len(debris_idx) > 1:\n",
    "#                     if df['# bin_center_elev_m'].values[debris_idx[0]] < zmin_debris:\n",
    "#                         zmin_debris = df['# bin_center_elev_m'].values[debris_idx[0]]\n",
    "#                     if df['# bin_center_elev_m'].values[debris_idx[-1]] > zmax_debris:\n",
    "#                         zmax_debris = df['# bin_center_elev_m'].values[debris_idx[-1]]\n",
    "\n",
    "#     # Area-weighted statistics\n",
    "#     if df_all is not None:\n",
    "#         # Assume 10 m horizontal resolution for computing the area-weighted statistics of the debris elevation\n",
    "#         pixel_res = 10\n",
    "\n",
    "#         # Estimate pixels in each bin\n",
    "#         df_all['pixels_debris'] = np.round(df_all['area_debris_km2'] / (pixel_res / 1000)**2, 0)\n",
    "\n",
    "#         elev_list_all = []\n",
    "#         for nelev, elev in enumerate(df_all['# bin_center_elev_m']):\n",
    "#             elev_list_single = list(np.repeat(elev, df_all.loc[nelev,'pixels_debris']))\n",
    "#             elev_list_all.extend(elev_list_single)\n",
    "\n",
    "#         # Compute statistics\n",
    "#         elev_mean = np.mean(elev_list_all)\n",
    "#         elev_std = np.std(elev_list_all)\n",
    "#         elev_med = malib.fast_median(elev_list_all)\n",
    "#         elev_mad = malib.mad(elev_list_all)\n",
    "\n",
    "        \n",
    "\n",
    "#         # Update array\n",
    "#         elevstats_mean[lat_idx,lon_idx] = elev_mean\n",
    "#         elevstats_std[lat_idx,lon_idx] = elev_std\n",
    "#         elevstats_med[lat_idx,lon_idx] = elev_med\n",
    "#         elevstats_mad[lat_idx,lon_idx] = elev_mad\n",
    "#         elevstats_min[lat_idx,lon_idx] = zmin_debris\n",
    "#         elevstats_max[lat_idx,lon_idx] = zmax_debris\n",
    "        \n",
    "#         print('mean +/- std:', np.round(elev_mean,0), '+/-', np.round(elev_std,0), \n",
    "#               ';  med +/- mad:', np.round(elev_med,0), '+/-', np.round(elev_mad,0), \n",
    "#               ';  zmin:', zmin_debris, 'zmax:', zmax_debris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export to dataset\n",
    "# ds_elevstats = xr.Dataset({'zmean': (['latitude', 'longitude'], elevstats_mean),\n",
    "#                            'zstd': (['latitude', 'longitude'], elevstats_std),\n",
    "#                            'zmed': (['latitude', 'longitude'], elevstats_med),\n",
    "#                            'zmad': (['latitude', 'longitude'], elevstats_mad),\n",
    "#                            'zmin': (['latitude', 'longitude'], elevstats_min),\n",
    "#                            'zmax': (['latitude', 'longitude'], elevstats_max),},\n",
    "#                           coords={'latitude': ds.latitude.values,\n",
    "#                                   'longitude': ds.longitude.values})\n",
    "# attrs_dict={\n",
    "#      'zmean':{'units':'m a.s.l.',\n",
    "#          'long_name':'mean elevation',\n",
    "#          'comment': 'mean elevation associated with the debris for the given lat/lon'},\n",
    "#      'zstd':{'units':'m a.s.l.',\n",
    "#          'long_name':'standard deviation of the debris elevation',\n",
    "#          'comment': 'standard deviation of the debris elevation associated with the debris for the given lat/lon'},\n",
    "#      'zmed':{'units':'m a.s.l.',\n",
    "#          'long_name':'median elevation',\n",
    "#          'comment': 'median elevation associated with the debris for the given lat/lon'},\n",
    "#      'zmad':{'units':'m a.s.l.',\n",
    "#          'long_name':'median absolute deviation of the debris elevation',\n",
    "#          'comment': 'median absolute deviation of the debris elevation associated with the debris for the given lat/lon'},\n",
    "#      'zmin':{'units':'m a.s.l.',\n",
    "#          'long_name':'minimum elevation',\n",
    "#          'comment': 'minimum elevation with >50% debris cover for the given lat/lon'},\n",
    "#      'zmax':{'units':'m a.s.l.',\n",
    "#          'long_name':'maximum elevation',\n",
    "#          'comment': 'maximum elevation with >50% debris cover for the given lat/lon'}}\n",
    "\n",
    "# for vn in ['zmean', 'zstd', 'zmed', 'zmad']:\n",
    "#     ds_elevstats[vn].attrs = attrs_dict[vn]\n",
    "    \n",
    "# ds_elevstats.to_netcdf(debris_elevstats_fullfn.replace('.nc','v2.nc'))\n",
    "                \n",
    "# print(ds_elevstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lat_idx = 68\n",
    "# # lon_idx = 88\n",
    "# lat_idx = 37\n",
    "# lon_idx = 46\n",
    "# print(ds['latitude'][lat_idx].values, ds['longitude'][lon_idx].values,\n",
    "#       '\\n', ds_elevstats['zmean'][lat_idx,lon_idx].values, ds_elevstats['zstd'][lat_idx,lon_idx].values, \n",
    "#       ds_elevstats['zmed'][lat_idx,lon_idx].values, ds_elevstats['zmad'][lat_idx,lon_idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlon_unique_dict[(68,88)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
